{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDVSpectra Likelihood module tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals (dev)\n",
    "FOLDER_MODULES = r'C:\\Users\\262272G\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\262272G\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "TEST_MODULE = r'C:\\Users\\262272G\\Documents\\GitHub\\tenement-tools\\tests\\code'\n",
    "GRP_LYR_FILE = r'C:\\Users\\262272G\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'toolbox'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# import testing functions\n",
    "sys.path.append(TEST_MODULE)\n",
    "import test_funcs\n",
    "\n",
    "# import toolbox\n",
    "arcpy.ImportToolbox(r\"C:\\Users\\262272G\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'test_funcs' from 'C:\\\\Users\\\\262272G\\\\Documents\\\\GitHub\\\\tenement-tools\\\\tests\\\\code\\\\test_funcs.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(test_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data files and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup general io\n",
    "#input_folder = r'E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs'\n",
    "#output_folder = r'E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\outputs'\n",
    "input_folder = r'C:\\Users\\262272G\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs'\n",
    "output_folder = r'C:\\Users\\262272G\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\outputs'\n",
    "temp_nc = os.path.join(input_folder, 'temp_nc.nc')  # temp nc file for use when breaking ncs\n",
    "\n",
    "# setup landsat cubes paths\n",
    "ls_cubes = [\n",
    "    #r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_1_ls_90_20_raw_odc.nc\",\n",
    "    #r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\",\n",
    "    #r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_3_ls_90_20_raw_odc.nc\",\n",
    "    #r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_4_ls_90_20_raw_odc.nc\",\n",
    "    \n",
    "    r\"C:\\Users\\262272G\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\",\n",
    "]\n",
    "\n",
    "# setup sentinel2 cubes paths\n",
    "s2_cubes = [\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_1_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_3_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_4_s2_16_20_raw_odc.nc\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup dataset corruptor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these dict items contain a dataset corruptor function and associated params\n",
    "# comment any out that aren't required.\n",
    "def build_data_corruptors():\n",
    "    \n",
    "    # set up list\n",
    "    nc_corruptors = []\n",
    "\n",
    "    # func: raw default dataset, no changes \n",
    "    nc_corruptors.append({'func': test_funcs.default, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: remove x, y, time, spatial_ref coords only (note: seperate tests)\n",
    "    nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'x'})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'y'})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'time'})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'spatial_ref'})\n",
    "\n",
    "    # func: remove red and oa_fmask band vars (note: seperate tests)\n",
    "    nc_corruptors.append({'func': test_funcs.remove_var, 'in_nc': temp_nc, 'var': 'nbart_red'})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_var, 'in_nc': temp_nc, 'var': 'oa_fmask'})\n",
    "\n",
    "    # func: set all vars to nan\n",
    "    nc_corruptors.append({'func': test_funcs.set_nc_vars_all_nan, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: set all vars for 10 rand times to all nan\n",
    "    nc_corruptors.append({'func': test_funcs.set_nc_vars_random_all_nan, 'in_nc': temp_nc, 'num': 10})\n",
    "\n",
    "    # func: strip all attrs from nc    \n",
    "    nc_corruptors.append({'func': test_funcs.strip_nc_attributes, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: set vars in first and last time index to all nan\n",
    "    nc_corruptors.append({'func': test_funcs.set_end_times_to_all_nan, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: reduce whole nc to one random time slice\n",
    "    nc_corruptors.append({'func': test_funcs.reduce_to_one_scene, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: set wet months all nan, all years, for specific months (note: seperate tests)\n",
    "    nc_corruptors.append({'func': test_funcs.set_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1]})\n",
    "    nc_corruptors.append({'func': test_funcs.set_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1, 2, 3]})\n",
    "    nc_corruptors.append({'func': test_funcs.set_all_specific_season_nan, 'in_nc': temp_nc, 'months': [7, 8, 9, 10, 11, 12]})\n",
    "\n",
    "    # func: set wet months all nan, specific years, for specific months (note: seperate tests)\n",
    "    nc_corruptors.append({'func': test_funcs.set_specific_years_season_nan, 'in_nc': temp_nc, 'years': [1990], 'months': [1, 2, 3]})\n",
    "    nc_corruptors.append({'func': test_funcs.set_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2005], 'months': [1, 2, 3]})\n",
    "    nc_corruptors.append({'func': test_funcs.set_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2006, 2007], 'months': [1, 2, 3]})\n",
    "\n",
    "    # func: drop wet months, all years, for specific months (note: seperate tests)\n",
    "    nc_corruptors.append({'func': test_funcs.remove_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1]})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1, 2, 3]})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_all_specific_season_nan, 'in_nc': temp_nc, 'months': [7, 8, 9, 10, 11, 12]})\n",
    "\n",
    "    # func: drop wet months, specific years, for specific months (note: seperate tests)\n",
    "    nc_corruptors.append({'func': test_funcs.remove_specific_years_season_nan, 'in_nc': temp_nc, 'years': [1990], 'months': [1, 2, 3]})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2009], 'months': [1, 2, 3]})\n",
    "    nc_corruptors.append({'func': test_funcs.remove_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2007, 2008], 'months': [1, 2, 3]})\n",
    "    \n",
    "    return nc_corruptors\n",
    "\n",
    "nc_corruptors = build_data_corruptors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# veg and mst index\n",
    "# try only veg\n",
    "# try only mst\n",
    "# try unavailble veg\n",
    "# try unavalble mst\n",
    "# try all veg\n",
    "# try all mst\n",
    "\n",
    "# outlier correction\n",
    "# zscore value is wrong\n",
    "# 0.01, 0.1, 0.05\n",
    "# try none\n",
    "# try 0\n",
    "# try no cube data\n",
    "# try dims\n",
    "\n",
    "# invariant standardisation\n",
    "# upper 0.99, lower 0.05\n",
    "# try none for upper and lower\n",
    "# try 0 for both\n",
    "# try - values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test One: Wet Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_one_wet_months(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the wet months input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '',                   # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't1{}_{}.nc')\n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t1a (test one a). Wet months input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_wet_months': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        _ = str(random.randint(1, 5))\n",
    "        print('\\n\\nRunning t1b (test one b). Wet months have 1 month only ({}).'.format(_))\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_wet_months': _})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)      \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t1c (test one c). Wet months have several months (1, 2, 3).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_wet_months': '1;2;3'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t1d (test one d). Wet months contains months in dry (5, 6, 7, 8, 9).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_wet_months': '5;6;7;8;9'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t1e (test one e). Wet months contains 1 month in december (12, 1, 2).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_wet_months': '12;1;2'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "def perform_tests(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests (e.g. wet season months)\"\"\"\n",
    "    \n",
    "    print('\\nRunning all data corruption functions through test one (wet season months).')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func: one wet months\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf with various wet month scenarios\n",
    "        _test_one_wet_months(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set specific dataset\n",
    "nc_file = ls_cubes[0]\n",
    "perform_tests(in_nc=nc_file, temp_nc=temp_nc, data_corruption_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "#  sat cube from cog\n",
    "# try dims\n",
    "# try no crs\n",
    "# try no data\n",
    "# try missing attrs\n",
    "# try 1 image\n",
    "# try all nan\n",
    "# try some nan\n",
    "# try very large ds\n",
    "# try very small ds\n",
    "# try wrong bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set testing parameters. these parameters must match arcgis pro input\n",
    "# syntax (i.e. values brought in directly from pro interface controls)\n",
    "\n",
    "# default\n",
    "test_1 = {\n",
    "    'in_nc': r'C:\\Users\\Lewis\\Desktop\\ryan\\ls.nc',        # raw input satellite netcdf\n",
    "    'out_nc': r'C:\\Users\\Lewis\\Desktop\\ryan\\ls_like.nc',  # raw output likelihood netcdf    \n",
    "    'in_wet_months': '1;2;3',                             # wet months \n",
    "    'in_dry_months': '9;10;11',                           # dry months \n",
    "    'in_veg_idx': 'MAVI',                                 # vege index name\n",
    "    'in_mst_idx': 'NDMI',                                 # moisture index name       \n",
    "    'in_zscore_pvalue': None,                             # zscore pvalue\n",
    "    'in_ivt_qupper': 0.99,                                # upper quantile for standardisation\n",
    "    'in_ivt_qlower': 0.05,                                # lower quantile for standardisation\n",
    "    'in_fmask_flags': 'Valid;Snow;Water',                 # fmask flag values\n",
    "    'in_max_cloud': 10,                                   # max cloud percentage\n",
    "    'in_interpolate': True,                               # interpolate missing pixels\n",
    "    'in_add_result_to_map': True,                         # add result to map\n",
    "}\n",
    "\n",
    "#execute(**test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "test_2 = {\n",
    "    'in_nc': r'C:\\Users\\Lewis\\Desktop\\ryan\\ls.nc',        # raw input satellite netcdf\n",
    "    'out_nc': r'C:\\Users\\Lewis\\Desktop\\ryan\\ls_like.nc',  # raw output likelihood netcdf    \n",
    "    'in_wet_months': '1;2;3',                             # wet months \n",
    "    'in_dry_months': '9;10;11',                           # dry months \n",
    "    'in_veg_idx': 'MAVI',                                 # vege index name\n",
    "    'in_mst_idx': 'NDMI',                                 # moisture index name       \n",
    "    'in_zscore_pvalue': None,                             # zscore pvalue\n",
    "    'in_ivt_qupper': 0.99,                                # upper quantile for standardisation\n",
    "    'in_ivt_qlower': 0.05,                                # lower quantile for standardisation\n",
    "    'in_fmask_flags': 'Valid;Snow;Water',                 # fmask flag values\n",
    "    'in_max_cloud': 10,                                   # max cloud percentage\n",
    "    'in_interpolate': True,                               # interpolate missing pixels\n",
    "    'in_add_result_to_map': True,                         # add result to map\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
