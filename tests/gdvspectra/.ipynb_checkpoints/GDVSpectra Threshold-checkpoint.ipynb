{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDVSpectra Threshold module tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# globals (dev)\n",
    "FOLDER_MODULES = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "TEST_MODULE = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\tests\\code'\n",
    "GRP_LYR_FILE = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'toolbox'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# import testing functions\n",
    "sys.path.append(TEST_MODULE)\n",
    "import test_funcs\n",
    "\n",
    "# import toolbox\n",
    "arcpy.ImportToolbox(r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reload libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'test_funcs' from 'C:\\\\Users\\\\Lewis\\\\Documents\\\\GitHub\\\\tenement-tools\\\\tests\\\\code\\\\test_funcs.py'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(test_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data files and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup general io\n",
    "input_folder = r'E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_threshold\\inputs'\n",
    "output_folder = r'E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_threshold\\outputs'\n",
    "temp_nc = os.path.join(input_folder, 'temp_nc.nc')  # temp nc file for use when breaking ncs\n",
    "\n",
    "# setup landsat cubes paths\n",
    "ls_cubes = [\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_1_ls_90_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_3_ls_90_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_4_ls_90_20_raw_odc.nc\",\n",
    "]\n",
    "\n",
    "# setup sentinel2 cubes paths\n",
    "s2_cubes = [\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_1_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_3_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_4_s2_16_20_raw_odc.nc\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup dataset corruptor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# these dict items contain a dataset corruptor function and associated params\n",
    "# comment any out that aren't required.\n",
    "def build_data_corruptors():\n",
    "    \n",
    "    # set up list\n",
    "    nc_corruptors = []\n",
    "\n",
    "    # func: raw default dataset, no changes \n",
    "    #nc_corruptors.append({'func': test_funcs.default, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: remove x, y, time, spatial_ref coords only (note: seperate tests)\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'x'})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'y'})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'time'})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_coord, 'in_nc': temp_nc, 'coord': 'spatial_ref'})\n",
    "\n",
    "    # func: remove red and oa_fmask band vars (note: seperate tests)\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_var, 'in_nc': temp_nc, 'var': 'nbart_red'})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_var, 'in_nc': temp_nc, 'var': 'oa_fmask'})\n",
    "    \n",
    "    # func: limit number of years in various circumstances (1, 2, 3, 5 years) (note: seperate tests)\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 1990, 'e_year': 1990})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 2000, 'e_year': 2000})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 2010, 'e_year': 2010})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 1990, 'e_year': 1991})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 2005, 'e_year': 2006})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 2019, 'e_year': 2020})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 1990, 'e_year': 1992})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 2010, 'e_year': 2012})\n",
    "    #nc_corruptors.append({'func': test_funcs.limit_years, 'in_nc': temp_nc, 's_year': 2011, 'e_year': 2013})    \n",
    "\n",
    "    # func: set all vars to nan\n",
    "    #nc_corruptors.append({'func': test_funcs.set_nc_vars_all_nan, 'in_nc': temp_nc})\n",
    "    \n",
    "    # func: set all vars to zero\n",
    "    #nc_corruptors.append({'func': test_funcs.set_nc_vars_all_zero, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: set all vars for 10 rand times to all nan\n",
    "    #nc_corruptors.append({'func': test_funcs.set_nc_vars_random_all_nan, 'in_nc': temp_nc, 'num': 10})\n",
    "\n",
    "    # func: strip all attrs from nc    \n",
    "    #nc_corruptors.append({'func': test_funcs.strip_nc_attributes, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: set vars in first and last time index to all nan\n",
    "    #nc_corruptors.append({'func': test_funcs.set_end_times_to_all_nan, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: reduce whole nc to one random time slice\n",
    "    #nc_corruptors.append({'func': test_funcs.reduce_to_one_scene, 'in_nc': temp_nc})\n",
    "\n",
    "    # func: set wet months all nan, all years, for specific months (note: seperate tests)\n",
    "    #nc_corruptors.append({'func': test_funcs.set_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1]})\n",
    "    #nc_corruptors.append({'func': test_funcs.set_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1, 2, 3]})\n",
    "    #nc_corruptors.append({'func': test_funcs.set_all_specific_season_nan, 'in_nc': temp_nc, 'months': [7, 8, 9, 10, 11, 12]})\n",
    "\n",
    "    # func: set wet months all nan, specific years, for specific months (note: seperate tests)\n",
    "    #nc_corruptors.append({'func': test_funcs.set_specific_years_season_nan, 'in_nc': temp_nc, 'years': [1990], 'months': [1, 2, 3]})\n",
    "    #nc_corruptors.append({'func': test_funcs.set_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2005], 'months': [1, 2, 3]})\n",
    "    #nc_corruptors.append({'func': test_funcs.set_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2006, 2007], 'months': [1, 2, 3]})\n",
    "\n",
    "    # func: drop wet months, all years, for specific months (note: seperate tests)\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1]})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_all_specific_season_nan, 'in_nc': temp_nc, 'months': [1, 2, 3]})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_all_specific_season_nan, 'in_nc': temp_nc, 'months': [7, 8, 9, 10, 11, 12]})\n",
    "\n",
    "    # func: drop wet months, specific years, for specific months (note: seperate tests)\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_specific_years_season_nan, 'in_nc': temp_nc, 'years': [1990], 'months': [1, 2, 3]})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2009], 'months': [1, 2, 3]})\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_specific_years_season_nan, 'in_nc': temp_nc, 'years': [2007, 2008], 'months': [1, 2, 3]})\n",
    "    \n",
    "    # func: remove crs attribute\n",
    "    #nc_corruptors.append({'func': test_funcs.remove_crs_attr, 'in_nc': temp_nc})    \n",
    "    \n",
    "    # func: invalidate crs attribute\n",
    "    #nc_corruptors.append({'func': test_funcs.invalidate_crs_attr, 'in_nc': temp_nc, 'crs_text': 'EPSG:4326'})\n",
    "    #nc_corruptors.append({'func': test_funcs.invalidate_crs_attr, 'in_nc': temp_nc, 'crs_text': ''})\n",
    "    \n",
    "    # func: remove nodatavals attribute\n",
    "    nc_corruptors.append({'func': test_funcs.remove_nodatavals_attr, 'in_nc': temp_nc})    \n",
    "    \n",
    "    return nc_corruptors\n",
    "\n",
    "nc_corruptors = build_data_corruptors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# veg and mst index\n",
    "# try only veg\n",
    "# try only mst\n",
    "# try unavailble veg\n",
    "# try unavalble mst\n",
    "# try all veg\n",
    "# try all mst\n",
    "\n",
    "# outlier correction\n",
    "# zscore value is wrong\n",
    "# 0.01, 0.1, 0.05\n",
    "# try none\n",
    "# try 0\n",
    "# try no cube data\n",
    "# try dims\n",
    "\n",
    "# invariant standardisation\n",
    "# upper 0.99, lower 0.05\n",
    "# try none for upper and lower\n",
    "# try 0 for both\n",
    "# try - values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Set specific raw netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set specific dataset\n",
    "nc_file = ls_cubes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test One: Wet Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_one_wet_months(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the wet months input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '',                   # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't1{}_{}.nc')\n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t1default (test one default). Wet months input is \"1;2;3\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_wet_months': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t1a (test one a). Wet months input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_wet_months': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        _ = str(random.randint(1, 5))\n",
    "        print('\\n\\nRunning t1b (test one b). Wet months have 1 month only ({}).'.format(_))\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_wet_months': _})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)      \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t1c (test one c). Wet months have several months (2, 3, 4).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_wet_months': '2;3;4'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t1d (test one d). Wet months contains months in dry (5, 6, 7, 8, 9).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_wet_months': '5;6;7;8;9'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t1e (test one e). Wet months contains 1 month in december (12, 1, 2).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_wet_months': '12;1;2'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "def perform_test_one(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "    \n",
    "    print('\\nRunning all data corruption functions through test one.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_one_wet_months(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test One: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test one\n",
    "perform_test_one(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "scrolled": false
   },
   "source": [
    "### Test Two: Dry Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_two_dry_months(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the dry months input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '',                   # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't2{}_{}.nc')\n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t2default (test two default). Dry months input is \"9;10;11\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_dry_months': '9;10;11'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t2a (test two a). Dry months input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_dry_months': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        _ = str(random.randint(7, 12))\n",
    "        print('\\n\\nRunning t2b (test two b). Dry months have 1 month only ({}).'.format(_))\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_dry_months': _})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)      \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t2c (test two c). Dry months have several months (10, 11, 12).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_dry_months': '10;11;12'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t2d (test two d). Dry months contains months in wet (1, 2, 3, 4, 5).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_dry_months': '1;2;3;4;5'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t2e (test two e). Dry months contains 1 month in jan (11, 12, 1).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_dry_months': '11;12;1'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "def perform_test_two(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "    \n",
    "    print('\\nRunning all data corruption functions through test two.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_two_dry_months(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Two: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running all data corruption functions through test two (dry season months).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Running data corruption function: remove_nodatavals_attr\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Help on function remove_nodatavals_attr in module test_funcs:\n",
      "\n",
      "remove_nodatavals_attr(in_nc)\n",
      "    strip nodatavals attribute from nc\n",
      "\n",
      "With parameter: in_nc of value: E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\temp_nc.nc\n",
      "\n",
      "Beginning test.\n",
      "Duplicating cube: E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\n",
      "Stripping nodatavals attribute from nc dim\n",
      "\n",
      "\n",
      "Running t2a (test two a). Dry months input is \"\".\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Failed to execute. Parameters are not valid.\n",
      "ERROR 000735: Dry month(s): Value is required\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t2b (test two b). Dry months have 1 month only (11).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t2c (test two c). Dry months have several months (9, 10, 11).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t2d (test two d). Dry months contains months in wet (1, 2, 3, 4, 5).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1996, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t2e (test two e). Dry months contains 1 month in jan (11, 12, 1).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1996, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run test two\n",
    "perform_test_two(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Three: Vegetation Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_three_veg_idx(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the veg idx input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',          # dry months \n",
    "        'in_veg_idx': '',                      # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't3{}_{}.nc')\n",
    "            \n",
    "    try:\n",
    "        print('\\n\\nRunning t3default (test three default). Veg Idx input is \"MAVI\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_veg_idx': 'MAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3a (test three a). Veg Idx input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_veg_idx': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3b (test three b). Veg Idx input is NDVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_veg_idx': 'NDVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3c (test three c). Veg Idx input is EVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_veg_idx': 'EVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3d (test three d). Veg Idx input is SAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_veg_idx': 'SAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t3e (test three e). Veg Idx input is MSAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_veg_idx': 'MSAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3f (test three f). Veg Idx input is SLAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_veg_idx': 'SLAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3g (test three g). Veg Idx input is MAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_veg_idx': 'MAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3h (test three h). Veg Idx input is kNDVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('h', out_func_name), 'in_veg_idx': 'kNDVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3i (test three i). Veg Idx input is TCG.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('i', out_func_name), 'in_veg_idx': 'TCG'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3j (test three j). Veg Idx input does not exist (NRVA).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('j', out_func_name), 'in_veg_idx': 'NRVA'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def perform_test_three(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test three.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_three_veg_idx(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Three: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running all data corruption functions through test three (veg idx).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Running data corruption function: remove_nodatavals_attr\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Help on function remove_nodatavals_attr in module test_funcs:\n",
      "\n",
      "remove_nodatavals_attr(in_nc)\n",
      "    strip nodatavals attribute from nc\n",
      "\n",
      "With parameter: in_nc of value: E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\temp_nc.nc\n",
      "\n",
      "Beginning test.\n",
      "Duplicating cube: E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\n",
      "Stripping nodatavals attribute from nc dim\n",
      "\n",
      "\n",
      "Running t3a (test three a). Veg Idx input is \"\".\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3b (test three b). Veg Idx input is NDVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3c (test three c). Veg Idx input is EVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3d (test three d). Veg Idx input is SAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3e (test three e). Veg Idx input is MSAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3f (test three f). Veg Idx input is SLAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3g (test three g). Veg Idx input is MAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3h (test three h). Veg Idx input is kNDVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3i (test three i). Veg Idx input is TCG.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3j (test three j). Veg Idx input does not exist (NRVA).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Failed to execute. Parameters are not valid.\n",
      "ERROR 000800: The value is not a member of NDVI | EVI | SAVI | MSAVI | SLAVI | MAVI | kNDVI | TCG.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run test three\n",
    "perform_test_three(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Four: Moisture Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_four_mst_idx(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the mst idx input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': '',                      # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't4{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t4default (test four default). Mst Idx input is \"NDMI\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_mst_idx': 'NDMI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t4a (test four a). Mst Idx input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_mst_idx': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t4b (test four b). Mst Idx input is NDMI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_mst_idx': 'NDMI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t4c (test four c). Mst Idx input is GVMI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_mst_idx': 'GVMI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t4d (test four d). Mst Idx input does not exist (MRVA).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_mst_idx': 'MRVA'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def perform_test_four(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test four.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_four_mst_idx(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Four: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test four\n",
    "perform_test_four(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Five: Outlier Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_five_outlier(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the outlier correction input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': '',                # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't5{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5default (test five default). Outlier correction input is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_zscore_pvalue': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t5a (test five a). Outlier correction input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_zscore_pvalue': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5b (test five b). Outlier correction input is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_zscore_pvalue': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5c (test five c). Outlier correction input is string of 0.01.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_zscore_pvalue': '0.01'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t5d (test five d). Outlier correction input is string of 0.05.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_zscore_pvalue': '0.05'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "             \n",
    "    try:\n",
    "        print('\\n\\nRunning t5e (test five e). Outlier correction input is string of 0.1.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_zscore_pvalue': '0.1'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5f (test five f). Outlier correction input is string of 1.0 (not supported).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_zscore_pvalue': '1.0'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)      \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t5g (test five g). Outlier correction input is float of 0.01.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_zscore_pvalue': 0.01})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5h (test five h). Outlier correction input is int of 1.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('h', out_func_name), 'in_zscore_pvalue': 1})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "        \n",
    "def perform_test_five(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test five.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_five_outlier(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Five: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test five\n",
    "perform_test_five(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Six: IVT Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_six_ivt_standardisation(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the ivt standardisation input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': '',                   # upper quantile for standardisation\n",
    "        'in_ivt_qlower': '',                   # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't6{}_{}.nc')   \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t6default (test six default). IVT lower, upper input is 0.05, 0.99.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_ivt_qlower': 0.05, 'in_ivt_qupper': 0.99})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t6a (test six a). IVT lower, upper input is \"\", \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_ivt_qlower': '', 'in_ivt_qupper': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6b (test six b). IVT lower, upper input is None, ''.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_ivt_qlower': None, 'in_ivt_qupper': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6c (test six c). IVT lower, upper input is 0.0, 0.99.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_ivt_qlower': 0.0, 'in_ivt_qupper': 0.99})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6d (test six d). IVT lower, upper input is 0.05, 0.0.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_ivt_qlower': 0.05, 'in_ivt_qupper': 0.0})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)               \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t6e (test six e). IVT lower, upper input is 0.25, 0.80.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_ivt_qlower': 0.25, 'in_ivt_qupper': 0.80})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6f (test six f). IVT lower, upper input is 0.4, 0.6.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_ivt_qlower': 0.4, 'in_ivt_qupper': 0.6})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)          \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t6g (test six g). IVT lower, upper input is 0.6, 0.4.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_ivt_qlower': 0.6, 'in_ivt_qupper': 0.4})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6h (test six h). IVT lower, upper input is 0.2, 1.4.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('h', out_func_name), 'in_ivt_qlower': 0.2, 'in_ivt_qupper': 1.4})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6i (test six i). IVT lower, upper input is 0.5, 0.5.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('i', out_func_name), 'in_ivt_qlower': 0.5, 'in_ivt_qupper': 0.5})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6j (test six j). IVT lower, upper input is \"0.2\", \"0.8\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('j', out_func_name), 'in_ivt_qlower': \"0.2\", 'in_ivt_qupper': \"0.8\"})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)          \n",
    "    \n",
    "        \n",
    "def perform_test_six(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test six.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_six_ivt_standardisation(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Six: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test six\n",
    "perform_test_six(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Seven: Pixel Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_seven_pixel_flags(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the pixel flag input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': '',                  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't7{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7default (test seven default). pixel flag input is \"Valid;Snow;Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_fmask_flags': 'Valid;Snow;Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t7a (test seven a). pixel flag input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_fmask_flags': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t7b (test seven b). pixel flag input is \"NoData;Valid;Cloud;Shadow;Snow;Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_fmask_flags': 'NoData;Valid;Cloud;Shadow;Snow;Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7c (test seven c). pixel flag input is \"Valid\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_fmask_flags': 'Valid'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t7d (test seven d). pixel flag input is \"Cloud;Shadow\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_fmask_flags': 'Cloud;Shadow'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t7e (test seven e). pixel flag input is \"Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_fmask_flags': 'Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7f (test seven f). pixel flag input is \"Water;Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_fmask_flags': 'Water;Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7g (test seven g). pixel flag input is \"water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_fmask_flags': 'water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "        \n",
    "def perform_test_seven(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test seven.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_seven_pixel_flags(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Seven: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test seven\n",
    "perform_test_seven(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Eight: Max Cloud Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_eight_max_cloud_cover(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the max cloud cover\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': '',                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't8{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8default (test eight default). max cloud cover is 10.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_max_cloud': 10})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t8a (test eight a). max cloud cover is 0.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_max_cloud': 0})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8b (test eight b). max cloud cover is 100.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_max_cloud': 10})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8c (test eight c). max cloud cover is 50.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_max_cloud': 50})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8d (test eight d). max cloud cover is \"10\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_max_cloud': \"10\"})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8e (test eight e). max cloud cover is 150.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_max_cloud': 150})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8f (test eight f). max cloud cover is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_max_cloud': \"\"})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)     \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8g (test eight g). max cloud cover is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_max_cloud': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "    \n",
    "def perform_test_eight(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test eight.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_eight_max_cloud_cover(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Eight: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test eight\n",
    "perform_test_eight(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Nine: Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_nine_interpolate(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the interpolate\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': '',                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't9{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t9default (test nine default). interpolate is True.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_interpolate': True})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t9a (test nine a). interpolate is False.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_interpolate': False})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t9b (test nine b). interpolate is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_interpolate': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "    \n",
    "def perform_test_nine(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test nine.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_nine_interpolate(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Nine: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test nine\n",
    "perform_test_nine(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Ten: Add To Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_ten_add_to_map(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the add output to map\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': '',          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't10{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t10default (test ten default). in_add_result_to_map is True.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_add_result_to_map': True})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t10a (test ten a). add result to_map is False.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_add_result_to_map': False})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t10b (test ten b). add result to_map is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_add_result_to_map': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)       \n",
    "    \n",
    "def perform_test_ten(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test ten.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_ten_add_to_map(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Ten: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test ten\n",
    "perform_test_ten(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
