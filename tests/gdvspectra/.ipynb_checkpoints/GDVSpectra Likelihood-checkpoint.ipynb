{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDVSpectra Likelihood module tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set globals paths\n",
    "FOLDER_MODULES = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "TEST_MODULE = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\tests\\code'\n",
    "GRP_LYR_FILE = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'toolbox'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from IPython.utils import io\n",
    "\n",
    "# import testing functions\n",
    "sys.path.append(TEST_MODULE)\n",
    "import test_funcs\n",
    "\n",
    "# import full arcpy toolbox\n",
    "arcpy.ImportToolbox(r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reload libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'test_funcs' from 'C:\\\\Users\\\\Lewis\\\\Documents\\\\GitHub\\\\tenement-tools\\\\tests\\\\code\\\\test_funcs.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if scripts change, reload\n",
    "from importlib import reload\n",
    "reload(test_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Set data files and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# setup general io. nc ins and outs exist in these folders\n",
    "input_folder = r'E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs'\n",
    "output_folder = r'E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\outputs'\n",
    "\n",
    "# temp nc file for use when breaking ncs\n",
    "temp_nc = os.path.join(input_folder, 'temp_nc.nc')  \n",
    "\n",
    "# setup landsat cubes paths\n",
    "ls_cubes = [\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_1_ls_90_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_3_ls_90_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_4_ls_90_20_raw_odc.nc\",\n",
    "]\n",
    "\n",
    "# setup sentinel2 cubes paths\n",
    "s2_cubes = [\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_1_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_3_s2_16_20_raw_odc.nc\",\n",
    "    r\"E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_4_s2_16_20_raw_odc.nc\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Set specific raw netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set specific dataset\n",
    "nc_file = ls_cubes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up function to iterate corruptor and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_corruptors_through_tests(in_nc, nc_coors, tests, verbose):\n",
    "    \"\"\"\n",
    "    this func takes a path to nc file or raw sat imagery, a list of nc\n",
    "    corruptor funcs and params, a list of test funcs and params. Each \n",
    "    nc corruptor func is iterated through, and for each corrupted nc, \n",
    "    each test in tests is applied to corrupted nc. verbose sets how\n",
    "    much information is printed.\n",
    "    \"\"\"\n",
    "    \n",
    "    for nc_corr in nc_corrs:\n",
    "        corr_name = nc_corr[0].__name__                   # name of current corruptor func\n",
    "        corr_func, corr_params = nc_corr[0], nc_corr[1]   # pointer to corruptor func and dict of params\n",
    "\n",
    "        # notify\n",
    "        print('Corrupting NetCDF via: {}.\\n'.format(corr_name) + '- ' * 30)\n",
    "\n",
    "        # create temp nc and corrupt it with current corruptor\n",
    "        if not verbose:\n",
    "            with io.capture_output() as cap:\n",
    "                test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "        else:\n",
    "            test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # run current corruptor function\n",
    "        try:\n",
    "            print(**corr_params)\n",
    "            corr_func(**corr_params)\n",
    "        except Exception as e:    \n",
    "            print(e)\n",
    "            print('Corruptor did not have enough data to work with. Skipping.\\n')\n",
    "\n",
    "        # iter each test func and apply to current corrupt nc\n",
    "        for test in tests:\n",
    "            test_nc_name = corr_name + '_' + test[0]    # name of current test nc\n",
    "            test_func, test_params = test[1], test[2]   # pointer to test func and dict of params\n",
    "            test_msg = test[3]\n",
    "\n",
    "            # create output nc file path and name and update params for in/out paths\n",
    "            out_nc_file = os.path.join(output_folder, test_nc_name)\n",
    "            \n",
    "            # remove output nc if exists\n",
    "            if os.path.exists(out_nc_file):\n",
    "                os.remove(out_nc_file)\n",
    "            \n",
    "            # update params\n",
    "            test_params.update({'in_nc_file': temp_nc, 'out_likelihood_nc_file': out_nc_file})\n",
    "            \n",
    "            print(test_params)\n",
    "\n",
    "            # perform current test\n",
    "            try:\n",
    "                # notify\n",
    "                print('Performing test: {}.'.format(test_nc_name))\n",
    "\n",
    "                # perform test, provide prints if requested\n",
    "                if not verbose:\n",
    "                    with io.capture_output() as cap:\n",
    "                        test_func(**test_params)\n",
    "                else:\n",
    "                    test_func(**test_params)\n",
    "                    print('\\n')\n",
    "\n",
    "            except Exception as e:    \n",
    "                print(e)\n",
    "\n",
    "        # notify\n",
    "        print('All tests applied to corruptor NetCDF.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Set up netcdf corruptor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# these are numerous netcdf corruptors. feed a raw nc in, break it, output as temp nc\n",
    "# comment out any that are irrelevant\n",
    "# each of these uncommented will be fed through the tests below\n",
    "def build_nc_corruptors(temp_nc):\n",
    "    \"\"\"\n",
    "    each one of these is a unique netcdf corruptor functions and \n",
    "    associated parameters. \n",
    "    \"\"\"\n",
    "    \n",
    "    # set up list\n",
    "    cs = []\n",
    "\n",
    "    # func: raw default dataset, no changes\n",
    "    cs.append([test_funcs.nc_default, {'in_nc': temp_nc}])\n",
    "\n",
    "    # func: remove x, y, time, spatial_ref coords\n",
    "    #cs.append([test_funcs.remove_coord, {'in_nc': temp_nc, 'coord': 'x'}])\n",
    "    #cs.append([test_funcs.remove_coord, {'in_nc': temp_nc, 'coord': 'y'}])\n",
    "    #cs.append([test_funcs.remove_coord, {'in_nc': temp_nc, 'coord': 'time'}])\n",
    "    #cs.append([test_funcs.remove_coord, {'in_nc': temp_nc, 'coord': 'spatial_ref'}])\n",
    "\n",
    "    #func: remove red and oa_fmask band vars\n",
    "    #cs.append([test_funcs.remove_var, {'in_nc': temp_nc, 'var': 'nbart_red'}])\n",
    "    #cs.append([test_funcs.remove_var, {'in_nc': temp_nc, 'var': 'oa_fmask'}])\n",
    "\n",
    "    #func: limit number of years in various combos\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 1990, 'e_year': 1990}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 2010, 'e_year': 2010}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 2012, 'e_year': 2012}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 1991, 'e_year': 1992}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 2005, 'e_year': 2006}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 2019, 'e_year': 2020}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 1993, 'e_year': 1995}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 2010, 'e_year': 2012}])\n",
    "    #cs.append([test_funcs.limit_years, {'in_nc': temp_nc, 's_year': 2011, 'e_year': 2013}])\n",
    "\n",
    "    #func: set all vars to nan\n",
    "    #cs.append([test_funcs.set_nc_vars_all_nan, {'in_nc': temp_nc}])\n",
    "\n",
    "    #func: set all vars to zero\n",
    "    #cs.append([test_funcs.set_nc_vars_all_zero, {'in_nc': temp_nc}])\n",
    "\n",
    "    #func: set all vars for 10 rand times to all nan\n",
    "    #cs.append([test_funcs.set_nc_vars_random_all_nan, {'in_nc': temp_nc, 'num': 10}])\n",
    "\n",
    "    #func: strip all attrs from nc    \n",
    "    #cs.append([test_funcs.strip_nc_attributes, {'in_nc': temp_nc}])\n",
    "\n",
    "    #func: set vars in first and last time index to all nan\n",
    "    #cs.append([test_funcs.set_end_times_to_all_nan, {'in_nc': temp_nc}])\n",
    "\n",
    "    #func: reduce whole nc to one random time slice\n",
    "    #cs.append([test_funcs.reduce_to_one_scene, {'in_nc': temp_nc}])\n",
    "\n",
    "    #func: set wet months all nan, all years, for specific months\n",
    "    #cs.append([test_funcs.set_all_specific_season_nan, {'in_nc': temp_nc, 'months': [1]}])\n",
    "    #cs.append([test_funcs.set_all_specific_season_nan, {'in_nc': temp_nc, 'months': [1, 2, 3]}])\n",
    "    #cs.append([test_funcs.set_all_specific_season_nan, {'in_nc': temp_nc, 'months': [7, 8, 9, 10, 11, 12]}])\n",
    "\n",
    "    #func: set wet months all nan, specific years, for specific months\n",
    "    #cs.append([test_funcs.set_specific_years_season_nan, {'in_nc': temp_nc, 'years': [1990], 'months': [1, 2, 3]}])\n",
    "    #cs.append([test_funcs.set_specific_years_season_nan, {'in_nc': temp_nc, 'years': [2005], 'months': [1, 2, 3]}])\n",
    "    #cs.append([test_funcs.set_specific_years_season_nan, {'in_nc': temp_nc, 'years': [2006, 2007], 'months': [1, 2, 3]}])\n",
    "\n",
    "    #func: drop wet months, all years, for specific months\n",
    "    #cs.append([test_funcs.remove_all_specific_season_nan, {'in_nc': temp_nc, 'months': [1]}])\n",
    "    #cs.append([test_funcs.remove_all_specific_season_nan, {'in_nc': temp_nc, 'months': [1, 2, 3]}])\n",
    "    #cs.append([test_funcs.remove_all_specific_season_nan, {'in_nc': temp_nc, 'months': [7, 8, 9, 10, 11, 12]}])\n",
    "\n",
    "    #func: drop wet months, specific years, for specific months (note: seperate tests)\n",
    "    #cs.append([test_funcs.remove_specific_years_season_nan, {'in_nc': temp_nc, 'years': [1990], 'months': [1, 2, 3]}])\n",
    "    #cs.append([test_funcs.remove_specific_years_season_nan, {'in_nc': temp_nc, 'years': [2009], 'months': [1, 2, 3]}])\n",
    "    #cs.append([test_funcs.remove_specific_years_season_nan, {'in_nc': temp_nc, 'years': [2007, 2008], 'months': [1, 2, 3]}])\n",
    "\n",
    "    #func: remove crs attribute\n",
    "    #cs.append([test_funcs.remove_crs_attr, {'in_nc': temp_nc}])\n",
    "\n",
    "    #func: invalidate crs attribute\n",
    "    #cs.append([test_funcs.invalidate_crs_attr, {'in_nc': temp_nc, 'crs_text': 'EPSG:4326'}])\n",
    "    #cs.append([test_funcs.invalidate_crs_attr, {'in_nc': temp_nc, 'crs_text': ''}])\n",
    "\n",
    "    #func: remove nodatavals attribute\n",
    "    #cs.append([test_funcs.remove_nodatavals_attr, {'in_nc': temp_nc}])\n",
    "    \n",
    "    return cs\n",
    "\n",
    "nc_corruptors = build_nc_corruptors(temp_nc=temp_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test One: Wet Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_test_one_funcs(in_nc, temp_nc):\n",
    "    \"\"\"sets up test one functions\"\"\"\n",
    "    \n",
    "    # set default params for tool\n",
    "    params = {\n",
    "        'in_nc_file': '',                         # input nc (i.e. temp nc)\n",
    "        'out_likelihood_nc_file': '',             # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '',                      # wet months \n",
    "        'in_dry_months': '9;10;11',               # dry months \n",
    "        'in_veg_idx': 'MAVI',                     # vege index name\n",
    "        'in_mst_idx': 'NDMI',                     # moisture index name       \n",
    "        'in_zscore_pvalue': None,                 # zscore pvalue\n",
    "        'in_stand_qupper': 0.99,                  # upper quantile for standardisation\n",
    "        'in_stand_qlower': 0.05,                  # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',     # fmask flag values\n",
    "        'in_max_cloud': 10,                       # max cloud percentage\n",
    "        'in_interpolate': True,                   # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,             # add result to map\n",
    "    }\n",
    "    \n",
    "    # set up list\n",
    "    ts = []\n",
    "            \n",
    "    # func: default wet months 1, 2, 3\n",
    "    msg = 'Running Test One: default wet months.'\n",
    "    params.update({'in_wet_months': '1;2;3'})\n",
    "    ts.append(['t_1_def.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])\n",
    "    \n",
    "    # func: no wet months\n",
    "    msg = 'Running Test One: \"\" wet months.'\n",
    "    params.update({'in_wet_months': ''})\n",
    "    ts.append(['t_1_a.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])\n",
    "    \n",
    "    # func: one random month\n",
    "    rand = str(random.randint(1, 5))\n",
    "    msg = 'Running Test One: single random wet month ({}).'.format(rand)\n",
    "    params.update({'in_wet_months': rand})\n",
    "    ts.append(['t_1_b.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])    \n",
    "\n",
    "    # func: three months (2, 3, 4)\n",
    "    msg = 'Running Test One: 2;3;4 as wet months.'\n",
    "    params.update({'in_wet_months': '2;3;4'})\n",
    "    ts.append(['t_1_c.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])    \n",
    "    \n",
    "    # func: all dry season months in wet season\n",
    "    msg = 'Running Test One: dry months 5;6;7;8;9 as wet months.'\n",
    "    params.update({'in_wet_months': '5;6;7;8;9'})\n",
    "    ts.append(['t_1_d.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg]) \n",
    "\n",
    "    # func: wet season includes a month in dec\n",
    "    msg = 'Running Test One: wet months contain dec (12).'\n",
    "    params.update({'in_wet_months': '12;1;2'})\n",
    "    ts.append(['t_1_e.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg]) \n",
    "    \n",
    "    # func: wet season includes only one month in dec\n",
    "    msg = 'Running Test One: single wet month in dec (12).'\n",
    "    params.update({'in_wet_months': '12'})\n",
    "    ts.append(['t_1_f.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])     \n",
    "        \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test One: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupting NetCDF via: nc_default.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "No changes, setting up for default dataset.\n",
      "Performing test: nc_default_t_1_def.nc.\n",
      "Performing test: nc_default_t_1_a.nc.\n",
      "Performing test: nc_default_t_1_b.nc.\n",
      "Performing test: nc_default_t_1_c.nc.\n",
      "Performing test: nc_default_t_1_d.nc.\n",
      "Performing test: nc_default_t_1_e.nc.\n",
      "Performing test: nc_default_t_1_f.nc.\n",
      "All tests applied to corruptor NetCDF.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build lsit of nc corruptors and tests to iterate\n",
    "nc_corrs = build_nc_corruptors(temp_nc)\n",
    "tests = build_test_one_funcs(in_nc=nc_file, temp_nc=temp_nc)\n",
    "\n",
    "# run!\n",
    "run_corruptors_through_tests(in_nc=nc_file, nc_coors=nc_corrs, tests=tests, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "scrolled": false
   },
   "source": [
    "### Test Two: Dry Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_test_two_funcs(in_nc, temp_nc):\n",
    "    \"\"\"sets up test two functions\"\"\"\n",
    "    \n",
    "    # set default params for tool\n",
    "    params = {\n",
    "        'in_nc_file': '',                         # input nc (i.e. temp nc)\n",
    "        'out_likelihood_nc_file': '',             # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',                      # wet months \n",
    "        'in_dry_months': '9;10;11',                      # dry months \n",
    "        'in_veg_idx': 'MAVI',                     # vege index name\n",
    "        'in_mst_idx': 'NDMI',                     # moisture index name       \n",
    "        'in_zscore_pvalue': None,                 # zscore pvalue\n",
    "        'in_stand_qupper': 0.99,                  # upper quantile for standardisation\n",
    "        'in_stand_qlower': 0.05,                  # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',     # fmask flag values\n",
    "        'in_max_cloud': 10,                       # max cloud percentage\n",
    "        'in_interpolate': True,                   # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,             # add result to map\n",
    "    }\n",
    "    \n",
    "    # set up list\n",
    "    ts = []\n",
    "            \n",
    "    # func: default dry months 9, 10, 11\n",
    "    msg = 'Running Test Two: default dry months.'\n",
    "    params.update({'in_dry_months': '9;10;11'})\n",
    "    print(params)\n",
    "    ts.append(['t_1_def.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])\n",
    "    \n",
    "    raise\n",
    "    \n",
    "    # func: no dry months\n",
    "    msg = 'Running Test Two: \"\" dry months.'\n",
    "    params.update({'in_dry_months': ''})\n",
    "    ts.append(['t_1_a.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])\n",
    "    \n",
    "    # func: one random month\n",
    "    rand = str(random.randint(7, 12))\n",
    "    msg = 'Running Test Two: single random dry month ({}).'.format(rand)\n",
    "    params.update({'in_dry_months': rand})\n",
    "    ts.append(['t_1_b.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])    \n",
    "\n",
    "    # func: three months (8, 9, 10)\n",
    "    msg = 'Running Test Two: 10;11;12 as dry months.'\n",
    "    params.update({'in_dry_months': '10;11;12'})\n",
    "    ts.append(['t_1_c.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg])    \n",
    "    \n",
    "    # func: all dry season months in wet season\n",
    "    msg = 'Running Test Two: dry months 1;2;3;4;5 as dry months.'\n",
    "    params.update({'in_dry_months': '1;2;3;4;5'})\n",
    "    ts.append(['t_1_d.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg]) \n",
    "\n",
    "    # func: wet season includes a month in dec\n",
    "    msg = 'Running Test Two: dry months contain one month in jan (1).'\n",
    "    params.update({'in_dry_months': '11;12;1'})\n",
    "    ts.append(['t_1_e.nc', arcpy.GDVSpectra_Likelihood_toolbox , params, msg]) \n",
    "        \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Two: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_nc_file': '', 'out_likelihood_nc_file': '', 'in_wet_months': '1;2;3', 'in_dry_months': '9;10;11', 'in_veg_idx': 'MAVI', 'in_mst_idx': 'NDMI', 'in_zscore_pvalue': None, 'in_stand_qupper': 0.99, 'in_stand_qlower': 0.05, 'in_fmask_flags': 'Valid;Snow;Water', 'in_max_cloud': 10, 'in_interpolate': True, 'in_add_result_to_map': True}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[29]\u001b[0m:\nLine \u001b[0;34m3\u001b[0m:     tests = build_test_two_funcs(in_nc=nc_file, temp_nc=temp_nc)\n",
      "In  \u001b[0;34m[27]\u001b[0m:\nLine \u001b[0;34m30\u001b[0m:    \u001b[34mraise\u001b[39;49;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# build lsit of nc corruptors and tests to iterate\n",
    "nc_corrs = build_nc_corruptors(temp_nc)\n",
    "tests = build_test_two_funcs(in_nc=nc_file, temp_nc=temp_nc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupting NetCDF via: nc_default.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Duplicating cube: E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\n",
      "No changes, setting up for default dataset.\n",
      "{'in_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\inputs\\\\temp_nc.nc', 'out_likelihood_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\outputs\\\\nc_default_t_1_def.nc', 'in_wet_months': '1;2;3', 'in_dry_months': '11;12;1', 'in_veg_idx': 'MAVI', 'in_mst_idx': 'NDMI', 'in_zscore_pvalue': None, 'in_stand_qupper': 0.99, 'in_stand_qlower': 0.05, 'in_fmask_flags': 'Valid;Snow;Water', 'in_max_cloud': 10, 'in_interpolate': True, 'in_add_result_to_map': True}\n",
      "Performing test: nc_default_t_1_def.nc.\n",
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "{'in_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\inputs\\\\temp_nc.nc', 'out_likelihood_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\outputs\\\\nc_default_t_1_a.nc', 'in_wet_months': '1;2;3', 'in_dry_months': '11;12;1', 'in_veg_idx': 'MAVI', 'in_mst_idx': 'NDMI', 'in_zscore_pvalue': None, 'in_stand_qupper': 0.99, 'in_stand_qlower': 0.05, 'in_fmask_flags': 'Valid;Snow;Water', 'in_max_cloud': 10, 'in_interpolate': True, 'in_add_result_to_map': True}\n",
      "Performing test: nc_default_t_1_a.nc.\n",
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "{'in_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\inputs\\\\temp_nc.nc', 'out_likelihood_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\outputs\\\\nc_default_t_1_b.nc', 'in_wet_months': '1;2;3', 'in_dry_months': '11;12;1', 'in_veg_idx': 'MAVI', 'in_mst_idx': 'NDMI', 'in_zscore_pvalue': None, 'in_stand_qupper': 0.99, 'in_stand_qlower': 0.05, 'in_fmask_flags': 'Valid;Snow;Water', 'in_max_cloud': 10, 'in_interpolate': True, 'in_add_result_to_map': True}\n",
      "Performing test: nc_default_t_1_b.nc.\n",
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "{'in_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\inputs\\\\temp_nc.nc', 'out_likelihood_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\outputs\\\\nc_default_t_1_c.nc', 'in_wet_months': '1;2;3', 'in_dry_months': '11;12;1', 'in_veg_idx': 'MAVI', 'in_mst_idx': 'NDMI', 'in_zscore_pvalue': None, 'in_stand_qupper': 0.99, 'in_stand_qlower': 0.05, 'in_fmask_flags': 'Valid;Snow;Water', 'in_max_cloud': 10, 'in_interpolate': True, 'in_add_result_to_map': True}\n",
      "Performing test: nc_default_t_1_c.nc.\n",
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "{'in_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\inputs\\\\temp_nc.nc', 'out_likelihood_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\outputs\\\\nc_default_t_1_d.nc', 'in_wet_months': '1;2;3', 'in_dry_months': '11;12;1', 'in_veg_idx': 'MAVI', 'in_mst_idx': 'NDMI', 'in_zscore_pvalue': None, 'in_stand_qupper': 0.99, 'in_stand_qlower': 0.05, 'in_fmask_flags': 'Valid;Snow;Water', 'in_max_cloud': 10, 'in_interpolate': True, 'in_add_result_to_map': True}\n",
      "Performing test: nc_default_t_1_d.nc.\n",
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "{'in_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\inputs\\\\temp_nc.nc', 'out_likelihood_nc_file': 'E:\\\\Curtin\\\\GDVII - General\\\\Work Package 2\\\\test_data\\\\gdvspectra_likelihood\\\\outputs\\\\nc_default_t_1_e.nc', 'in_wet_months': '1;2;3', 'in_dry_months': '11;12;1', 'in_veg_idx': 'MAVI', 'in_mst_idx': 'NDMI', 'in_zscore_pvalue': None, 'in_stand_qupper': 0.99, 'in_stand_qlower': 0.05, 'in_fmask_flags': 'Valid;Snow;Water', 'in_max_cloud': 10, 'in_interpolate': True, 'in_add_result_to_map': True}\n",
      "Performing test: nc_default_t_1_e.nc.\n",
      "Cannot use same value for wet and dry months.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "All tests applied to corruptor NetCDF.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run!\n",
    "run_corruptors_through_tests(in_nc=nc_file, nc_coors=nc_corrs, tests=tests, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Three: Vegetation Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_three_veg_idx(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the veg idx input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',          # dry months \n",
    "        'in_veg_idx': '',                      # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't3{}_{}.nc')\n",
    "            \n",
    "    try:\n",
    "        print('\\n\\nRunning t3default (test three default). Veg Idx input is \"MAVI\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_veg_idx': 'MAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3a (test three a). Veg Idx input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_veg_idx': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3b (test three b). Veg Idx input is NDVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_veg_idx': 'NDVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3c (test three c). Veg Idx input is EVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_veg_idx': 'EVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3d (test three d). Veg Idx input is SAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_veg_idx': 'SAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t3e (test three e). Veg Idx input is MSAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_veg_idx': 'MSAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3f (test three f). Veg Idx input is SLAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_veg_idx': 'SLAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3g (test three g). Veg Idx input is MAVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_veg_idx': 'MAVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3h (test three h). Veg Idx input is kNDVI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('h', out_func_name), 'in_veg_idx': 'kNDVI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3i (test three i). Veg Idx input is TCG.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('i', out_func_name), 'in_veg_idx': 'TCG'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t3j (test three j). Veg Idx input does not exist (NRVA).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('j', out_func_name), 'in_veg_idx': 'NRVA'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def perform_test_three(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test three.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_three_veg_idx(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Three: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running all data corruption functions through test three (veg idx).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "Running data corruption function: remove_nodatavals_attr\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Help on function remove_nodatavals_attr in module test_funcs:\n",
      "\n",
      "remove_nodatavals_attr(in_nc)\n",
      "    strip nodatavals attribute from nc\n",
      "\n",
      "With parameter: in_nc of value: E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\temp_nc.nc\n",
      "\n",
      "Beginning test.\n",
      "Duplicating cube: E:\\Curtin\\GDVII - General\\Work Package 2\\test_data\\gdvspectra_likelihood\\inputs\\yandi_2_ls_90_20_raw_odc.nc\n",
      "Stripping nodatavals attribute from nc dim\n",
      "\n",
      "\n",
      "Running t3a (test three a). Veg Idx input is \"\".\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3b (test three b). Veg Idx input is NDVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3c (test three c). Veg Idx input is EVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3d (test three d). Veg Idx input is SAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3e (test three e). Veg Idx input is MSAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3f (test three f). Veg Idx input is SLAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3g (test three g). Veg Idx input is MAVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3h (test three h). Veg Idx input is kNDVI.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3i (test three i). Veg Idx input is TCG.\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 2045, in execute\n",
      "RuntimeError: No active exception to reraise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF nodatavals attribute not found.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "\n",
      "\n",
      "Running t3j (test three j). Veg Idx input does not exist (NRVA).\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Failed to execute. Parameters are not valid.\n",
      "ERROR 000800: The value is not a member of NDVI | EVI | SAVI | MSAVI | SLAVI | MAVI | kNDVI | TCG.\n",
      "Failed to execute (GDVSpectra_Likelihood).\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run test three\n",
    "perform_test_three(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Four: Moisture Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_four_mst_idx(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the mst idx input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': '',                      # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't4{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t4default (test four default). Mst Idx input is \"NDMI\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_mst_idx': 'NDMI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t4a (test four a). Mst Idx input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_mst_idx': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t4b (test four b). Mst Idx input is NDMI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_mst_idx': 'NDMI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t4c (test four c). Mst Idx input is GVMI.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_mst_idx': 'GVMI'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t4d (test four d). Mst Idx input does not exist (MRVA).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_mst_idx': 'MRVA'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def perform_test_four(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test four.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_four_mst_idx(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Four: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test four\n",
    "perform_test_four(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Five: Outlier Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_five_outlier(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the outlier correction input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': '',                # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't5{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5default (test five default). Outlier correction input is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_zscore_pvalue': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t5a (test five a). Outlier correction input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_zscore_pvalue': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5b (test five b). Outlier correction input is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_zscore_pvalue': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5c (test five c). Outlier correction input is string of 0.01.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_zscore_pvalue': '0.01'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t5d (test five d). Outlier correction input is string of 0.05.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_zscore_pvalue': '0.05'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "             \n",
    "    try:\n",
    "        print('\\n\\nRunning t5e (test five e). Outlier correction input is string of 0.1.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_zscore_pvalue': '0.1'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5f (test five f). Outlier correction input is string of 1.0 (not supported).')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_zscore_pvalue': '1.0'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)      \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t5g (test five g). Outlier correction input is float of 0.01.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_zscore_pvalue': 0.01})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t5h (test five h). Outlier correction input is int of 1.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('h', out_func_name), 'in_zscore_pvalue': 1})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "        \n",
    "def perform_test_five(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test five.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_five_outlier(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Five: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test five\n",
    "perform_test_five(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Six: IVT Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_six_ivt_standardisation(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the ivt standardisation input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': '',                   # upper quantile for standardisation\n",
    "        'in_ivt_qlower': '',                   # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't6{}_{}.nc')   \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t6default (test six default). IVT lower, upper input is 0.05, 0.99.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_ivt_qlower': 0.05, 'in_ivt_qupper': 0.99})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t6a (test six a). IVT lower, upper input is \"\", \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_ivt_qlower': '', 'in_ivt_qupper': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6b (test six b). IVT lower, upper input is None, ''.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_ivt_qlower': None, 'in_ivt_qupper': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6c (test six c). IVT lower, upper input is 0.0, 0.99.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_ivt_qlower': 0.0, 'in_ivt_qupper': 0.99})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6d (test six d). IVT lower, upper input is 0.05, 0.0.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_ivt_qlower': 0.05, 'in_ivt_qupper': 0.0})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)               \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t6e (test six e). IVT lower, upper input is 0.25, 0.80.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_ivt_qlower': 0.25, 'in_ivt_qupper': 0.80})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6f (test six f). IVT lower, upper input is 0.4, 0.6.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_ivt_qlower': 0.4, 'in_ivt_qupper': 0.6})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)          \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t6g (test six g). IVT lower, upper input is 0.6, 0.4.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_ivt_qlower': 0.6, 'in_ivt_qupper': 0.4})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6h (test six h). IVT lower, upper input is 0.2, 1.4.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('h', out_func_name), 'in_ivt_qlower': 0.2, 'in_ivt_qupper': 1.4})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6i (test six i). IVT lower, upper input is 0.5, 0.5.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('i', out_func_name), 'in_ivt_qlower': 0.5, 'in_ivt_qupper': 0.5})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t6j (test six j). IVT lower, upper input is \"0.2\", \"0.8\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('j', out_func_name), 'in_ivt_qlower': \"0.2\", 'in_ivt_qupper': \"0.8\"})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)          \n",
    "    \n",
    "        \n",
    "def perform_test_six(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test six.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_six_ivt_standardisation(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Six: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test six\n",
    "perform_test_six(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Seven: Pixel Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_seven_pixel_flags(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the pixel flag input\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': '',                  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't7{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7default (test seven default). pixel flag input is \"Valid;Snow;Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_fmask_flags': 'Valid;Snow;Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t7a (test seven a). pixel flag input is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_fmask_flags': ''})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t7b (test seven b). pixel flag input is \"NoData;Valid;Cloud;Shadow;Snow;Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_fmask_flags': 'NoData;Valid;Cloud;Shadow;Snow;Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7c (test seven c). pixel flag input is \"Valid\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_fmask_flags': 'Valid'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t7d (test seven d). pixel flag input is \"Cloud;Shadow\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_fmask_flags': 'Cloud;Shadow'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        print('\\n\\nRunning t7e (test seven e). pixel flag input is \"Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_fmask_flags': 'Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7f (test seven f). pixel flag input is \"Water;Water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_fmask_flags': 'Water;Water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t7g (test seven g). pixel flag input is \"water\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_fmask_flags': 'water'})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "        \n",
    "def perform_test_seven(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test seven.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_seven_pixel_flags(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Seven: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test seven\n",
    "perform_test_seven(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Eight: Max Cloud Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_eight_max_cloud_cover(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the max cloud cover\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': '',                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't8{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8default (test eight default). max cloud cover is 10.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_max_cloud': 10})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t8a (test eight a). max cloud cover is 0.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_max_cloud': 0})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8b (test eight b). max cloud cover is 100.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_max_cloud': 10})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8c (test eight c). max cloud cover is 50.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('c', out_func_name), 'in_max_cloud': 50})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8d (test eight d). max cloud cover is \"10\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('d', out_func_name), 'in_max_cloud': \"10\"})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8e (test eight e). max cloud cover is 150.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('e', out_func_name), 'in_max_cloud': 150})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8f (test eight f). max cloud cover is \"\".')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('f', out_func_name), 'in_max_cloud': \"\"})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)     \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t8g (test eight g). max cloud cover is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('g', out_func_name), 'in_max_cloud': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "    \n",
    "def perform_test_eight(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test eight.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_eight_max_cloud_cover(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Eight: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test eight\n",
    "perform_test_eight(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Nine: Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_nine_interpolate(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the interpolate\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': '',                # interpolate missing pixels\n",
    "        'in_add_result_to_map': True,          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't9{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t9default (test nine default). interpolate is True.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_interpolate': True})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t9a (test nine a). interpolate is False.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_interpolate': False})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t9b (test nine b). interpolate is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_interpolate': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "    \n",
    "def perform_test_nine(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test nine.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_nine_interpolate(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Nine: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test nine\n",
    "perform_test_nine(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Ten: Add To Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _test_ten_add_to_map(in_nc, out_func_name='default'):\n",
    "    \"\"\"tests different set ups of the add output to map\"\"\"\n",
    "\n",
    "    # set default params for tool\n",
    "    inputs = {\n",
    "        'in_nc': in_nc,                        # input nc (i.e. temp nc)\n",
    "        'out_nc': '',                          # output nc (i.e. t1a nc)\n",
    "        'in_wet_months': '1;2;3',              # wet months \n",
    "        'in_dry_months': '9;10;11',            # dry months \n",
    "        'in_veg_idx': 'MAVI',                  # vege index name\n",
    "        'in_mst_idx': 'NDMI',                  # moisture index name       \n",
    "        'in_zscore_pvalue': None,              # zscore pvalue\n",
    "        'in_ivt_qupper': 0.99,                 # upper quantile for standardisation\n",
    "        'in_ivt_qlower': 0.05,                 # lower quantile for standardisation\n",
    "        'in_fmask_flags': 'Valid;Snow;Water',  # fmask flag values\n",
    "        'in_max_cloud': 10,                    # max cloud percentage\n",
    "        'in_interpolate': True,                # interpolate missing pixels\n",
    "        'in_add_result_to_map': '',          # add result to map\n",
    "    }\n",
    "    \n",
    "    # set output test string convention\n",
    "    out_nc = os.path.join(output_folder, 't10{}_{}.nc')\n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t10default (test ten default). in_add_result_to_map is True.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('default', out_func_name), 'in_add_result_to_map': True})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    \n",
    "    try:\n",
    "        print('\\n\\nRunning t10a (test ten a). add result to_map is False.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('a', out_func_name), 'in_add_result_to_map': False})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "    try:\n",
    "        print('\\n\\nRunning t10b (test ten b). add result to_map is None.')\n",
    "        print('- ' * 50)\n",
    "        inputs.update({'out_nc': out_nc.format('b', out_func_name), 'in_add_result_to_map': None})\n",
    "        arcpy.GDVSpectra_Likelihood_toolbox(*list(inputs.values()))\n",
    "    except Exception as e:\n",
    "        print(e)       \n",
    "    \n",
    "def perform_test_ten(in_nc, temp_nc, nc_corruption_funcs):\n",
    "    \"\"\"iterates corrupt ncs and runs through parameter tests\"\"\"\n",
    "\n",
    "    print('\\nRunning all data corruption functions through test ten.')\n",
    "    print('- ' * 50)\n",
    "\n",
    "    # iterate different dataset corruptors and feed each into test func\n",
    "    for func in nc_corruption_funcs:\n",
    "\n",
    "        # get func name and notify\n",
    "        print('\\nRunning data corruption function: {}'.format(func['func'].__name__))\n",
    "        print('- ' * 50)\n",
    "        help(func['func'])\n",
    "\n",
    "        # make new instance of func dict so we dont destroy keys\n",
    "        func_copy = func.copy()\n",
    "\n",
    "        # get parameter names and entered value\n",
    "        params, inputs = [], []\n",
    "        for k, v in func_copy.items():\n",
    "            if k != 'func':\n",
    "                print('With parameter: {} of value: {}'.format(k, v))\n",
    "\n",
    "        # start the test\n",
    "        print('\\nBeginning test.')\n",
    "\n",
    "        # duplicate raw netcdf for testing\n",
    "        test_funcs.create_temp_nc(in_nc=in_nc, out_nc=temp_nc)\n",
    "\n",
    "        # prepare current function with associated parameters and run\n",
    "        f = func_copy['func']  # get func only\n",
    "        func_copy.pop('func')  # get params only\n",
    "        f(**func_copy)         # run func\n",
    "\n",
    "        # test current corrupted netcdf\n",
    "        _test_ten_add_to_map(temp_nc, out_func_name=str(func['func'].__name__))\n",
    "\n",
    "        # add some space to print out\n",
    "        print('- ' * 50)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test Ten: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run test ten\n",
    "perform_test_ten(in_nc=nc_file, temp_nc=temp_nc, nc_corruption_funcs=nc_corruptors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
