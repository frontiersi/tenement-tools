{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals (dev)\n",
    "FOLDER_MODULES = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "GRP_LYR_FILE = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx\"\n",
    "\n",
    "# set gdal global environ\n",
    "import os\n",
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN'] = 'EMPTY_DIR'\n",
    "os.environ['CPL_VSIL_CURL_ALLOWED_EXTENSIONS '] = 'tif'\n",
    "os.environ['VSI_CACHE '] = 'TRUE'\n",
    "os.environ['GDAL_HTTP_MULTIRANGE '] = 'YES'\n",
    "os.environ['GDAL_HTTP_MERGE_CONSECUTIVE_RANGES '] = 'YES'\n",
    "\n",
    "# also set rasterio env variables\n",
    "rasterio_env = {\n",
    "    'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n",
    "    'CPL_VSIL_CURL_ALLOWED_EXTENSIONS': 'tif',\n",
    "    'VSI_CACHE': True,\n",
    "    'GDAL_HTTP_MULTIRANGE': 'YES',\n",
    "    'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES'\n",
    "}\n",
    "\n",
    "# disable future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# safe imports\n",
    "import sys                  # arcgis comes with these\n",
    "import datetime                 # arcgis comes with these\n",
    "import numpy as np              # arcgis comes with these\n",
    "import arcpy                    # arcgis comes with these\n",
    "from datetime import datetime   # arcgis comes with these\n",
    "\n",
    "# risky imports (not native to arcgis)\n",
    "try:\n",
    "    from osgeo import gdal\n",
    "    from osgeo import ogr\n",
    "    import tempfile\n",
    "    import xarray as xr\n",
    "    import dask\n",
    "    import rasterio\n",
    "    import pystac_client\n",
    "    from odc import stac\n",
    "except:\n",
    "    arcpy.AddError('Python libraries xarray, dask, rasterio, pystac, or odc not installed.')\n",
    "    raise\n",
    "\n",
    "# import tools\n",
    "try:\n",
    "    # shared folder\n",
    "    sys.path.append(FOLDER_SHARED)\n",
    "    import arc, satfetcher, tools\n",
    "\n",
    "    # module folder\n",
    "    sys.path.append(FOLDER_MODULES)\n",
    "    import nrt, cog_odc, cog\n",
    "except:\n",
    "    arcpy.AddError('Could not find tenement tools python scripts (modules, shared).')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'toolbox'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import arcpy\n",
    "\n",
    "tbx = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\"\n",
    "arcpy.ImportToolbox(tbx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need button to create shapefile with relevent attributes\n",
    "# set a folder\n",
    "# create a shapefile of polygons\n",
    "# need a id field, out netcdf, platform, start/end monitor date, other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create monitoring areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new monitoring project database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 7225, in execute\n",
      "  File \"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules\\nrt.py\", line 65, in create_nrt_project\n",
      "    raise ValueError('Requested file location arleady exists. Choose a different name.')\n",
      "ValueError: Requested file location arleady exists. Choose a different name.\n"
     ]
    },
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 000582: Error occurred during execution.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[5]\u001b[0m:\nLine \u001b[0;34m5\u001b[0m:     arcpy.NRT_Create_Project_toolbox(out_folder, out_filename)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\u001b[0m, in \u001b[0;32mNRT_Create_Project\u001b[0m:\nLine \u001b[0;34m718\u001b[0m:   multiValue=\u001b[34mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\u001b[0m, in \u001b[0;32mNRT_Create_Project\u001b[0m:\nLine \u001b[0;34m715\u001b[0m:   parameterType=\u001b[33m'\u001b[39;49;00m\u001b[33mRequired\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: ERROR 000582: Error occurred during execution.\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "out_folder = r'C:\\Users\\Lewis\\Desktop\\nrt_projects'\n",
    "out_filename = 'ophthalmia_monitoring'\n",
    "\n",
    "# create a new nrt project\n",
    "arcpy.NRT_Create_Project_toolbox(out_folder, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make monitoring areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is up to user using usual arcgis pro tools?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate monitoring areas and update cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syncing cube for monitoring area: C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A001.nc\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n",
      "A total of 1 scenes were found.\n",
      "Replacing url prefix: s3://dea-public-data with https://data.dea.ga.gov.au\n",
      "Converting raw STAC data into xarray dataset via odc-stac.\n",
      "Created xarray dataset via odc-stac successfully.\n",
      "Exporting xarray as netcdf file.\n",
      "Exported xarray as netcdf successfully.\n",
      "Syncing cube for monitoring area: C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A002.nc\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n",
      "A total of 1 scenes were found.\n",
      "Replacing url prefix: s3://dea-public-data with https://data.dea.ga.gov.au\n",
      "Converting raw STAC data into xarray dataset via odc-stac.\n",
      "Created xarray dataset via odc-stac successfully.\n",
      "Exporting xarray as netcdf file.\n",
      "Exported xarray as netcdf successfully.\n",
      "Syncing cube for monitoring area: C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A003.nc\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n",
      "A total of 1 scenes were found.\n",
      "Replacing url prefix: s3://dea-public-data with https://data.dea.ga.gov.au\n",
      "Converting raw STAC data into xarray dataset via odc-stac.\n",
      "Created xarray dataset via odc-stac successfully.\n",
      "Exporting xarray as netcdf file.\n",
      "Exported xarray as netcdf successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Output</h2><h2>Messages</h2>Start Time: Monday, 10 January 2022 5:37:46 PM<br/>Beginning NRT Sync Cube...<br/>Validating monitoring area: A001<br/>Preparing monitoring area: A001<br/>Syncing monitoring area: A001<br/>Validating monitoring area: A002<br/>Preparing monitoring area: A002<br/>Syncing monitoring area: A002<br/>Validating monitoring area: A003<br/>Preparing monitoring area: A003<br/>Syncing monitoring area: A003<br/>Monitoring areas synced successfully.<br/>Succeeded at Monday, 10 January 2022 5:37:56 PM (Elapsed Time: 9.88 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result ''>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform sync\n",
    "in_feat = r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas'\n",
    "\n",
    "# create a new nrt project\n",
    "arcpy.NRT_Sync_Cube_toolbox(in_feat=in_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp inputs\n",
    "in_fmask_flags = 'Valid;Snow;Water'\n",
    "in_max_cloud = 0\n",
    "in_veg_idx = 'MAVI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR NRT_Detect_Change\n",
    "def execute(in_feat, in_fmask_flags, in_max_cloud=0, in_veg_idx='MAVI', ewmacd_method='dynamic', keep_running=False, time_interval=43200):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        \n",
    "    # grab parameter values \n",
    "    #in_feat = parameters[0]        # input monitoring area features\n",
    "    \n",
    "    \n",
    "    # # # # #\n",
    "    # notify user and set up progress bar\n",
    "    arcpy.AddMessage('Beginning NRT change detection...')\n",
    "    arcpy.SetProgressor(type='step', \n",
    "                        message='Preparing parameters...', \n",
    "                        min_range=0, max_range=3)\n",
    "            \n",
    "    # prepare features shapefile\n",
    "    shp_desc = arcpy.Describe(in_feat)\n",
    "    in_feat = os.path.join(shp_desc.path, shp_desc.name)\n",
    "    \n",
    "    # validate monitoring area feature class\n",
    "    if not nrt.validate_monitoring_areas(in_feat):\n",
    "        arcpy.AddError('Monitoring areas feature is invalid.')\n",
    "        raise\n",
    "    \n",
    "    # get input featureclass file, get dir and filename\n",
    "    in_name = os.path.basename(in_feat)     # name of monitor fc\n",
    "    in_gdb = os.path.dirname(in_feat)       # path of gdb\n",
    "\n",
    "    # check gdv extension\n",
    "    if not in_gdb.endswith('.gdb'):\n",
    "        arcpy.AddError('Feature class is not in a geodatabase.')\n",
    "        raise\n",
    "    else:\n",
    "        in_path = os.path.splitext(in_gdb)[0]   # path of gdb without ext\n",
    "        in_data_path = in_path + '_' + 'cubes'  # associated cube data folder\n",
    "\n",
    "    # check if cubes folder exists\n",
    "    if not os.path.exists(in_data_path):\n",
    "        arcpy.AddError('Could not find cube folder for selected monitoring areas.')\n",
    "        raise    \n",
    "        \n",
    "    # convert fmask flags as text to numeric code equivalents\n",
    "    in_fmask_flags = [e for e in in_fmask_flags.split(';')]\n",
    "    in_fmask_flags = arc.convert_fmask_codes(in_fmask_flags)\n",
    "    \n",
    "    # check if cloud cover is valid\n",
    "    if in_max_cloud < 0 or in_max_cloud > 100:\n",
    "        arcpy.AddError('Cloud cover must be between 0 and 100.')\n",
    "        raise\n",
    "        \n",
    "    # check if time interval is > 0\n",
    "    if not time_interval > 0:\n",
    "        arcpy.AddError('Time interval must be above 0 seconds.')\n",
    "        raise\n",
    "        \n",
    "    # check edyn type\n",
    "    if ewmacd_method not in ['dynamic', 'static']:\n",
    "        arcpy.AddError('EWMACD method can only be dynamic or static.')\n",
    "        raise\n",
    "        \n",
    "        \n",
    "    # todo count num feats in fc for progressor \n",
    "    #\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Iterating through monitoring areas...')\n",
    "    arcpy.SetProgressorPosition(1)\n",
    "        \n",
    "    # get features (will always have at least one, as we validated earlier)\n",
    "    driver = ogr.GetDriverByName(\"OpenFileGDB\")\n",
    "    data_source = driver.Open(os.path.dirname(in_feat), 0)\n",
    "    feats = data_source.GetLayer('monitoring_areas')\n",
    "    \n",
    "    # begin processing\n",
    "    monitoring = True\n",
    "    while monitoring:\n",
    "        \n",
    "        # iterate through each polygon\n",
    "        for feat in feats:\n",
    "\n",
    "            # # # # #\n",
    "            # notify\n",
    "            arcpy.AddMessage('Validating monitoring area: {}'.format(feat['area_id']))\n",
    "\n",
    "            # send off to check if valid\n",
    "            is_valid = nrt.validate_monitoring_area(area_id=feat['area_id'],\n",
    "                                                    platform=feat['platform'], \n",
    "                                                    s_year=feat['s_year'], \n",
    "                                                    e_year=feat['e_year'], \n",
    "                                                    index=feat['index'])\n",
    "\n",
    "            # check if monitoring area is valid\n",
    "            if not is_valid:\n",
    "                arcpy.AddWarning('Invalid monitoring area: {}, skipping.'.format(feat['area_id']))\n",
    "                continue\n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify\n",
    "            arcpy.AddMessage('Opening cube for monitoring area: {}'.format(feat['area_id']))\n",
    "\n",
    "            # set existing nc path and open if exists\n",
    "            out_nc = os.path.join(in_data_path, 'cube' + '_' + feat['area_id'] + '.nc')\n",
    "            if os.path.exists(out_nc):\n",
    "                try:\n",
    "                    ds_existing = xr.open_dataset(out_nc)                   \n",
    "                except:\n",
    "                    arcpy.AddWarning('Could not open existing cube, skipping.')\n",
    "                    continue\n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify\n",
    "            arcpy.AddMessage('Preparing cube for monitoring area: {}'.format(feat['area_id']))\n",
    "\n",
    "            # check xr type, dims, num time\n",
    "            if not isinstance(ds_existing, xr.Dataset):\n",
    "                arcpy.AddWarning('NetCDF is not not an xarray dataset type, skipping.')\n",
    "                continue\n",
    "            elif 'x' not in list(ds_existing.dims) or 'y' not in list(ds_existing.dims):\n",
    "                arcpy.AddWarning('No x or y dimension in dataset, skipping.')\n",
    "                continue\n",
    "            elif 'time' not in list(ds_existing.dims):\n",
    "                arcpy.AddWarning('No time dimension in dataset, skipping.')\n",
    "                continue\n",
    "\n",
    "            # get dataset and band attributes\n",
    "            ds_attrs = ds_existing.attrs\n",
    "            ds_band_attrs = ds_existing[list(ds_existing.data_vars)[0]].attrs\n",
    "            ds_spatial_ref_attrs = ds_existing['spatial_ref'].attrs    \n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify\n",
    "            #arcpy.SetProgressorLabel('Removing invalid pixels and empty dates...')\n",
    "            #arcpy.SetProgressorPosition(3)\n",
    "\n",
    "            # check if expected band name exists\n",
    "            mask_band = arc.get_name_of_mask_band(list(ds_existing.data_vars))\n",
    "\n",
    "            # remove invalid pixels and empty scenes\n",
    "            ds_existing = cog.remove_fmask_dates(ds=ds_existing, \n",
    "                                                 valid_class=in_fmask_flags, \n",
    "                                                 max_invalid=in_max_cloud, \n",
    "                                                 mask_band=mask_band, \n",
    "                                                 nodata_value=np.nan, \n",
    "                                                 drop_fmask=True)\n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify and increment progess bar\n",
    "            #arcpy.SetProgressorLabel('Calculating vegetation index...')\n",
    "            #arcpy.SetProgressorPosition(4)\n",
    "\n",
    "            # conform dea aws band names based on platform\n",
    "            ds_existing = satfetcher.conform_dea_ard_band_names(ds=ds_existing, \n",
    "                                                                platform=feat['platform'].lower()) \n",
    "\n",
    "            # calculate vegetation index \n",
    "            ds_existing = tools.calculate_indices(ds=ds_existing, \n",
    "                                                  index=in_veg_idx.lower(), \n",
    "                                                  custom_name='veg_idx', \n",
    "                                                  rescale=False, \n",
    "                                                  drop=True)\n",
    "\n",
    "            # append original attributes on to new band\n",
    "            ds_existing['veg_idx'].attrs = ds_band_attrs\n",
    "\n",
    "            # see phenolopy for resample, edge effects, etc\n",
    "            # todo!\n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify and increment progess bar\n",
    "            #arcpy.SetProgressorLabel('Masking out edge pixels...')\n",
    "            #arcpy.SetProgressorPosition(4)\n",
    "\n",
    "            # convert feature to layer and use to mask\n",
    "            geom = ogr.Open(feat.ExportToJson(), 0)\n",
    "            lyr = geom.GetLayer()\n",
    "            mask = nrt.mask_xr_via_polygon(geom=lyr, \n",
    "                                           x=ds_existing['x'].data, \n",
    "                                           y=ds_existing['y'].data, \n",
    "                                           bbox=ds_existing.geobox.extent.boundingbox, \n",
    "                                           transform=ds_existing.geobox.transform, \n",
    "                                           ncols=len(ds_existing['x']), \n",
    "                                           nrows=len(ds_existing['y']), \n",
    "                                           mask_value=1)\n",
    "\n",
    "            # apply mask to current dataset, set everything outside to nan\n",
    "            ds_existing = ds_existing.where(mask)\n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify and increment progess bar\n",
    "            #arcpy.SetProgressorLabel('Preparing cubve for change detection...')\n",
    "            #arcpy.SetProgressorPosition(4)      \n",
    "\n",
    "            # sumamrise each image to 1 median\n",
    "            ds_summary = ds_existing.median(['x', 'y'])\n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify and increment progess bar\n",
    "            #arcpy.SetProgressorLabel('Performing NRT change detection...')\n",
    "            #arcpy.SetProgressorPosition(4)   \n",
    "\n",
    "            # apply ewmacd function\n",
    "            ds_change = nrt.EWMACD(ds=ds_summary, \n",
    "                                   trainingPeriod=ewmacd_method)\n",
    "\n",
    "\n",
    "            # # # # #\n",
    "            # notify and increment progess bar\n",
    "            #arcpy.SetProgressorLabel('Building output change detection cube...')\n",
    "            #arcpy.SetProgressorPosition(4)   \n",
    "\n",
    "            # broadcast median cube onto pixel cubes to steal median cube values\n",
    "            ds_summary, _ = xr.broadcast(ds_summary, ds_existing)   # want same median value for every pixel per image\n",
    "            ds_change, _ = xr.broadcast(ds_change, ds_existing)   # want same change value for every pixel per image\n",
    "\n",
    "            # ensure dimensions in original order\n",
    "            ds_summary = ds_summary.transpose('time', 'y', 'x')\n",
    "            ds_change = ds_change.transpose('time', 'y', 'x')\n",
    "\n",
    "            # re mask summary and change cubes as nan pixels now set to non-nan\n",
    "            ds_summary = ds_summary.where(mask)\n",
    "            ds_change = ds_change.where(mask)\n",
    "            \n",
    "            # append attributes back on\n",
    "            ds_summary.attrs = ds_attrs\n",
    "            ds_summary['spatial_ref'].attrs = ds_spatial_ref_attrs\n",
    "            for var in list(ds_summary.data_vars):\n",
    "                ds_summary[var].attrs = ds_band_attrs\n",
    "                \n",
    "            ds_change.attrs = ds_attrs\n",
    "            ds_change['spatial_ref'].attrs = ds_spatial_ref_attrs\n",
    "            for var in list(ds_change.data_vars):\n",
    "                ds_change[var].attrs = ds_band_attrs\n",
    "            \n",
    "            ds_summary.to_netcdf(r'C:\\Users\\Lewis\\Desktop\\testing ds\\ds_summary_{}_static.nc'.format(feat['area_id']))\n",
    "            ds_change.to_netcdf(r'C:\\Users\\Lewis\\Desktop\\testing ds\\ds_change_{}_static.nc'.format(feat['area_id']))\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            print()\n",
    "            print(ds_summary)\n",
    "            print()\n",
    "            print(ds_change)\n",
    "            print()\n",
    "            \n",
    "            \n",
    "\n",
    "            # close and delete everything\n",
    "            mask = None\n",
    "            ds_existing.close()\n",
    "            ds_change.close()\n",
    "            ds_summary.close()\n",
    "            \n",
    "            del ds_existing\n",
    "            del ds_change\n",
    "            del ds_summary\n",
    "            \n",
    "            # do flag system\n",
    "            # draw results on screen\n",
    "            # send email if flagged\n",
    "\n",
    "            \n",
    "        # set processing to false if not requested to end this\n",
    "        if keep_running:\n",
    "            print('Continuous monitoring requested, hibernating for {} seconds.\\n'.format(time_interval))\n",
    "            time.sleep(time_interval)\n",
    "            \n",
    "        else:\n",
    "            print('Continuous monitoring not requested, only ran once.\\n')\n",
    "            monitoring = False\n",
    "                \n",
    "    print('Finished process!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing dates where too many invalid pixels.\n",
      "Filling invalid pixels with requested nodata value.\n",
      "Dropping mask band.\n",
      "Removed invalid images successfully.\n",
      "Conforming DEA ARD satellite band names.\n",
      "Satellite band names conformed successfully.\n",
      "Calculating indices: mavi.\n",
      "Calculating index: mavi\n",
      "Renamed default indices.\n",
      "Calculated indices successfully.\n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 324, x: 4, y: 6)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2000-02-06T01:49:38 ... 2021-12-08T01:...\n",
      "    spatial_ref  int32 3577\n",
      "  * x            (x) float64 -1.228e+06 -1.228e+06 -1.228e+06 -1.228e+06\n",
      "  * y            (y) float64 -2.572e+06 -2.572e+06 ... -2.572e+06 -2.572e+06\n",
      "Data variables:\n",
      "    veg_idx      (time, y, x) float32 nan nan nan nan ... nan 0.2749 0.2749 nan\n",
      "Attributes:\n",
      "    crs:           EPSG:3577\n",
      "    grid_mapping:  spatial_ref\n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 324, x: 4, y: 6)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2000-02-06T01:49:38 ... 2021-12-08T01:...\n",
      "    spatial_ref  int32 3577\n",
      "  * x            (x) float64 -1.228e+06 -1.228e+06 -1.228e+06 -1.228e+06\n",
      "  * y            (y) float64 -2.572e+06 -2.572e+06 ... -2.572e+06 -2.572e+06\n",
      "Data variables:\n",
      "    change       (time, y, x) float32 nan nan nan nan nan ... nan -1.0 -1.0 nan\n",
      "Attributes:\n",
      "    crs:           EPSG:3577\n",
      "    grid_mapping:  spatial_ref\n",
      "\n",
      "Removing dates where too many invalid pixels.\n",
      "Filling invalid pixels with requested nodata value.\n",
      "Dropping mask band.\n",
      "Removed invalid images successfully.\n",
      "Conforming DEA ARD satellite band names.\n",
      "Satellite band names conformed successfully.\n",
      "Calculating indices: mavi.\n",
      "Calculating index: mavi\n",
      "Renamed default indices.\n",
      "Calculated indices successfully.\n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 233, x: 5, y: 7)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2005-01-10T01:42:55 ... 2021-12-08T01:...\n",
      "    spatial_ref  int32 3577\n",
      "  * x            (x) float64 -1.228e+06 -1.228e+06 ... -1.227e+06 -1.227e+06\n",
      "  * y            (y) float64 -2.572e+06 -2.572e+06 ... -2.572e+06 -2.572e+06\n",
      "Data variables:\n",
      "    veg_idx      (time, y, x) float32 nan nan nan nan nan ... nan nan nan nan\n",
      "Attributes:\n",
      "    crs:           EPSG:3577\n",
      "    grid_mapping:  spatial_ref\n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 233, x: 5, y: 7)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2005-01-10T01:42:55 ... 2021-12-08T01:...\n",
      "    spatial_ref  int32 3577\n",
      "  * x            (x) float64 -1.228e+06 -1.228e+06 ... -1.227e+06 -1.227e+06\n",
      "  * y            (y) float64 -2.572e+06 -2.572e+06 ... -2.572e+06 -2.572e+06\n",
      "Data variables:\n",
      "    change       (time, y, x) float32 nan nan nan nan nan ... nan nan nan nan\n",
      "Attributes:\n",
      "    crs:           EPSG:3577\n",
      "    grid_mapping:  spatial_ref\n",
      "\n",
      "Removing dates where too many invalid pixels.\n",
      "Filling invalid pixels with requested nodata value.\n",
      "Dropping mask band.\n",
      "Removed invalid images successfully.\n",
      "Conforming DEA ARD satellite band names.\n",
      "Satellite band names conformed successfully.\n",
      "Calculating indices: mavi.\n",
      "Calculating index: mavi\n",
      "Renamed default indices.\n",
      "Calculated indices successfully.\n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 147, x: 7, y: 7)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2013-03-29T02:02:38 ... 2021-12-08T01:...\n",
      "    spatial_ref  int32 3577\n",
      "  * x            (x) float64 -1.228e+06 -1.228e+06 ... -1.228e+06 -1.228e+06\n",
      "  * y            (y) float64 -2.572e+06 -2.572e+06 ... -2.572e+06 -2.572e+06\n",
      "Data variables:\n",
      "    veg_idx      (time, y, x) float32 nan nan nan nan nan ... nan nan nan nan\n",
      "Attributes:\n",
      "    crs:           EPSG:3577\n",
      "    grid_mapping:  spatial_ref\n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 147, x: 7, y: 7)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2013-03-29T02:02:38 ... 2021-12-08T01:...\n",
      "    spatial_ref  int32 3577\n",
      "  * x            (x) float64 -1.228e+06 -1.228e+06 ... -1.228e+06 -1.228e+06\n",
      "  * y            (y) float64 -2.572e+06 -2.572e+06 ... -2.572e+06 -2.572e+06\n",
      "Data variables:\n",
      "    change       (time, y, x) float32 nan nan nan nan nan ... nan nan nan nan\n",
      "Attributes:\n",
      "    crs:           EPSG:3577\n",
      "    grid_mapping:  spatial_ref\n",
      "\n",
      "Continuous monitoring requested, hibernating for 30 seconds.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "In  \u001b[0;34m[7]\u001b[0m:\nLine \u001b[0;34m7\u001b[0m:     time_interval=\u001b[34m30\u001b[39;49;00m)  \u001b[37m# 43200\u001b[39;49;00m\n",
      "In  \u001b[0;34m[6]\u001b[0m:\nLine \u001b[0;34m276\u001b[0m:   time.sleep(time_interval)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: \n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "ds_summary = execute(in_feat=r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas',\n",
    "                      in_fmask_flags='Valid;Snow;Water',\n",
    "                      in_max_cloud=0, \n",
    "                      in_veg_idx='MAVI', \n",
    "                      ewmacd_method='static',\n",
    "                      keep_running=True,\n",
    "                      time_interval=30)  # 43200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, b'2.0.0 Service closing transmission channel')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import ssl\n",
    "#from smtpd import SMTPServer\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = 'mrlewie@outlook.com'\n",
    "msg['To'] = 'mrlewie@outlook.com'\n",
    "msg['Subject'] = 'New area detected'\n",
    "message = 'Yep, I found a new area'\n",
    "msg.attach(MIMEText(message))\n",
    "\n",
    "server = smtplib.SMTP('smtp.office365.com', 587) # init server\n",
    "server.ehlo()  # say hi to server\n",
    "server.starttls()  # secure email with tls encryption\n",
    "server.ehlo()  # say hi to server again\n",
    "o = server.login('mrlewie@outlook.com', 'halfLife1985micr')  # login\n",
    "\n",
    "server.sendmail('mrlewie@outlook.com', 'mrlewie@outlook.com', msg.as_string())\n",
    "\n",
    "server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emailing alert.\n",
      "Emailed alert area.\n"
     ]
    }
   ],
   "source": [
    "nrt.send_email_alert(sent_from='mrlewie@outlook.com', \n",
    "                     sent_to='mrlewie@outlook.com', \n",
    "                     subject='Area ID: 012 has been flagged.', \n",
    "                     body_text='Area ID 012 has been found to have a decline. Please check.', \n",
    "                     smtp_server='smtp.office365.com', \n",
    "                     smtp_port=587, \n",
    "                     username='mrlewie@outlook.com', \n",
    "                     password='halfLife1985micr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    # check folder exists\n",
    "    #if not os.path.exists(out_folder):\n",
    "        #raise ValueError('Requested folder does not exist.')\n",
    "        \n",
    "    # check file does not already exist\n",
    "    #if os.path.exists(out_filepath):\n",
    "        #raise ValueError('Requested file location arleady exists. Choose a different name.')\n",
    "    \n",
    "    # build project geodatbase\n",
    "    #out_filepath = arcpy.management.CreateFileGDB(out_folder, out_filename)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Generating database feature class...')\n",
    "    \n",
    "    # temporarily disable auto-visual of outputs\n",
    "    arcpy.env.addOutputsToMap = False\n",
    "    \n",
    "    # create feature class and wgs84 spatial ref sys\n",
    "    srs = arcpy.SpatialReference(4326)\n",
    "    out_feat = arcpy.management.CreateFeatureclass(out_path=out_filepath, \n",
    "                                                   out_name='monitoring_areas', \n",
    "                                                   geometry_type='POLYGON',\n",
    "                                                   spatial_reference=srs)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Generating database domains...')\n",
    "    \n",
    "    # create platform domain\n",
    "    arcpy.management.CreateDomain(in_workspace=out_filepath, \n",
    "                                  domain_name='dom_platforms', \n",
    "                                  domain_description='Platform name (Landsat or Sentinel)',\n",
    "                                  field_type='TEXT', \n",
    "                                  domain_type='CODED')\n",
    "    \n",
    "    # generate coded values to platform domain\n",
    "    dom_values = {'Landsat': 'Landsat', 'Sentinel': 'Sentinel'}\n",
    "    for dom_value in dom_values:\n",
    "        arcpy.management.AddCodedValueToDomain(in_workspace=out_filepath, \n",
    "                                               domain_name='dom_platforms', \n",
    "                                               code=dom_value, \n",
    "                                               code_description=dom_values.get(dom_value))\n",
    "\n",
    "\n",
    "    # notify\n",
    "    print('Generating database fields...') \n",
    "    \n",
    "    # add area id field to featureclass   \n",
    "    arcpy.management.AddField(in_table=out_feat, \n",
    "                              field_name='area_id', \n",
    "                              field_type='TEXT', \n",
    "                              field_alias='Area ID',\n",
    "                              field_length=200,\n",
    "                              field_is_required='REQUIRED')\n",
    "            \n",
    "    \n",
    "    # notify todo - delete if we dont want defaults\n",
    "    print('Generating database defaults...')  \n",
    "    \n",
    "    # set default platform\n",
    "    arcpy.management.AssignDefaultToField(in_table=out_feat, \n",
    "                                          field_name='platform',\n",
    "                                          default_value='Landsat')   \n",
    "           \n",
    "           \n",
    "    # notify\n",
    "    print('Creating NetCDF data folder...') \n",
    "    \n",
    "    # create output folder\n",
    "    out_nc_folder = os.path.join(out_folder, '{}_cubes'.format(out_filename))\n",
    "    if os.path.exists(out_nc_folder):\n",
    "        try:\n",
    "            shutil.rmtree(out_nc_folder)\n",
    "        except:\n",
    "            raise ValueError('Could not delete {}'.format(out_nc_folder))\n",
    "\n",
    "    # create new folder\n",
    "    os.makedirs(out_nc_folder)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Adding data to current map...') \n",
    "    \n",
    "    # enable auto-visual of outputs\n",
    "    arcpy.env.addOutputsToMap = True\n",
    "    \n",
    "    try:\n",
    "        # get active map, add feat\n",
    "        aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "        mp = aprx.activeMap\n",
    "        mp.addDataFromPath(out_feat)\n",
    "    \n",
    "    except:\n",
    "        arcpy.AddWarning('Could not find active map. Add monitor areas manually.')        \n",
    "        \n",
    "    # notify\n",
    "    print('Created new monitoring project database successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor tool\n",
    "# select shapefile\n",
    "# run checks\n",
    "# loop through each record in shapefile\n",
    "# get date time of last time\n",
    "# query stac for all dates above this\n",
    "# if new records, create new netcdf using odc-stac like func for bb, etc\n",
    "# append to existing netcdf and save\n",
    "\n",
    "# get input shapefile file, get dir and filename\n",
    "out_path = os.path.dirname(out_shp)\n",
    "out_name = os.path.basename(out_shp)\n",
    "\n",
    "fields = ['AreaID', 'NetCDF', 'Platform', 'VegIdx', 'YrStart', 'YrEnd', 'Shape@']\n",
    "with arcpy.da.UpdateCursor(out_shp, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        area_id = row[0]\n",
    "        nc = row[1]\n",
    "        platform = row[2]\n",
    "        veg_idx = row[3]\n",
    "        year_start = row[4]\n",
    "        year_end = row[5]\n",
    "        geom = row[6]\n",
    "\n",
    "        # temp\n",
    "        in_epsg = 3577\n",
    "        in_res = 30\n",
    "\n",
    "        # get as bbox\n",
    "        bbox = [geom.extent.XMin, geom.extent.YMin, \n",
    "                geom.extent.XMax, geom.extent.YMax]\n",
    "        \n",
    "        # get collections and bands based on platform\n",
    "        if platform == 'Landsat':\n",
    "            collections = ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3']\n",
    "            bands = ['nbart_red', 'nbart_green', 'nbart_blue']\n",
    "        else:\n",
    "            raise ValueError('Not yet implemented')\n",
    "\n",
    "        # if netcdf field is empty, add path to row\n",
    "        if nc == ' ' or nc == '' or nc is None:\n",
    "            \n",
    "            # notify\n",
    "            print('Querying stac for new Area ID: {}'.format(area_id))\n",
    "            \n",
    "            # update row with nc path\n",
    "            out_nc_path = os.path.join(out_path, 'area_{}.nc'.format(area_id))\n",
    "            row[1] = out_nc_path\n",
    "            \n",
    "            # get dates\n",
    "            in_from_date = '{}-01-01'.format(year_start)\n",
    "            #in_to_date = '{}-12-31'.format(datetime.now().year)  # testing\n",
    "            in_to_date = '2020-03-01'\n",
    "            \n",
    "            # notify\n",
    "            print('Getting new data for period: {} to {}'.format(in_from_date, in_to_date))\n",
    "            \n",
    "            # get me the data!\n",
    "            ds = fetch_odc_xr(collections=collections, \n",
    "                              in_from_date=in_from_date, \n",
    "                              in_to_date=in_to_date, \n",
    "                              bbox=bbox, \n",
    "                              bands=bands, \n",
    "                              in_epsg=3577, \n",
    "                              in_res=30, \n",
    "                              like=None)\n",
    "                \n",
    "            # download and export netcdf to output folder\n",
    "            with rasterio.Env(**rasterio_env):\n",
    "                tools.export_xr_as_nc(ds=ds, filename=out_nc_path)\n",
    "           \n",
    "        else:\n",
    "            # notify\n",
    "            print('Querying stac for existing Area ID: {}'.format(area_id))\n",
    "            \n",
    "            # get output nc path\n",
    "            out_nc_path = nc\n",
    "            \n",
    "            # load existing netcdf\n",
    "            ds_old = xr.open_dataset(out_nc_path)\n",
    "                  \n",
    "            # notify\n",
    "            print('Existing cube has {} images'.format(len(ds_old['time'])))\n",
    "            \n",
    "            # get latest datetime from ds old\n",
    "            latest_dt = ds_old.isel(time=-1)\n",
    "            in_from_date = str(latest_dt['time'].dt.strftime('%Y-%m-%d').values)                                    \n",
    "            \n",
    "            # get now\n",
    "            in_to_date = '{}-12-31'.format(datetime.now().year)  # testing\n",
    "            #in_to_date = '2021-06-01'\n",
    "            \n",
    "            \n",
    "                   \n",
    "            # notify\n",
    "            print('Adding data for period: {} to {}'.format(in_from_date, in_to_date))\n",
    "                  \n",
    "            # get me the data!\n",
    "            ds_new = fetch_odc_xr(collections=collections, \n",
    "                                  in_from_date=in_from_date, \n",
    "                                  in_to_date=in_to_date, \n",
    "                                  bbox=bbox, \n",
    "                                  bands=bands, \n",
    "                                  in_epsg=None, \n",
    "                                  in_res=None, \n",
    "                                  like=ds_old)\n",
    "                  \n",
    "            # notify\n",
    "            print('New cube has {} images'.format(len(ds_new['time'])))\n",
    "            \n",
    "            # download and compute\n",
    "            with rasterio.Env(**rasterio_env):\n",
    "                ds_new = ds_new.compute()            \n",
    "            \n",
    "            # combine but exclude duplicates CHECK THIS CAREFULLY\n",
    "            ds_old = ds_old.combine_first(ds_new)\n",
    "                  \n",
    "            # notify\n",
    "            print('Newly synced cube now has {} images'.format(len(ds_old['time'])))\n",
    "                  \n",
    "            # export new to named file temp, close old, then overwrite\n",
    "            with tempfile.NamedTemporaryFile() as tmp:\n",
    "                ds_old.to_netcdf(tmp.name + '.nc')\n",
    "                \n",
    "                ds_old.close()\n",
    "                ds_new.close()\n",
    "                del ds_old\n",
    "                del ds_new\n",
    "                \n",
    "                ds = xr.open_dataset(tmp.name + '.nc')\n",
    "                \n",
    "                ds.to_netcdf(out_nc_path)\n",
    "\n",
    "            \n",
    "        # update cursor regardless\n",
    "        cursor.updateRow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
