{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals (dev)\n",
    "FOLDER_MODULES = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "GRP_LYR_FILE = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx\"\n",
    "\n",
    "# set gdal global environ\n",
    "import os\n",
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN'] = 'EMPTY_DIR'\n",
    "os.environ['CPL_VSIL_CURL_ALLOWED_EXTENSIONS '] = 'tif'\n",
    "os.environ['VSI_CACHE '] = 'TRUE'\n",
    "os.environ['GDAL_HTTP_MULTIRANGE '] = 'YES'\n",
    "os.environ['GDAL_HTTP_MERGE_CONSECUTIVE_RANGES '] = 'YES'\n",
    "\n",
    "# also set rasterio env variables\n",
    "rasterio_env = {\n",
    "    'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n",
    "    'CPL_VSIL_CURL_ALLOWED_EXTENSIONS': 'tif',\n",
    "    'VSI_CACHE': True,\n",
    "    'GDAL_HTTP_MULTIRANGE': 'YES',\n",
    "    'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES'\n",
    "}\n",
    "\n",
    "# disable future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# safe imports\n",
    "import sys                  # arcgis comes with these\n",
    "import datetime                 # arcgis comes with these\n",
    "import numpy as np              # arcgis comes with these\n",
    "import arcpy                    # arcgis comes with these\n",
    "from datetime import datetime   # arcgis comes with these\n",
    "\n",
    "# risky imports (not native to arcgis)\n",
    "try:\n",
    "    from osgeo import gdal\n",
    "    from osgeo import ogr\n",
    "    import tempfile\n",
    "    import xarray as xr\n",
    "    import dask\n",
    "    import rasterio\n",
    "    import pystac_client\n",
    "    from odc import stac\n",
    "except:\n",
    "    arcpy.AddError('Python libraries xarray, dask, rasterio, pystac, or odc not installed.')\n",
    "    raise\n",
    "\n",
    "# import tools\n",
    "try:\n",
    "    # shared folder\n",
    "    sys.path.append(FOLDER_SHARED)\n",
    "    import arc, satfetcher, tools\n",
    "\n",
    "    # module folder\n",
    "    sys.path.append(FOLDER_MODULES)\n",
    "    import nrt, cog_odc, cog\n",
    "except:\n",
    "    arcpy.AddError('Could not find tenement tools python scripts (modules, shared).')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'toolbox'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import arcpy\n",
    "\n",
    "tbx = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\"\n",
    "arcpy.ImportToolbox(tbx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need button to create shapefile with relevent attributes\n",
    "# set a folder\n",
    "# create a shapefile of polygons\n",
    "# need a id field, out netcdf, platform, start/end monitor date, other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create monitoring areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new monitoring project database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 7225, in execute\n",
      "  File \"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules\\nrt.py\", line 65, in create_nrt_project\n",
      "    raise ValueError('Requested file location arleady exists. Choose a different name.')\n",
      "ValueError: Requested file location arleady exists. Choose a different name.\n"
     ]
    },
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 000582: Error occurred during execution.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[4]\u001b[0m:\nLine \u001b[0;34m5\u001b[0m:     arcpy.NRT_Create_Project_toolbox(out_folder, out_filename)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\u001b[0m, in \u001b[0;32mNRT_Create_Project\u001b[0m:\nLine \u001b[0;34m718\u001b[0m:   multiValue=\u001b[34mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\u001b[0m, in \u001b[0;32mNRT_Create_Project\u001b[0m:\nLine \u001b[0;34m715\u001b[0m:   parameterType=\u001b[33m'\u001b[39;49;00m\u001b[33mRequired\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: ERROR 000582: Error occurred during execution.\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "out_folder = r'C:\\Users\\Lewis\\Desktop\\nrt_projects'\n",
    "out_filename = 'ophthalmia_monitoring'\n",
    "\n",
    "# create a new nrt project\n",
    "arcpy.NRT_Create_Project_toolbox(out_folder, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make monitoring areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is up to user using usual arcgis pro tools?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate monitoring areas and update cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform sync\n",
    "in_feat = r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas'\n",
    "\n",
    "# create a new nrt project\n",
    "arcpy.NRT_Sync_Cube_toolbox(in_feat=in_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp inputs\n",
    "in_fmask_flags = 'Valid;Snow;Water'\n",
    "in_max_cloud = 0\n",
    "in_veg_idx = 'MAVI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR NRT_Detect_Change\n",
    "def execute(in_feat, in_fmask_flags, in_max_cloud=0, in_veg_idx='MAVI'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        \n",
    "    # grab parameter values \n",
    "    #in_feat = parameters[0]        # input monitoring area features\n",
    "    \n",
    "    \n",
    "    # # # # #\n",
    "    # notify user and set up progress bar\n",
    "    arcpy.AddMessage('Beginning NRT change detection...')\n",
    "    arcpy.SetProgressor(type='step', \n",
    "                        message='Preparing parameters...', \n",
    "                        min_range=0, max_range=3)\n",
    "            \n",
    "    # prepare features shapefile\n",
    "    shp_desc = arcpy.Describe(in_feat)\n",
    "    in_feat = os.path.join(shp_desc.path, shp_desc.name)\n",
    "    \n",
    "    # validate monitoring area feature class\n",
    "    if not nrt.validate_monitoring_areas(in_feat):\n",
    "        arcpy.AddError('Monitoring areas feature is invalid.')\n",
    "        raise\n",
    "    \n",
    "    # get input featureclass file, get dir and filename\n",
    "    in_name = os.path.basename(in_feat)     # name of monitor fc\n",
    "    in_gdb = os.path.dirname(in_feat)       # path of gdb\n",
    "\n",
    "    # check gdv extension\n",
    "    if not in_gdb.endswith('.gdb'):\n",
    "        arcpy.AddError('Feature class is not in a geodatabase.')\n",
    "        raise\n",
    "    else:\n",
    "        in_path = os.path.splitext(in_gdb)[0]   # path of gdb without ext\n",
    "        in_data_path = in_path + '_' + 'cubes'  # associated cube data folder\n",
    "\n",
    "    # check if cubes folder exists\n",
    "    if not os.path.exists(in_data_path):\n",
    "        arcpy.AddError('Could not find cube folder for selected monitoring areas.')\n",
    "        raise    \n",
    "        \n",
    "    # convert fmask flags as text to numeric code equivalents\n",
    "    in_fmask_flags = [e for e in in_fmask_flags.split(';')]\n",
    "    in_fmask_flags = arc.convert_fmask_codes(in_fmask_flags)\n",
    "    \n",
    "    # check if cloud cover is valid\n",
    "    if in_max_cloud < 0 or in_max_cloud > 100:\n",
    "        arcpyAddError('Cloud cover must be between 0 and 100.')\n",
    "        raise\n",
    "        \n",
    "        \n",
    "    # todo count num feats in fc for progressor \n",
    "    #\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Iterating through monitoring areas...')\n",
    "    arcpy.SetProgressorPosition(1)\n",
    "        \n",
    "    # get features (will always have at least one, as we validated earlier)\n",
    "    driver = ogr.GetDriverByName(\"OpenFileGDB\")\n",
    "    data_source = driver.Open(os.path.dirname(in_feat), 0)\n",
    "    feats = data_source.GetLayer('monitoring_areas')\n",
    "\n",
    "    # iterate through each polygon\n",
    "    for feat in feats:\n",
    "        \n",
    "        # # # # #\n",
    "        # notify\n",
    "        arcpy.AddMessage('Validating monitoring area: {}'.format(feat['area_id']))\n",
    "\n",
    "        # send off to check if valid\n",
    "        is_valid = nrt.validate_monitoring_area(area_id=feat['area_id'],\n",
    "                                                platform=feat['platform'], \n",
    "                                                s_year=feat['s_year'], \n",
    "                                                e_year=feat['e_year'], \n",
    "                                                index=feat['index'])\n",
    "                \n",
    "        # check if monitoring area is valid\n",
    "        if not is_valid:\n",
    "            arcpy.AddWarning('Invalid monitoring area: {}, skipping.'.format(feat['area_id']))\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # # # # #\n",
    "        # notify\n",
    "        arcpy.AddMessage('Opening cube for monitoring area: {}'.format(feat['area_id']))\n",
    "\n",
    "        # set existing nc path and open if exists\n",
    "        out_nc = os.path.join(in_data_path, 'cube' + '_' + feat['area_id'] + '.nc')\n",
    "        if os.path.exists(out_nc):\n",
    "            try:\n",
    "                ds_existing = xr.open_dataset(out_nc)                   \n",
    "            except:\n",
    "                arcpy.AddWarning('Could not open existing cube, skipping.')\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        # # # # #\n",
    "        # notify\n",
    "        arcpy.AddMessage('Preparing cube for monitoring area: {}'.format(feat['area_id']))\n",
    "        \n",
    "        # check xr type, dims, num time\n",
    "        if not isinstance(ds_existing, xr.Dataset):\n",
    "            arcpy.AddWarning('NetCDF is not not an xarray dataset type, skipping.')\n",
    "            continue\n",
    "        elif 'x' not in list(ds_existing.dims) or 'y' not in list(ds_existing.dims):\n",
    "            arcpy.AddWarning('No x or y dimension in dataset, skipping.')\n",
    "            continue\n",
    "        elif 'time' not in list(ds_existing.dims):\n",
    "            arcpy.AddWarning('No time dimension in dataset, skipping.')\n",
    "            continue\n",
    "        \n",
    "        # get dataset and band attributes\n",
    "        ds_attrs = ds_existing.attrs\n",
    "        ds_band_attrs = ds_existing[list(ds_existing.data_vars)[0]].attrs\n",
    "        ds_spatial_ref_attrs = ds_existing['spatial_ref'].attrs    \n",
    "        \n",
    "        \n",
    "        # # # # #\n",
    "        # notify\n",
    "        #arcpy.SetProgressorLabel('Removing invalid pixels and empty dates...')\n",
    "        #arcpy.SetProgressorPosition(3)\n",
    "\n",
    "        # check if expected band name exists\n",
    "        mask_band = arc.get_name_of_mask_band(list(ds_existing.data_vars))\n",
    "\n",
    "        # remove invalid pixels and empty scenes\n",
    "        ds_existing = cog.remove_fmask_dates(ds=ds_existing, \n",
    "                                             valid_class=in_fmask_flags, \n",
    "                                             max_invalid=in_max_cloud, \n",
    "                                             mask_band=mask_band, \n",
    "                                             nodata_value=np.nan, \n",
    "                                             drop_fmask=True)\n",
    "        \n",
    "        \n",
    "        # # # # #\n",
    "        # notify and increment progess bar\n",
    "        #arcpy.SetProgressorLabel('Calculating vegetation index...')\n",
    "        #arcpy.SetProgressorPosition(4)\n",
    "\n",
    "        # conform dea aws band names based on platform\n",
    "        ds_existing = satfetcher.conform_dea_ard_band_names(ds=ds_existing, \n",
    "                                                            platform=feat['platform'].lower()) \n",
    "\n",
    "        # calculate vegetation index \n",
    "        ds_existing = tools.calculate_indices(ds=ds_existing, \n",
    "                                              index=in_veg_idx.lower(), \n",
    "                                              custom_name='veg_idx', \n",
    "                                              rescale=False, \n",
    "                                              drop=True)\n",
    "        \n",
    "        # append original attributes on to new band\n",
    "        ds_existing['veg_idx'].attrs = ds_band_attrs\n",
    "        \n",
    "        # see phenolopy for resample, edge effects, etc\n",
    "        # todo!\n",
    "        \n",
    "        \n",
    "        # # # # #\n",
    "        # notify and increment progess bar\n",
    "        #arcpy.SetProgressorLabel('Masking out edge pixels...')\n",
    "        #arcpy.SetProgressorPosition(4)\n",
    "\n",
    "        # convert feature to layer and use to mask\n",
    "        geom = ogr.Open(feat.ExportToJson(), 0)\n",
    "        lyr = geom.GetLayer()\n",
    "        mask = nrt.mask_xr_via_polygon(geom=lyr, \n",
    "                                       x=ds_existing['x'].data, \n",
    "                                       y=ds_existing['y'].data, \n",
    "                                       bbox=ds_existing.geobox.extent.boundingbox, \n",
    "                                       transform=ds_existing.geobox.transform, \n",
    "                                       ncols=len(ds_existing['x']), \n",
    "                                       nrows=len(ds_existing['y']), \n",
    "                                       mask_value=1)\n",
    "        \n",
    "        # apply mask to current dataset, set everything outside to nan\n",
    "        ds_existing = ds_existing.where(mask)\n",
    "                \n",
    "        \n",
    "        # # # # #\n",
    "        # notify and increment progess bar\n",
    "        #arcpy.SetProgressorLabel('Preparing cubve for change detection...')\n",
    "        #arcpy.SetProgressorPosition(4)      \n",
    "        \n",
    "        # prepare time into ewmacd compaitble structure\n",
    "        #time_array = ds_existing['time'].data\n",
    "        # may need to convert\n",
    "\n",
    "        # get raw index values\n",
    "        #veg_array = ds_existing['veg_idx'].median(['x', 'y']).data\n",
    "        \n",
    "        # sumamrise each image to 1 median\n",
    "        ds_summary = ds.median(['x', 'y'])\n",
    "\n",
    " \n",
    "        # # # # #\n",
    "        # notify and increment progess bar\n",
    "        #arcpy.SetProgressorLabel('Performing NRT change detection...')\n",
    "        #arcpy.SetProgressorPosition(4)   \n",
    "        \n",
    "        # apply ewmacd function\n",
    "        #ds_change = nrt.EWMACD(ds=ds, trainingPeriod='dynamic', etc..)\n",
    "        \n",
    " \n",
    "        # # # # #\n",
    "        # notify and increment progess bar\n",
    "        #arcpy.SetProgressorLabel('Building output change detection cube...')\n",
    "        #arcpy.SetProgressorPosition(4)   \n",
    "        \n",
    "        # broadcast median cube onto pixel cubes to steal median cube values\n",
    "        ds_summary, _ = xr.broadcast(ds_summary, ds)   # want same median value for every pixel per image\n",
    "        ds_change, _ = xr.broadcast(ds_change , ds)   # want same change value for every pixel per image\n",
    "\n",
    "        # ensure dimensions in original order\n",
    "        ds_summary = ds_summary.transpose('time', 'y', 'x')\n",
    "        ds_change = ds_change.transpose('time', 'y', 'x')\n",
    "        \n",
    "        # re mask summary and change cubes as nan pixels now set to non-nan\n",
    "        ds_summary = ds_summary.where(mask)\n",
    "        ds_change = ds_change.where(mask)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing dates where too many invalid pixels.\n",
      "Filling invalid pixels with requested nodata value.\n",
      "Dropping mask band.\n",
      "Removed invalid images successfully.\n",
      "Conforming DEA ARD satellite band names.\n",
      "Satellite band names conformed successfully.\n",
      "Calculating indices: mavi.\n",
      "Calculating index: mavi\n",
      "Renamed default indices.\n",
      "Calculated indices successfully.\n"
     ]
    }
   ],
   "source": [
    "in_fmask_flags = 'Valid;Snow;Water'\n",
    "\n",
    "ds_existing = execute(in_feat=r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas',\n",
    "                        in_fmask_flags=in_fmask_flags) # make sure flags are 1, 5, 7 at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, b'2.0.0 Service closing transmission channel')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smtpd import SMTPServer\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = 'mrlewie@outlook.com'\n",
    "msg['To'] = 'mrlewie@outlook.com'\n",
    "msg['Subject'] = 'New area detected'\n",
    "message = 'Yep, I found a new area'\n",
    "msg.attach(MIMEText(message))\n",
    "\n",
    "server = smtplib.SMTP('smtp.office365.com', 587) # init server\n",
    "server.ehlo()  # say hi to server\n",
    "server.starttls()  # secure email with tls encryption\n",
    "server.ehlo()  # say hi to server again\n",
    "server.login('mrlewie@outlook.com', 'halfLife1985micr')  # login\n",
    "\n",
    "server.sendmail('mrlewie@outlook.com', 'mrlewie@outlook.com', msg.as_string())\n",
    "\n",
    "server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "PYTHON ERRORS:\nTraceback Info:\n  File \"c:\\program files\\arcgis\\pro\\Resources\\ArcToolbox\\scripts\\SendEmailWithZip.py\", line 82, in <module>\n    send_mail(fromaddr, sendto, subject, text, zipfile, smtpMailServer, smtpUser, smtpPwd)\n\nError Info:\n    <class 'Exception'>: SendEmailError:PYTHON ERRORS:\nTraceback Info:\n  File \"c:\\program files\\arcgis\\pro\\Resources\\ArcToolbox\\scripts\\SendEmailWithZip.py\", line 49, in send_mail\n    smtp = smtplib.SMTP(server)\n\nError Info:\n    <class 'socket.gaierror'>: [Errno 11001] getaddrinfo failed\n\n\nERROR, Unable to send email\nFailed to execute (SendEmailWithZipFileAttachment).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[14]\u001b[0m:\nLine \u001b[0;34m7\u001b[0m:     SMTP_Email_Server=\u001b[33m'\u001b[39;49;00m\u001b[33msmtp.office365.com, 587\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\server.py\u001b[0m, in \u001b[0;32mSendEmailWithZipFileAttachment\u001b[0m:\nLine \u001b[0;34m902\u001b[0m:   \u001b[34mraise\u001b[39;49;00m e\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\server.py\u001b[0m, in \u001b[0;32mSendEmailWithZipFileAttachment\u001b[0m:\nLine \u001b[0;34m899\u001b[0m:   retval = convertArcObjectToPythonObject(gp.SendEmailWithZipFileAttachment_server(*gp_fixargs((To, From, Subject, Text, Zip_File, Max_File_Size__MB_, SMTP_Email_Server, User, Password), \u001b[34mTrue\u001b[39;49;00m)))\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: PYTHON ERRORS:\nTraceback Info:\n  File \"c:\\program files\\arcgis\\pro\\Resources\\ArcToolbox\\scripts\\SendEmailWithZip.py\", line 82, in <module>\n    send_mail(fromaddr, sendto, subject, text, zipfile, smtpMailServer, smtpUser, smtpPwd)\n\nError Info:\n    <class 'Exception'>: SendEmailError:PYTHON ERRORS:\nTraceback Info:\n  File \"c:\\program files\\arcgis\\pro\\Resources\\ArcToolbox\\scripts\\SendEmailWithZip.py\", line 49, in send_mail\n    smtp = smtplib.SMTP(server)\n\nError Info:\n    <class 'socket.gaierror'>: [Errno 11001] getaddrinfo failed\n\n\nERROR, Unable to send email\nFailed to execute (SendEmailWithZipFileAttachment).\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "arcpy.server.SendEmailWithZipFileAttachment(To='mrlewie@outlook.com',\n",
    "                                            From='mrlewie@outlook.com',\n",
    "                                            Subject='Heya!',\n",
    "                                            Text='Hello, this is a test my dude!',\n",
    "                                            Zip_File=r\"C:\\Users\\Lewis\\Desktop\\hello.zip\",\n",
    "                                            Max_File_Size__MB_=10,\n",
    "                                            SMTP_Email_Server='smtp.office365.com, 587'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare time into ewmacd compaitble structure\n",
    "time_array = ds_existing['time'].data\n",
    "# may need to convert\n",
    "\n",
    "# get raw index values\n",
    "veg_array = ds_existing['veg_idx'].median(['x', 'y']).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWMACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A001.nc\")\n",
    "ds = ds.compute()\n",
    "\n",
    "#ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['nbart_red'].isel(time=-50).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Lewis\\Desktop\\testing\\area.tif<h2>Messages</h2>Start Time: Thursday, 2 December 2021 8:24:49 PM<br/>Succeeded at Thursday, 2 December 2021 8:24:50 PM (Elapsed Time: 0.81 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Lewis\\\\Desktop\\\\testing\\\\area.tif'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tif from vectors\n",
    "arcpy.conversion.FeatureToRaster(in_features=r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas\", \n",
    "                                 field='area_id', \n",
    "                                 out_raster=r\"C:\\Users\\Lewis\\Desktop\\testing\\area.tif\", \n",
    "                                 cell_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_area = xr.open_dataset(r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A001.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ras = xr.open_rasterio(r\"C:\\Users\\Lewis\\Desktop\\testing\\area.tif\")\n",
    "ds_ras = ds_ras.where(ds_ras == 0, 1)\n",
    "ds_ras = ds_ras.squeeze(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ds_ras.interp_like(ds_area, method='nearest')\n",
    "mask = mask.where(mask == 1, 0)\n",
    "ds_area = ds_area.where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_area['nbart_red'].isel(time=0).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1785.5, -999. , 3497. , -999. ,  513. , -999. , 3019. , -999. ,\n",
       "       -999. ,  680. ,  889.5, -999. ,  457. ,  505. , -999. , -999. ,\n",
       "        466. , -999. , 2501. , -999. ,  499. ,  538.5, -999. , -999. ,\n",
       "        572. , -999. ,  655.5, -999. , 3751.5, -999. ,  792. , -999. ,\n",
       "        844.5, -999. ,  838.5, -999. ,  697. , -999. ,  633. , -999. ,\n",
       "       2211.5, -999. , 1874.5, -999. , 2520. , -999. ,  490.5, -999. ,\n",
       "        544.5, -999. ,  516. , -999. ,  503. , -999. ,  497. , -999. ,\n",
       "        457. , -999. , -999. ,  414.5, -999. ,  461. , -999. , -999. ,\n",
       "        477.5, -999. ,  550.5, -999. ,  557. , -999. , -999. ,  629. ,\n",
       "       -999. ,  633. , -999. ,  652.5, -999. , -999. ,  720.5,  740.5,\n",
       "       -999. ,  637.5, -999. , 3438. , -999. , -999. ,  496. , -999. ,\n",
       "        521.5, -999. ,  528.5, -999. ,  549. , -999. , 4357. , -999. ,\n",
       "        741. , -999. ,  551.5, -999. ,  503.5,  544.5, -999. ,  590. ,\n",
       "       -999. ,  613. , -999. ,  712.5, -999. ,  660.5, -999. ,  767.5,\n",
       "       -999. ,  826. , -999. ,  768. , -999. ,  729. , -999. ,  713. ,\n",
       "       -999. ,  728.5, -999. ,  602. , -999. ,  599. , -999. , -999. ,\n",
       "        561.5, -999. ,  527.5, -999. ,  529.5, -999. , -999. ,  525. ,\n",
       "       -999. ,  536. , -999. , 4936.5, -999. ,  510. , -999. ,  508. ,\n",
       "       -999. ,  542.5, -999. ,  559. , -999. ,  596. , -999. ,  641. ,\n",
       "       -999. ,  671.5, -999. ,  496.5,  727. , -999. ,  702. , -999. ,\n",
       "        721.5, -999. ,  706.5, -999. ,  788.5, -999. ,  694. , -999. ,\n",
       "        837.5,  574.5,  571. , -999. , -999. , 8361. , -999. ,  525. ,\n",
       "       -999. ,  579.5, -999. , -999. ,  550. , -999. ,  533. , -999. ,\n",
       "       4713. , -999. ,  525.5, -999. ,  521.5, -999. , -999. ,  640. ,\n",
       "       -999. ,  705.5,  760.5, -999. ,  650.5, -999. ,  678.5, -999. ,\n",
       "        702.5, -999. ,  673.5,  638.5, -999. ,  664.5, -999. ,  922.5,\n",
       "       -999. ,  657. , -999. , 4442. , -999. ,  614. , -999. ,  620. ,\n",
       "       -999. , 1239.5, -999. ,  615.5, -999. ,  714.5, -999. ,  619.5,\n",
       "       -999. ,  664. , -999. ,  595.5, -999. ,  650.5, -999. ,  672. ,\n",
       "       -999. ,  703. , -999. ,  798. , -999. ,  831. , -999. ,  813.5,\n",
       "       -999. ,  841. , -999. ,  879.5, -999. , -999. ,  575. , -999. ,\n",
       "        558. , -999. , 2799.5, -999. ,  456.5, -999. , 2266.5, -999. ,\n",
       "        511. , -999. ,  472. , -999. ,  480.5, -999. ,  549.5, -999. ,\n",
       "        511. , -999. ,  530. ,  583. , -999. ,  571.5, -999. ,  624.5,\n",
       "       -999. ,  685.5, -999. ,  727.5, -999. ,  734. , -999. ,  710.5,\n",
       "       -999. , 4650. , -999. ,  734.5, -999. , 1325. , -999. ,  772.5,\n",
       "        792. ,  768. ,  692. , -999. ,  596. , -999. , -999. ,  784.5,\n",
       "       -999. ,  655.5, -999. ,  678.5, -999. ,  632. , -999. ,  654. ,\n",
       "       -999. ,  748. , -999. ,  722. , -999. ,  718.5, -999. ,  788. ,\n",
       "       -999. ,  860. , -999. ,  942.5, -999. ,  874.5, -999. ,  919. ,\n",
       "        830.5, 1238. , 1637.5,  206. ,  686.5,  762. ,  844. , -999. ,\n",
       "       -999. ,  884. , -999. ,  882. , -999. ,  884. , -999. ,  943.5,\n",
       "       -999. ,  906.5, -999. ,  934. , 1572.5,  775. ,  803.5,  776. ,\n",
       "       -999. , 1241. , 5691. , -999. , 2449.5, 4015.5, -999. , -999. ,\n",
       "        645.5,  679. , -999. ,  725. , -999. ,  740.5, -999. ,  813. ,\n",
       "       -999. ,  891. , -999. ,  698. , -999. ,  791. , -999. , 1056. ,\n",
       "       -999. , -999. ,  875. , -999. , 3362.5, -999. , -999. , -999. ,\n",
       "       -999. ,  800. , -999. ,  820. , -999. ,  766.5, -999. ,  853. ,\n",
       "       -999. , 1017.5, -999. ,  921.5,  828.5, -999. ,  882. , -999. ,\n",
       "       1171. , -999. , -999. , -999. , -999. , -999. , -999. ,  632.5,\n",
       "       -999. ,  762. ,  583.5,  983.5, -999. ,  609. , -999. , -999. ,\n",
       "        550.5, -999. , -999. ,  592.5, -999. ,  564.5, -999. ,  592. ,\n",
       "       -999. ,  621. , -999. ,  672.5,  731.5, -999. , 4595. , -999. ,\n",
       "        773. , -999. , -999. ,  810.5, -999. ,  753.5,  708. , -999. ,\n",
       "       -999. ,  649. ,  617. , -999. ,  667. , -999. ,  712. , -999. ,\n",
       "        634. , -999. , 1593. , -999. ,  631. , -999. ,  567. , -999. ,\n",
       "        577.5, -999. ,  645. , -999. , 3136.5, -999. ,  587.5, -999. ,\n",
       "        600. , -999. ,  634.5, -999. ,  733. , -999. ,  869.5, -999. ,\n",
       "        744. , -999. ,  770.5, -999. , 1033.5, -999. ,  740. , -999. ,\n",
       "        794.5, -999. ,  723. , -999. ,  718. , -999. ,  649.5, -999. ,\n",
       "        843. , 1220. , -999. , 1565.5, -999. , 2939. , -999. ,  525.5,\n",
       "       -999. ,  553. , -999. , 1650.5, -999. , 4585. , -999. ,  506. ,\n",
       "       -999. ,   87. , -999. ,  512.5, -999. ,  626. , -999. ,  591. ,\n",
       "       -999. ,  626. , -999. ,  667.5, -999. ,  789. , -999. , 1040.5,\n",
       "       -999. ,  709.5, -999. ,  764. , -999. ,  800. , -999. ,  805.5,\n",
       "       -999. ,  625. , -999. ,  598. , -999. ,  615. , -999. ,  648. ,\n",
       "       -999. ,  641.5, -999. ,  641.5, -999. , 3210. , -999. ,  561. ,\n",
       "       -999. ,  604.5, -999. ,  561. , -999. , 2410. , -999. , 4753. ,\n",
       "       -999. ,  519. , -999. ,  552.5, -999. ,  656.5, -999. ,  630. ,\n",
       "       -999. ,  683. , -999. ,  766. , -999. ,  778. , -999. , 2593. ,\n",
       "       -999. , 2130.5, -999. ,  836. , -999. ,  719. , -999. , 3377.5,\n",
       "       -999. ,  536. , -999. , 6682.5, -999. ,  575.5, -999. ,  536.5,\n",
       "       -999. , 1833.5, -999. ,  507.5, -999. ,  499.5, -999. ,  503. ,\n",
       "       -999. ,  504.5, -999. ,  523. , -999. ,  542.5, -999. ,  552. ,\n",
       "       -999. ,  605.5, -999. , 2255.5, -999. ,  688.5, -999. ,  796.5,\n",
       "       -999. ,  706.5, -999. ,  719.5, -999. ,  792. , -999. ,  794. ,\n",
       "       -999. , 3630.5, -999. ,  928. , -999. , 8348.5, -999. ,  713. ,\n",
       "       -999. , 3085. , -999. ,  596.5, -999. ,  561. , -999. ,  574. ,\n",
       "       -999. ,  572.5, -999. ,  571. , -999. , 5590. , -999. ,  496. ,\n",
       "       -999. ,  488.5, -999. ,  512. , -999. , 3733. , -999. ,  569.5,\n",
       "       -999. ,  596. , -999. ,  669.5, -999. ,  809. , -999. ,  717.5,\n",
       "       -999. ,  693.5, -999. ,  740. , -999. ,  735. , -999. ,  750. ,\n",
       "       -999. , 1868. , -999. ,  666.5, -999. ,  553. , -999. ,  659.5,\n",
       "       -999. ,  845. , -999. ,  598.5, -999. ,  679. , -999. ,  610. ,\n",
       "       -999. ,  562. , -999. ,  531. , -999. ,  579.5, -999. ,  528. ,\n",
       "       -999. , 3448. , -999. ,  603. , -999. ,  606.5, -999. ,  625. ,\n",
       "       -999. ,  852. , -999. ,  751. , -999. , 1215. , -999. ,  811. ,\n",
       "       -999. ,  789. , -999. , 1594. , -999. ,  854.5, -999. ,  610. ,\n",
       "       -999. ,  645.5, -999. , 3680.5, -999. ,  596.5, -999. ,  608. ,\n",
       "       -999. ,  548. , -999. ,  888. , -999. , 2183.5, -999. ,  541.5,\n",
       "       -999. ,  549. , -999. , 6054.5, -999. ,  533.5, -999. ,  540. ,\n",
       "       -999. ,  558. , -999. ,  602. , -999. ,  681.5, -999. ,  743. ,\n",
       "       -999. , 1165. , -999. , -999. , 2090. , -999. ,  768. , -999. ,\n",
       "        785. , -999. , 4528. , -999. , 1169. , -999. ,  763.5, -999. ,\n",
       "        575. , -999. ,  609.5, -999. ,  609. , -999. , 1426. , -999. ,\n",
       "        564. ,  542.5, -999. , -999. ,  560. , -999. ,  538. , -999. ,\n",
       "        555.5, -999. ,  545.5, -999. ,  593.5, -999. ,  501. , -999. ,\n",
       "        705. , -999. , -999. ,  797. , -999. ,  904.5, -999. ])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_medians = ds_area.median(dim=['x', 'y'], keep_attrs=True)\n",
    "ds_medians['nbart_red'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    # check folder exists\n",
    "    #if not os.path.exists(out_folder):\n",
    "        #raise ValueError('Requested folder does not exist.')\n",
    "        \n",
    "    # check file does not already exist\n",
    "    #if os.path.exists(out_filepath):\n",
    "        #raise ValueError('Requested file location arleady exists. Choose a different name.')\n",
    "    \n",
    "    # build project geodatbase\n",
    "    #out_filepath = arcpy.management.CreateFileGDB(out_folder, out_filename)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Generating database feature class...')\n",
    "    \n",
    "    # temporarily disable auto-visual of outputs\n",
    "    arcpy.env.addOutputsToMap = False\n",
    "    \n",
    "    # create feature class and wgs84 spatial ref sys\n",
    "    srs = arcpy.SpatialReference(4326)\n",
    "    out_feat = arcpy.management.CreateFeatureclass(out_path=out_filepath, \n",
    "                                                   out_name='monitoring_areas', \n",
    "                                                   geometry_type='POLYGON',\n",
    "                                                   spatial_reference=srs)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Generating database domains...')\n",
    "    \n",
    "    # create platform domain\n",
    "    arcpy.management.CreateDomain(in_workspace=out_filepath, \n",
    "                                  domain_name='dom_platforms', \n",
    "                                  domain_description='Platform name (Landsat or Sentinel)',\n",
    "                                  field_type='TEXT', \n",
    "                                  domain_type='CODED')\n",
    "    \n",
    "    # generate coded values to platform domain\n",
    "    dom_values = {'Landsat': 'Landsat', 'Sentinel': 'Sentinel'}\n",
    "    for dom_value in dom_values:\n",
    "        arcpy.management.AddCodedValueToDomain(in_workspace=out_filepath, \n",
    "                                               domain_name='dom_platforms', \n",
    "                                               code=dom_value, \n",
    "                                               code_description=dom_values.get(dom_value))\n",
    "\n",
    "\n",
    "    # notify\n",
    "    print('Generating database fields...') \n",
    "    \n",
    "    # add area id field to featureclass   \n",
    "    arcpy.management.AddField(in_table=out_feat, \n",
    "                              field_name='area_id', \n",
    "                              field_type='TEXT', \n",
    "                              field_alias='Area ID',\n",
    "                              field_length=200,\n",
    "                              field_is_required='REQUIRED')\n",
    "            \n",
    "    \n",
    "    # notify todo - delete if we dont want defaults\n",
    "    print('Generating database defaults...')  \n",
    "    \n",
    "    # set default platform\n",
    "    arcpy.management.AssignDefaultToField(in_table=out_feat, \n",
    "                                          field_name='platform',\n",
    "                                          default_value='Landsat')   \n",
    "           \n",
    "           \n",
    "    # notify\n",
    "    print('Creating NetCDF data folder...') \n",
    "    \n",
    "    # create output folder\n",
    "    out_nc_folder = os.path.join(out_folder, '{}_cubes'.format(out_filename))\n",
    "    if os.path.exists(out_nc_folder):\n",
    "        try:\n",
    "            shutil.rmtree(out_nc_folder)\n",
    "        except:\n",
    "            raise ValueError('Could not delete {}'.format(out_nc_folder))\n",
    "\n",
    "    # create new folder\n",
    "    os.makedirs(out_nc_folder)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Adding data to current map...') \n",
    "    \n",
    "    # enable auto-visual of outputs\n",
    "    arcpy.env.addOutputsToMap = True\n",
    "    \n",
    "    try:\n",
    "        # get active map, add feat\n",
    "        aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "        mp = aprx.activeMap\n",
    "        mp.addDataFromPath(out_feat)\n",
    "    \n",
    "    except:\n",
    "        arcpy.AddWarning('Could not find active map. Add monitor areas manually.')        \n",
    "        \n",
    "    # notify\n",
    "    print('Created new monitoring project database successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor tool\n",
    "# select shapefile\n",
    "# run checks\n",
    "# loop through each record in shapefile\n",
    "# get date time of last time\n",
    "# query stac for all dates above this\n",
    "# if new records, create new netcdf using odc-stac like func for bb, etc\n",
    "# append to existing netcdf and save\n",
    "\n",
    "# get input shapefile file, get dir and filename\n",
    "out_path = os.path.dirname(out_shp)\n",
    "out_name = os.path.basename(out_shp)\n",
    "\n",
    "fields = ['AreaID', 'NetCDF', 'Platform', 'VegIdx', 'YrStart', 'YrEnd', 'Shape@']\n",
    "with arcpy.da.UpdateCursor(out_shp, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        area_id = row[0]\n",
    "        nc = row[1]\n",
    "        platform = row[2]\n",
    "        veg_idx = row[3]\n",
    "        year_start = row[4]\n",
    "        year_end = row[5]\n",
    "        geom = row[6]\n",
    "\n",
    "        # temp\n",
    "        in_epsg = 3577\n",
    "        in_res = 30\n",
    "\n",
    "        # get as bbox\n",
    "        bbox = [geom.extent.XMin, geom.extent.YMin, \n",
    "                geom.extent.XMax, geom.extent.YMax]\n",
    "        \n",
    "        # get collections and bands based on platform\n",
    "        if platform == 'Landsat':\n",
    "            collections = ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3']\n",
    "            bands = ['nbart_red', 'nbart_green', 'nbart_blue']\n",
    "        else:\n",
    "            raise ValueError('Not yet implemented')\n",
    "\n",
    "        # if netcdf field is empty, add path to row\n",
    "        if nc == ' ' or nc == '' or nc is None:\n",
    "            \n",
    "            # notify\n",
    "            print('Querying stac for new Area ID: {}'.format(area_id))\n",
    "            \n",
    "            # update row with nc path\n",
    "            out_nc_path = os.path.join(out_path, 'area_{}.nc'.format(area_id))\n",
    "            row[1] = out_nc_path\n",
    "            \n",
    "            # get dates\n",
    "            in_from_date = '{}-01-01'.format(year_start)\n",
    "            #in_to_date = '{}-12-31'.format(datetime.now().year)  # testing\n",
    "            in_to_date = '2020-03-01'\n",
    "            \n",
    "            # notify\n",
    "            print('Getting new data for period: {} to {}'.format(in_from_date, in_to_date))\n",
    "            \n",
    "            # get me the data!\n",
    "            ds = fetch_odc_xr(collections=collections, \n",
    "                              in_from_date=in_from_date, \n",
    "                              in_to_date=in_to_date, \n",
    "                              bbox=bbox, \n",
    "                              bands=bands, \n",
    "                              in_epsg=3577, \n",
    "                              in_res=30, \n",
    "                              like=None)\n",
    "                \n",
    "            # download and export netcdf to output folder\n",
    "            with rasterio.Env(**rasterio_env):\n",
    "                tools.export_xr_as_nc(ds=ds, filename=out_nc_path)\n",
    "           \n",
    "        else:\n",
    "            # notify\n",
    "            print('Querying stac for existing Area ID: {}'.format(area_id))\n",
    "            \n",
    "            # get output nc path\n",
    "            out_nc_path = nc\n",
    "            \n",
    "            # load existing netcdf\n",
    "            ds_old = xr.open_dataset(out_nc_path)\n",
    "                  \n",
    "            # notify\n",
    "            print('Existing cube has {} images'.format(len(ds_old['time'])))\n",
    "            \n",
    "            # get latest datetime from ds old\n",
    "            latest_dt = ds_old.isel(time=-1)\n",
    "            in_from_date = str(latest_dt['time'].dt.strftime('%Y-%m-%d').values)                                    \n",
    "            \n",
    "            # get now\n",
    "            in_to_date = '{}-12-31'.format(datetime.now().year)  # testing\n",
    "            #in_to_date = '2021-06-01'\n",
    "            \n",
    "            \n",
    "                   \n",
    "            # notify\n",
    "            print('Adding data for period: {} to {}'.format(in_from_date, in_to_date))\n",
    "                  \n",
    "            # get me the data!\n",
    "            ds_new = fetch_odc_xr(collections=collections, \n",
    "                                  in_from_date=in_from_date, \n",
    "                                  in_to_date=in_to_date, \n",
    "                                  bbox=bbox, \n",
    "                                  bands=bands, \n",
    "                                  in_epsg=None, \n",
    "                                  in_res=None, \n",
    "                                  like=ds_old)\n",
    "                  \n",
    "            # notify\n",
    "            print('New cube has {} images'.format(len(ds_new['time'])))\n",
    "            \n",
    "            # download and compute\n",
    "            with rasterio.Env(**rasterio_env):\n",
    "                ds_new = ds_new.compute()            \n",
    "            \n",
    "            # combine but exclude duplicates CHECK THIS CAREFULLY\n",
    "            ds_old = ds_old.combine_first(ds_new)\n",
    "                  \n",
    "            # notify\n",
    "            print('Newly synced cube now has {} images'.format(len(ds_old['time'])))\n",
    "                  \n",
    "            # export new to named file temp, close old, then overwrite\n",
    "            with tempfile.NamedTemporaryFile() as tmp:\n",
    "                ds_old.to_netcdf(tmp.name + '.nc')\n",
    "                \n",
    "                ds_old.close()\n",
    "                ds_new.close()\n",
    "                del ds_old\n",
    "                del ds_new\n",
    "                \n",
    "                ds = xr.open_dataset(tmp.name + '.nc')\n",
    "                \n",
    "                ds.to_netcdf(out_nc_path)\n",
    "\n",
    "            \n",
    "        # update cursor regardless\n",
    "        cursor.updateRow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
