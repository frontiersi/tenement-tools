{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals (dev)\n",
    "FOLDER_MODULES = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "GRP_LYR_FILE = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx\"\n",
    "\n",
    "# set gdal global environ\n",
    "import os\n",
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN'] = 'EMPTY_DIR'\n",
    "os.environ['CPL_VSIL_CURL_ALLOWED_EXTENSIONS '] = 'tif'\n",
    "os.environ['VSI_CACHE '] = 'TRUE'\n",
    "os.environ['GDAL_HTTP_MULTIRANGE '] = 'YES'\n",
    "os.environ['GDAL_HTTP_MERGE_CONSECUTIVE_RANGES '] = 'YES'\n",
    "\n",
    "# also set rasterio env variables\n",
    "rasterio_env = {\n",
    "    'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n",
    "    'CPL_VSIL_CURL_ALLOWED_EXTENSIONS': 'tif',\n",
    "    'VSI_CACHE': True,\n",
    "    'GDAL_HTTP_MULTIRANGE': 'YES',\n",
    "    'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES'\n",
    "}\n",
    "\n",
    "# disable future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# safe imports\n",
    "import sys                  # arcgis comes with these\n",
    "import datetime                 # arcgis comes with these\n",
    "import numpy as np              # arcgis comes with these\n",
    "import arcpy                    # arcgis comes with these\n",
    "from datetime import datetime   # arcgis comes with these\n",
    "\n",
    "# risky imports (not native to arcgis)\n",
    "try:\n",
    "    from osgeo import gdal\n",
    "    from osgeo import ogr\n",
    "    import tempfile\n",
    "    import xarray as xr\n",
    "    import dask\n",
    "    import rasterio\n",
    "    import pystac_client\n",
    "    from odc import stac\n",
    "except:\n",
    "    arcpy.AddError('Python libraries xarray, dask, rasterio, pystac, or odc not installed.')\n",
    "    raise\n",
    "\n",
    "# import tools\n",
    "try:\n",
    "    # shared folder\n",
    "    sys.path.append(FOLDER_SHARED)\n",
    "    import arc, satfetcher, tools\n",
    "\n",
    "    # module folder\n",
    "    sys.path.append(FOLDER_MODULES)\n",
    "    import nrt, cog_odc, cog\n",
    "except:\n",
    "    arcpy.AddError('Could not find tenement tools python scripts (modules, shared).')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'toolbox'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import arcpy\n",
    "\n",
    "tbx = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\"\n",
    "arcpy.ImportToolbox(tbx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need button to create shapefile with relevent attributes\n",
    "# set a folder\n",
    "# create a shapefile of polygons\n",
    "# need a id field, out netcdf, platform, start/end monitor date, other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create monitoring areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new monitoring project database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 7225, in execute\n",
      "  File \"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules\\nrt.py\", line 57, in create_nrt_project\n",
      "    raise ValueError('Requested file location arleady exists. Choose a different name.')\n",
      "ValueError: Requested file location arleady exists. Choose a different name.\n"
     ]
    },
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 000582: Error occurred during execution.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[4]\u001b[0m:\nLine \u001b[0;34m5\u001b[0m:     arcpy.NRT_Create_Project_toolbox(out_folder, out_filename)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\u001b[0m, in \u001b[0;32mNRT_Create_Project\u001b[0m:\nLine \u001b[0;34m718\u001b[0m:   multiValue=\u001b[34mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\toolbox\\tenement-tools-toolbox.pyt\u001b[0m, in \u001b[0;32mNRT_Create_Project\u001b[0m:\nLine \u001b[0;34m715\u001b[0m:   parameterType=\u001b[33m'\u001b[39;49;00m\u001b[33mRequired\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: ERROR 000582: Error occurred during execution.\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "out_folder = r'C:\\Users\\Lewis\\Desktop\\nrt_projects'\n",
    "out_filename = 'ophthalmia_monitoring'\n",
    "\n",
    "# create a new nrt project\n",
    "arcpy.NRT_Create_Project_toolbox(out_folder, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make monitoring areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is up to user using usual arcgis pro tools?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate monitoring areas and update cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syncing monitoring area cubes...\n",
      "Iterating through monitoring areas...\n",
      "Validating monitoring area: A001\n",
      "Syncing monitoring area: A001\n",
      "Syncing cube for monitoring area: C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A001.nc\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n",
      "A total of 1 scenes were found.\n",
      "Replacing url prefix: s3://dea-public-data with https://data.dea.ga.gov.au\n",
      "Converting raw STAC data into xarray dataset via odc-stac.\n",
      "Created xarray dataset via odc-stac successfully.\n",
      "Exporting xarray as netcdf file.\n",
      "Exported xarray as netcdf successfully.\n",
      "Validating monitoring area: A002\n",
      "Syncing monitoring area: A002\n",
      "Syncing cube for monitoring area: C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A002.nc\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n",
      "A total of 1 scenes were found.\n",
      "Replacing url prefix: s3://dea-public-data with https://data.dea.ga.gov.au\n",
      "Converting raw STAC data into xarray dataset via odc-stac.\n",
      "Created xarray dataset via odc-stac successfully.\n",
      "Exporting xarray as netcdf file.\n",
      "Exported xarray as netcdf successfully.\n",
      "Validating monitoring area: A003\n",
      "Syncing monitoring area: A003\n",
      "Syncing cube for monitoring area: C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A003.nc\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n",
      "A total of 1 scenes were found.\n",
      "Replacing url prefix: s3://dea-public-data with https://data.dea.ga.gov.au\n",
      "Converting raw STAC data into xarray dataset via odc-stac.\n",
      "Created xarray dataset via odc-stac successfully.\n",
      "Exporting xarray as netcdf file.\n",
      "Exported xarray as netcdf successfully.\n"
     ]
    }
   ],
   "source": [
    "def sync_nrt_cubes(in_feat, in_epsg=3577, temp=None):\n",
    "    \"\"\"\n",
    "    Queries DEA AWS via STAC and obtains latest imagery \n",
    "    from start of training period in monitoring shapefile\n",
    "    and now. Appends all new images on to end of netcdf and\n",
    "    exports it as a new version.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat: str\n",
    "        A path to an existing monitoring areas gdb feature class.\n",
    "    in_epsg: int\n",
    "        A integer representing a specific epsg code for coordinate system.\n",
    "    \"\"\"   \n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Syncing monitoring area cubes...')\n",
    "                \n",
    "    # validate monitoring area feature class\n",
    "    if not nrt.validate_monitoring_areas(in_feat):\n",
    "        raise ValueError('Monitoring areas feature is invalid.')\n",
    "        \n",
    "    # get input featureclass file, get dir and filename\n",
    "    in_name = os.path.basename(in_feat)     # name of monitor fc\n",
    "    in_gdb = os.path.dirname(in_feat)       # path of gdb\n",
    "    in_path = os.path.splitext(in_gdb)[0]   # path of gdb without ext\n",
    "    in_data_path = in_path + '_' + 'cubes'  # associated cube data folder\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Iterating through monitoring areas...')\n",
    "    \n",
    "    # set required fields and iterate\n",
    "    fields = ['area_id', 'platform', 's_year', 'e_year', 'index', 'Shape@']\n",
    "    with arcpy.da.UpdateCursor(in_feat, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            \n",
    "            # notify\n",
    "            print('Validating monitoring area: {}'.format(row[0]))\n",
    "            \n",
    "            # send off to check if valid\n",
    "            is_valid = nrt.validate_monitoring_area(area_id=row[0],\n",
    "                                                    platform=row[1], \n",
    "                                                    s_year=row[2], \n",
    "                                                    e_year=row[3], \n",
    "                                                    index=row[4])\n",
    "            \n",
    "            if not is_valid:\n",
    "                print('Skipping over invalid monitoring area: {}'.format(row[0]))\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # notify\n",
    "            print('Syncing monitoring area: {}'.format(row[0]))\n",
    "            \n",
    "            # prepare start year from input, get latest year for end\n",
    "            s_year = '{}-01-01'.format(row[2])\n",
    "            #e_year = '{}-12-31'.format(datetime.datetime.now().year)  # e.g. always latest\n",
    "            e_year = '{}-12-31'.format(temp)\n",
    "            \n",
    "            # get parameters for platform\n",
    "            params = nrt.get_satellite_params(platform=row[1])  \n",
    "            \n",
    "            # convert to wgs84 temporarily\n",
    "            srs = arcpy.SpatialReference(4326)\n",
    "            geom = row[5].projectAs(srs)\n",
    "                        \n",
    "            # get bbox of current bbox\n",
    "            bbox = [geom.extent.XMin, geom.extent.YMin, \n",
    "                    geom.extent.XMax, geom.extent.YMax]\n",
    "\n",
    "            # build expected monitoring area data cube and check exists\n",
    "            ds_existing = None\n",
    "            out_nc = os.path.join(in_data_path, 'cube' + '_' + row[0] + '.nc')\n",
    "            if os.path.exists(out_nc):\n",
    "                try:\n",
    "                    # open existing ds\n",
    "                    ds_existing = xr.open_dataset(out_nc)\n",
    "                    \n",
    "                    # get latest datetime to reduce download \n",
    "                    s_year = ds_existing.isel(time=-1)\n",
    "                    s_year = str(s_year['time'].dt.strftime('%Y-%m-%d').values)                       \n",
    "                    \n",
    "                except:\n",
    "                    raise ValueError('Could not open existing dataset - skipping.')\n",
    "                    continue\n",
    "           \n",
    "            \n",
    "            ds = nrt.sync_nrt_cube(out_nc=out_nc,\n",
    "                                   collections=params.get('collections'),\n",
    "                                   bands=params.get('bands'),\n",
    "                                   start_dt=s_year,\n",
    "                                   end_dt=e_year,\n",
    "                                   bbox=bbox,\n",
    "                                   in_epsg=in_epsg,\n",
    "                                   slc_off=False,\n",
    "                                   resolution=params.get('resolution'),\n",
    "                                   ds_existing=ds_existing,\n",
    "                                   chunks={})\n",
    "            \n",
    "            \n",
    "            with rasterio.Env(**rasterio_env):\n",
    "                tools.export_xr_as_nc(ds=ds, filename=out_nc)\n",
    "            \n",
    "                              \n",
    "\n",
    "#ds_new, ds_existing = sync_nrt_cubes(in_feat=r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas', temp=2016)\n",
    "sync_nrt_cubes(in_feat=r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas', temp=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp inputs\n",
    "in_fmask_flags = 'Valid;Snow;Water'\n",
    "in_max_cloud = 0\n",
    "in_veg_idx = 'MAVI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_nrt_cube(ds, in_fmask_flags, in_max_cloud, in_veg_idx):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # checks\n",
    "    #\n",
    "\n",
    "    # notify\n",
    "    print('Getting NetCDF attributes and mask information...')\n",
    "    print('todo')\n",
    "\n",
    "    # TODO ENSURE COG ODC HAS ACTUAL ORIG ATTRS CURRENTLY NOT WORKING\n",
    "    # get attributes from dataset\n",
    "    ds_attrs = ds.attrs\n",
    "    ds_band_attrs = ds[list(ds.data_vars)[0]].attrs\n",
    "    ds_spatial_ref_attrs = ds['spatial_ref'].attrs    \n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Removing invalid pixels...')\n",
    "    print('todo')\n",
    "\n",
    "    # check if expected band name exists\n",
    "    mask_band = arc.get_name_of_mask_band(list(ds.data_vars))\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progess bar\n",
    "    print('fmasking')\n",
    "    #arcpy.SetProgressorLabel('Removing invalid pixels and empty dates...')\n",
    "    #arcpy.SetProgressorPosition(3)\n",
    "\n",
    "    # remove invalid pixels and empty scenes\n",
    "    ds = cog.remove_fmask_dates(ds=ds, \n",
    "                                valid_class=in_fmask_flags, \n",
    "                                max_invalid=in_max_cloud, \n",
    "                                mask_band=mask_band, \n",
    "                                nodata_value=np.nan, \n",
    "                                drop_fmask=True)     \n",
    "    \n",
    "    # get platform name from attributes, error if no attributes\n",
    "    #in_platform = arc.get_platform_from_dea_attrs(ds_attrs)  # todo this doesnt work coz orig_attrs not in ds\n",
    "    in_platform = 'Landsat'\n",
    "    \n",
    "    \n",
    "    # # # # #\n",
    "    # notify and increment progess bar\n",
    "    print('veg index')\n",
    "    #arcpy.SetProgressorLabel('Calculating vegetation index...')\n",
    "    #arcpy.SetProgressorPosition(4)\n",
    "\n",
    "    # conform dea aws band names based on platform\n",
    "    ds = satfetcher.conform_dea_ard_band_names(ds=ds, \n",
    "                                               platform=in_platform.lower()) \n",
    "\n",
    "    # calculate vegetation index \n",
    "    ds = tools.calculate_indices(ds=ds, \n",
    "                                 index=in_veg_idx.lower(), \n",
    "                                 custom_name='veg_idx', \n",
    "                                 rescale=False, \n",
    "                                 drop=True)\n",
    "\n",
    "    # append original attributes on to new band\n",
    "    ds['veg_idx'].attrs = ds_band_attrs \n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_nrt(in_feat, in_fmask_flags='Valid;Snow;Water', in_max_cloud=0, in_veg_idx='MAVI'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat: str\n",
    "        A path to an existing monitoring areas gdb feature class.\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    # notify\n",
    "    #\n",
    "    \n",
    "    # checks  \n",
    "    # is shapefile path called filename = monitoring_areas?\n",
    "    \n",
    "    # get arc params\n",
    "    \n",
    "    \n",
    "    # convert fmask flags as text to numeric code equivalents\n",
    "    in_fmask_flags = [e for e in in_fmask_flags.split(';')]\n",
    "    in_fmask_flags = arc.convert_fmask_codes(in_fmask_flags)\n",
    "\n",
    "    \n",
    "    # notify \n",
    "    print('Getting cube data folder path...')\n",
    "    \n",
    "    # get basename of geodatabase\n",
    "    cube_folder = os.path.dirname(in_feat)\n",
    "    if cube_folder.endswith('.gdb'):\n",
    "        cube_folder = cube_folder.replace('.gdb', '_cubes')\n",
    "    else:\n",
    "        raise ValueError('Could not find associated geodatabase.')\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Converting geodatabase feature to temporary shapefile...')\n",
    "    \n",
    "    # get shapefile info\n",
    "    tmp = tempfile.mkdtemp()\n",
    "\n",
    "    # load feature as shapefile at temp directory\n",
    "    #feat = r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas'\n",
    "    arcpy.conversion.FeatureClassToShapefile(in_feat, tmp)\n",
    "    \n",
    "    # open temp shapefile\n",
    "    drv = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    shp = ogr.Open(os.path.join(tmp, 'monitoring_areas.shp'), 0)\n",
    "    lyr = shp.GetLayer()\n",
    "    num_feats = lyr.GetFeatureCount()\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Performing change detection...')\n",
    "    \n",
    "    # iter each monitoring area, mask, clean, veg index and ewmacd\n",
    "    for f_idx in range(num_feats):\n",
    "        \n",
    "        #mask_value = 1\n",
    "    \n",
    "        # get current feature area id, layer from geojson\n",
    "        feat = lyr.GetFeature(f_idx)\n",
    "        area_id = feat.GetField('area_id')\n",
    "        geom = ogr.Open(feat.ExportToJson(), 0)\n",
    "        new_lyr = geom.GetLayer() \n",
    "        \n",
    "        # notify\n",
    "        print('Opening cube for area: {}...'.format(area_id))\n",
    "        \n",
    "        # open associated netcdf\n",
    "        out_nc = os.path.join(cube_folder, 'cube_{}.nc'.format(area_id))\n",
    "        ds = xr.open_dataset(out_nc)\n",
    "        \n",
    "        \n",
    "        # prepare \n",
    "        print('Preparing cube')\n",
    "        ds = prepare_nrt_cube(ds=ds, \n",
    "                              in_fmask_flags=in_fmask_flags, \n",
    "                              in_max_cloud=in_max_cloud, \n",
    "                              in_veg_idx=in_veg_idx)\n",
    "        \n",
    "        \n",
    "        # notify\n",
    "        print('Masking pixels where outside monitoring area...')\n",
    "        \n",
    "        # get mask as numpy array\n",
    "        mask = nrt.mask_xr_via_polygon(geom=new_lyr, \n",
    "                                       x=ds['x'].data, \n",
    "                                       y=ds['y'].data, \n",
    "                                       bbox=ds.geobox.extent.boundingbox, \n",
    "                                       transform=ds.geobox.transform, \n",
    "                                       ncols=len(ds['x']), \n",
    "                                       nrows=len(ds['y']), \n",
    "                                       mask_value=1)\n",
    "        \n",
    "        # apply mask to current dataset, set everything outside to nan\n",
    "        ds = ds.where(mask)\n",
    "        \n",
    "        # get medians of each image\n",
    "        ds = ds.median(['x', 'y'], keep_attrs=True)\n",
    "        \n",
    "        # notify\n",
    "        print('Calculating change using EWMACD...')\n",
    "        print('todo')\n",
    "        \n",
    "        return ds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cube data folder path...\n",
      "Converting geodatabase feature to temporary shapefile...\n",
      "Performing change detection...\n",
      "Opening cube for area: A001...\n",
      "Preparing cube\n",
      "Getting NetCDF attributes and mask information...\n",
      "todo\n",
      "Removing invalid pixels...\n",
      "todo\n",
      "fmasking\n",
      "Removing dates where too many invalid pixels.\n",
      "Filling invalid pixels with requested nodata value.\n",
      "Dropping mask band.\n",
      "Removed invalid images successfully.\n",
      "veg index\n",
      "Conforming DEA ARD satellite band names.\n",
      "Satellite band names conformed successfully.\n",
      "Calculating indices: mavi.\n",
      "Calculating index: mavi\n",
      "Renamed default indices.\n",
      "Calculated indices successfully.\n",
      "Masking pixels where outside monitoring area...\n",
      "Calculating change using EWMACD...\n",
      "todo\n"
     ]
    }
   ],
   "source": [
    "ds = perform_nrt(in_feat=r'C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas',\n",
    "                        in_fmask_flags=in_fmask_flags) # make sure flags are 1, 5, 7 at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['veg_idx'].isel(time=0).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(r'C:\\Users\\Lewis\\Desktop\\clean testing\\mavi.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = ds.median(['x', 'y'])\n",
    "\n",
    "vec['veg_idx'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #xmin, ymin, xmax, ymax = bbox.left, bbox.bottom, bbox.right, bbox.top\n",
    "    \n",
    "    #transform = ds.geobox.transform\n",
    "    #geotransform = (transform[2], transform[0], 0.0, \n",
    "                    #transform[5], 0.0, transform[4])\n",
    "    \n",
    "    #dst_rast = gdal.GetDriverByName('MEM').Create('', ncols, nrows, bands=1, eType=gdal.GDT_Byte)\n",
    "    #dst_rb = dst_rast.GetRasterBand(1)\n",
    "    #dst_rb.Fill(0)\n",
    "    #dst_rb.SetNoDataValue(0)\n",
    "    #dst_rast.SetGeoTransform(geotransform)\n",
    "    \n",
    "    #rst = gdal.RasterizeLayer(dst_rast, [1], new_lyr, burn_values=[mask_value])\n",
    "    \n",
    "    #dst_rast.FlushCache()   \n",
    "\n",
    "    #arr = dst_rast.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "    #mask = xr.DataArray(data=arr,\n",
    "                        #dims=['y', 'x'],\n",
    "                        #coords={\n",
    "                            #'y': ds['y'].data,\n",
    "                            #'x': ds['x'].data\n",
    "                        #})\n",
    "\n",
    "    #print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ds.where(mask).copy(deep=True)\n",
    "out = out.median(dim=['x', 'y'], keep_attrs=True)\n",
    "#out['nbart_red'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['nbart_red'].isel(time=0).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A001.nc\")\n",
    "ds = ds.compute()\n",
    "\n",
    "#ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['nbart_red'].isel(time=-50).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\Lewis\\Desktop\\testing\\area.tif<h2>Messages</h2>Start Time: Thursday, 2 December 2021 8:24:49 PM<br/>Succeeded at Thursday, 2 December 2021 8:24:50 PM (Elapsed Time: 0.81 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Lewis\\\\Desktop\\\\testing\\\\area.tif'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tif from vectors\n",
    "arcpy.conversion.FeatureToRaster(in_features=r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring.gdb\\monitoring_areas\", \n",
    "                                 field='area_id', \n",
    "                                 out_raster=r\"C:\\Users\\Lewis\\Desktop\\testing\\area.tif\", \n",
    "                                 cell_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_area = xr.open_dataset(r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\ophthalmia_monitoring_cubes\\cube_A001.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ras = xr.open_rasterio(r\"C:\\Users\\Lewis\\Desktop\\testing\\area.tif\")\n",
    "ds_ras = ds_ras.where(ds_ras == 0, 1)\n",
    "ds_ras = ds_ras.squeeze(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ds_ras.interp_like(ds_area, method='nearest')\n",
    "mask = mask.where(mask == 1, 0)\n",
    "ds_area = ds_area.where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_area['nbart_red'].isel(time=0).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1785.5, -999. , 3497. , -999. ,  513. , -999. , 3019. , -999. ,\n",
       "       -999. ,  680. ,  889.5, -999. ,  457. ,  505. , -999. , -999. ,\n",
       "        466. , -999. , 2501. , -999. ,  499. ,  538.5, -999. , -999. ,\n",
       "        572. , -999. ,  655.5, -999. , 3751.5, -999. ,  792. , -999. ,\n",
       "        844.5, -999. ,  838.5, -999. ,  697. , -999. ,  633. , -999. ,\n",
       "       2211.5, -999. , 1874.5, -999. , 2520. , -999. ,  490.5, -999. ,\n",
       "        544.5, -999. ,  516. , -999. ,  503. , -999. ,  497. , -999. ,\n",
       "        457. , -999. , -999. ,  414.5, -999. ,  461. , -999. , -999. ,\n",
       "        477.5, -999. ,  550.5, -999. ,  557. , -999. , -999. ,  629. ,\n",
       "       -999. ,  633. , -999. ,  652.5, -999. , -999. ,  720.5,  740.5,\n",
       "       -999. ,  637.5, -999. , 3438. , -999. , -999. ,  496. , -999. ,\n",
       "        521.5, -999. ,  528.5, -999. ,  549. , -999. , 4357. , -999. ,\n",
       "        741. , -999. ,  551.5, -999. ,  503.5,  544.5, -999. ,  590. ,\n",
       "       -999. ,  613. , -999. ,  712.5, -999. ,  660.5, -999. ,  767.5,\n",
       "       -999. ,  826. , -999. ,  768. , -999. ,  729. , -999. ,  713. ,\n",
       "       -999. ,  728.5, -999. ,  602. , -999. ,  599. , -999. , -999. ,\n",
       "        561.5, -999. ,  527.5, -999. ,  529.5, -999. , -999. ,  525. ,\n",
       "       -999. ,  536. , -999. , 4936.5, -999. ,  510. , -999. ,  508. ,\n",
       "       -999. ,  542.5, -999. ,  559. , -999. ,  596. , -999. ,  641. ,\n",
       "       -999. ,  671.5, -999. ,  496.5,  727. , -999. ,  702. , -999. ,\n",
       "        721.5, -999. ,  706.5, -999. ,  788.5, -999. ,  694. , -999. ,\n",
       "        837.5,  574.5,  571. , -999. , -999. , 8361. , -999. ,  525. ,\n",
       "       -999. ,  579.5, -999. , -999. ,  550. , -999. ,  533. , -999. ,\n",
       "       4713. , -999. ,  525.5, -999. ,  521.5, -999. , -999. ,  640. ,\n",
       "       -999. ,  705.5,  760.5, -999. ,  650.5, -999. ,  678.5, -999. ,\n",
       "        702.5, -999. ,  673.5,  638.5, -999. ,  664.5, -999. ,  922.5,\n",
       "       -999. ,  657. , -999. , 4442. , -999. ,  614. , -999. ,  620. ,\n",
       "       -999. , 1239.5, -999. ,  615.5, -999. ,  714.5, -999. ,  619.5,\n",
       "       -999. ,  664. , -999. ,  595.5, -999. ,  650.5, -999. ,  672. ,\n",
       "       -999. ,  703. , -999. ,  798. , -999. ,  831. , -999. ,  813.5,\n",
       "       -999. ,  841. , -999. ,  879.5, -999. , -999. ,  575. , -999. ,\n",
       "        558. , -999. , 2799.5, -999. ,  456.5, -999. , 2266.5, -999. ,\n",
       "        511. , -999. ,  472. , -999. ,  480.5, -999. ,  549.5, -999. ,\n",
       "        511. , -999. ,  530. ,  583. , -999. ,  571.5, -999. ,  624.5,\n",
       "       -999. ,  685.5, -999. ,  727.5, -999. ,  734. , -999. ,  710.5,\n",
       "       -999. , 4650. , -999. ,  734.5, -999. , 1325. , -999. ,  772.5,\n",
       "        792. ,  768. ,  692. , -999. ,  596. , -999. , -999. ,  784.5,\n",
       "       -999. ,  655.5, -999. ,  678.5, -999. ,  632. , -999. ,  654. ,\n",
       "       -999. ,  748. , -999. ,  722. , -999. ,  718.5, -999. ,  788. ,\n",
       "       -999. ,  860. , -999. ,  942.5, -999. ,  874.5, -999. ,  919. ,\n",
       "        830.5, 1238. , 1637.5,  206. ,  686.5,  762. ,  844. , -999. ,\n",
       "       -999. ,  884. , -999. ,  882. , -999. ,  884. , -999. ,  943.5,\n",
       "       -999. ,  906.5, -999. ,  934. , 1572.5,  775. ,  803.5,  776. ,\n",
       "       -999. , 1241. , 5691. , -999. , 2449.5, 4015.5, -999. , -999. ,\n",
       "        645.5,  679. , -999. ,  725. , -999. ,  740.5, -999. ,  813. ,\n",
       "       -999. ,  891. , -999. ,  698. , -999. ,  791. , -999. , 1056. ,\n",
       "       -999. , -999. ,  875. , -999. , 3362.5, -999. , -999. , -999. ,\n",
       "       -999. ,  800. , -999. ,  820. , -999. ,  766.5, -999. ,  853. ,\n",
       "       -999. , 1017.5, -999. ,  921.5,  828.5, -999. ,  882. , -999. ,\n",
       "       1171. , -999. , -999. , -999. , -999. , -999. , -999. ,  632.5,\n",
       "       -999. ,  762. ,  583.5,  983.5, -999. ,  609. , -999. , -999. ,\n",
       "        550.5, -999. , -999. ,  592.5, -999. ,  564.5, -999. ,  592. ,\n",
       "       -999. ,  621. , -999. ,  672.5,  731.5, -999. , 4595. , -999. ,\n",
       "        773. , -999. , -999. ,  810.5, -999. ,  753.5,  708. , -999. ,\n",
       "       -999. ,  649. ,  617. , -999. ,  667. , -999. ,  712. , -999. ,\n",
       "        634. , -999. , 1593. , -999. ,  631. , -999. ,  567. , -999. ,\n",
       "        577.5, -999. ,  645. , -999. , 3136.5, -999. ,  587.5, -999. ,\n",
       "        600. , -999. ,  634.5, -999. ,  733. , -999. ,  869.5, -999. ,\n",
       "        744. , -999. ,  770.5, -999. , 1033.5, -999. ,  740. , -999. ,\n",
       "        794.5, -999. ,  723. , -999. ,  718. , -999. ,  649.5, -999. ,\n",
       "        843. , 1220. , -999. , 1565.5, -999. , 2939. , -999. ,  525.5,\n",
       "       -999. ,  553. , -999. , 1650.5, -999. , 4585. , -999. ,  506. ,\n",
       "       -999. ,   87. , -999. ,  512.5, -999. ,  626. , -999. ,  591. ,\n",
       "       -999. ,  626. , -999. ,  667.5, -999. ,  789. , -999. , 1040.5,\n",
       "       -999. ,  709.5, -999. ,  764. , -999. ,  800. , -999. ,  805.5,\n",
       "       -999. ,  625. , -999. ,  598. , -999. ,  615. , -999. ,  648. ,\n",
       "       -999. ,  641.5, -999. ,  641.5, -999. , 3210. , -999. ,  561. ,\n",
       "       -999. ,  604.5, -999. ,  561. , -999. , 2410. , -999. , 4753. ,\n",
       "       -999. ,  519. , -999. ,  552.5, -999. ,  656.5, -999. ,  630. ,\n",
       "       -999. ,  683. , -999. ,  766. , -999. ,  778. , -999. , 2593. ,\n",
       "       -999. , 2130.5, -999. ,  836. , -999. ,  719. , -999. , 3377.5,\n",
       "       -999. ,  536. , -999. , 6682.5, -999. ,  575.5, -999. ,  536.5,\n",
       "       -999. , 1833.5, -999. ,  507.5, -999. ,  499.5, -999. ,  503. ,\n",
       "       -999. ,  504.5, -999. ,  523. , -999. ,  542.5, -999. ,  552. ,\n",
       "       -999. ,  605.5, -999. , 2255.5, -999. ,  688.5, -999. ,  796.5,\n",
       "       -999. ,  706.5, -999. ,  719.5, -999. ,  792. , -999. ,  794. ,\n",
       "       -999. , 3630.5, -999. ,  928. , -999. , 8348.5, -999. ,  713. ,\n",
       "       -999. , 3085. , -999. ,  596.5, -999. ,  561. , -999. ,  574. ,\n",
       "       -999. ,  572.5, -999. ,  571. , -999. , 5590. , -999. ,  496. ,\n",
       "       -999. ,  488.5, -999. ,  512. , -999. , 3733. , -999. ,  569.5,\n",
       "       -999. ,  596. , -999. ,  669.5, -999. ,  809. , -999. ,  717.5,\n",
       "       -999. ,  693.5, -999. ,  740. , -999. ,  735. , -999. ,  750. ,\n",
       "       -999. , 1868. , -999. ,  666.5, -999. ,  553. , -999. ,  659.5,\n",
       "       -999. ,  845. , -999. ,  598.5, -999. ,  679. , -999. ,  610. ,\n",
       "       -999. ,  562. , -999. ,  531. , -999. ,  579.5, -999. ,  528. ,\n",
       "       -999. , 3448. , -999. ,  603. , -999. ,  606.5, -999. ,  625. ,\n",
       "       -999. ,  852. , -999. ,  751. , -999. , 1215. , -999. ,  811. ,\n",
       "       -999. ,  789. , -999. , 1594. , -999. ,  854.5, -999. ,  610. ,\n",
       "       -999. ,  645.5, -999. , 3680.5, -999. ,  596.5, -999. ,  608. ,\n",
       "       -999. ,  548. , -999. ,  888. , -999. , 2183.5, -999. ,  541.5,\n",
       "       -999. ,  549. , -999. , 6054.5, -999. ,  533.5, -999. ,  540. ,\n",
       "       -999. ,  558. , -999. ,  602. , -999. ,  681.5, -999. ,  743. ,\n",
       "       -999. , 1165. , -999. , -999. , 2090. , -999. ,  768. , -999. ,\n",
       "        785. , -999. , 4528. , -999. , 1169. , -999. ,  763.5, -999. ,\n",
       "        575. , -999. ,  609.5, -999. ,  609. , -999. , 1426. , -999. ,\n",
       "        564. ,  542.5, -999. , -999. ,  560. , -999. ,  538. , -999. ,\n",
       "        555.5, -999. ,  545.5, -999. ,  593.5, -999. ,  501. , -999. ,\n",
       "        705. , -999. , -999. ,  797. , -999. ,  904.5, -999. ])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_medians = ds_area.median(dim=['x', 'y'], keep_attrs=True)\n",
    "ds_medians['nbart_red'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    # check folder exists\n",
    "    #if not os.path.exists(out_folder):\n",
    "        #raise ValueError('Requested folder does not exist.')\n",
    "        \n",
    "    # check file does not already exist\n",
    "    #if os.path.exists(out_filepath):\n",
    "        #raise ValueError('Requested file location arleady exists. Choose a different name.')\n",
    "    \n",
    "    # build project geodatbase\n",
    "    #out_filepath = arcpy.management.CreateFileGDB(out_folder, out_filename)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Generating database feature class...')\n",
    "    \n",
    "    # temporarily disable auto-visual of outputs\n",
    "    arcpy.env.addOutputsToMap = False\n",
    "    \n",
    "    # create feature class and wgs84 spatial ref sys\n",
    "    srs = arcpy.SpatialReference(4326)\n",
    "    out_feat = arcpy.management.CreateFeatureclass(out_path=out_filepath, \n",
    "                                                   out_name='monitoring_areas', \n",
    "                                                   geometry_type='POLYGON',\n",
    "                                                   spatial_reference=srs)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Generating database domains...')\n",
    "    \n",
    "    # create platform domain\n",
    "    arcpy.management.CreateDomain(in_workspace=out_filepath, \n",
    "                                  domain_name='dom_platforms', \n",
    "                                  domain_description='Platform name (Landsat or Sentinel)',\n",
    "                                  field_type='TEXT', \n",
    "                                  domain_type='CODED')\n",
    "    \n",
    "    # generate coded values to platform domain\n",
    "    dom_values = {'Landsat': 'Landsat', 'Sentinel': 'Sentinel'}\n",
    "    for dom_value in dom_values:\n",
    "        arcpy.management.AddCodedValueToDomain(in_workspace=out_filepath, \n",
    "                                               domain_name='dom_platforms', \n",
    "                                               code=dom_value, \n",
    "                                               code_description=dom_values.get(dom_value))\n",
    "\n",
    "\n",
    "    # notify\n",
    "    print('Generating database fields...') \n",
    "    \n",
    "    # add area id field to featureclass   \n",
    "    arcpy.management.AddField(in_table=out_feat, \n",
    "                              field_name='area_id', \n",
    "                              field_type='TEXT', \n",
    "                              field_alias='Area ID',\n",
    "                              field_length=200,\n",
    "                              field_is_required='REQUIRED')\n",
    "            \n",
    "    \n",
    "    # notify todo - delete if we dont want defaults\n",
    "    print('Generating database defaults...')  \n",
    "    \n",
    "    # set default platform\n",
    "    arcpy.management.AssignDefaultToField(in_table=out_feat, \n",
    "                                          field_name='platform',\n",
    "                                          default_value='Landsat')   \n",
    "           \n",
    "           \n",
    "    # notify\n",
    "    print('Creating NetCDF data folder...') \n",
    "    \n",
    "    # create output folder\n",
    "    out_nc_folder = os.path.join(out_folder, '{}_cubes'.format(out_filename))\n",
    "    if os.path.exists(out_nc_folder):\n",
    "        try:\n",
    "            shutil.rmtree(out_nc_folder)\n",
    "        except:\n",
    "            raise ValueError('Could not delete {}'.format(out_nc_folder))\n",
    "\n",
    "    # create new folder\n",
    "    os.makedirs(out_nc_folder)\n",
    "    \n",
    "    \n",
    "    # notify\n",
    "    print('Adding data to current map...') \n",
    "    \n",
    "    # enable auto-visual of outputs\n",
    "    arcpy.env.addOutputsToMap = True\n",
    "    \n",
    "    try:\n",
    "        # get active map, add feat\n",
    "        aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "        mp = aprx.activeMap\n",
    "        mp.addDataFromPath(out_feat)\n",
    "    \n",
    "    except:\n",
    "        arcpy.AddWarning('Could not find active map. Add monitor areas manually.')        \n",
    "        \n",
    "    # notify\n",
    "    print('Created new monitoring project database successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor tool\n",
    "# select shapefile\n",
    "# run checks\n",
    "# loop through each record in shapefile\n",
    "# get date time of last time\n",
    "# query stac for all dates above this\n",
    "# if new records, create new netcdf using odc-stac like func for bb, etc\n",
    "# append to existing netcdf and save\n",
    "\n",
    "# get input shapefile file, get dir and filename\n",
    "out_path = os.path.dirname(out_shp)\n",
    "out_name = os.path.basename(out_shp)\n",
    "\n",
    "fields = ['AreaID', 'NetCDF', 'Platform', 'VegIdx', 'YrStart', 'YrEnd', 'Shape@']\n",
    "with arcpy.da.UpdateCursor(out_shp, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        area_id = row[0]\n",
    "        nc = row[1]\n",
    "        platform = row[2]\n",
    "        veg_idx = row[3]\n",
    "        year_start = row[4]\n",
    "        year_end = row[5]\n",
    "        geom = row[6]\n",
    "\n",
    "        # temp\n",
    "        in_epsg = 3577\n",
    "        in_res = 30\n",
    "\n",
    "        # get as bbox\n",
    "        bbox = [geom.extent.XMin, geom.extent.YMin, \n",
    "                geom.extent.XMax, geom.extent.YMax]\n",
    "        \n",
    "        # get collections and bands based on platform\n",
    "        if platform == 'Landsat':\n",
    "            collections = ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3']\n",
    "            bands = ['nbart_red', 'nbart_green', 'nbart_blue']\n",
    "        else:\n",
    "            raise ValueError('Not yet implemented')\n",
    "\n",
    "        # if netcdf field is empty, add path to row\n",
    "        if nc == ' ' or nc == '' or nc is None:\n",
    "            \n",
    "            # notify\n",
    "            print('Querying stac for new Area ID: {}'.format(area_id))\n",
    "            \n",
    "            # update row with nc path\n",
    "            out_nc_path = os.path.join(out_path, 'area_{}.nc'.format(area_id))\n",
    "            row[1] = out_nc_path\n",
    "            \n",
    "            # get dates\n",
    "            in_from_date = '{}-01-01'.format(year_start)\n",
    "            #in_to_date = '{}-12-31'.format(datetime.now().year)  # testing\n",
    "            in_to_date = '2020-03-01'\n",
    "            \n",
    "            # notify\n",
    "            print('Getting new data for period: {} to {}'.format(in_from_date, in_to_date))\n",
    "            \n",
    "            # get me the data!\n",
    "            ds = fetch_odc_xr(collections=collections, \n",
    "                              in_from_date=in_from_date, \n",
    "                              in_to_date=in_to_date, \n",
    "                              bbox=bbox, \n",
    "                              bands=bands, \n",
    "                              in_epsg=3577, \n",
    "                              in_res=30, \n",
    "                              like=None)\n",
    "                \n",
    "            # download and export netcdf to output folder\n",
    "            with rasterio.Env(**rasterio_env):\n",
    "                tools.export_xr_as_nc(ds=ds, filename=out_nc_path)\n",
    "           \n",
    "        else:\n",
    "            # notify\n",
    "            print('Querying stac for existing Area ID: {}'.format(area_id))\n",
    "            \n",
    "            # get output nc path\n",
    "            out_nc_path = nc\n",
    "            \n",
    "            # load existing netcdf\n",
    "            ds_old = xr.open_dataset(out_nc_path)\n",
    "                  \n",
    "            # notify\n",
    "            print('Existing cube has {} images'.format(len(ds_old['time'])))\n",
    "            \n",
    "            # get latest datetime from ds old\n",
    "            latest_dt = ds_old.isel(time=-1)\n",
    "            in_from_date = str(latest_dt['time'].dt.strftime('%Y-%m-%d').values)                                    \n",
    "            \n",
    "            # get now\n",
    "            in_to_date = '{}-12-31'.format(datetime.now().year)  # testing\n",
    "            #in_to_date = '2021-06-01'\n",
    "            \n",
    "            \n",
    "                   \n",
    "            # notify\n",
    "            print('Adding data for period: {} to {}'.format(in_from_date, in_to_date))\n",
    "                  \n",
    "            # get me the data!\n",
    "            ds_new = fetch_odc_xr(collections=collections, \n",
    "                                  in_from_date=in_from_date, \n",
    "                                  in_to_date=in_to_date, \n",
    "                                  bbox=bbox, \n",
    "                                  bands=bands, \n",
    "                                  in_epsg=None, \n",
    "                                  in_res=None, \n",
    "                                  like=ds_old)\n",
    "                  \n",
    "            # notify\n",
    "            print('New cube has {} images'.format(len(ds_new['time'])))\n",
    "            \n",
    "            # download and compute\n",
    "            with rasterio.Env(**rasterio_env):\n",
    "                ds_new = ds_new.compute()            \n",
    "            \n",
    "            # combine but exclude duplicates CHECK THIS CAREFULLY\n",
    "            ds_old = ds_old.combine_first(ds_new)\n",
    "                  \n",
    "            # notify\n",
    "            print('Newly synced cube now has {} images'.format(len(ds_old['time'])))\n",
    "                  \n",
    "            # export new to named file temp, close old, then overwrite\n",
    "            with tempfile.NamedTemporaryFile() as tmp:\n",
    "                ds_old.to_netcdf(tmp.name + '.nc')\n",
    "                \n",
    "                ds_old.close()\n",
    "                ds_new.close()\n",
    "                del ds_old\n",
    "                del ds_new\n",
    "                \n",
    "                ds = xr.open_dataset(tmp.name + '.nc')\n",
    "                \n",
    "                ds.to_netcdf(out_nc_path)\n",
    "\n",
    "            \n",
    "        # update cursor regardless\n",
    "        cursor.updateRow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
