{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final EWMACD Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T08:28:30.215718Z",
     "start_time": "2022-05-18T08:28:30.188794Z"
    },
    "code_folding": [
     143
    ]
   },
   "outputs": [],
   "source": [
    "# globals (dev)\n",
    "FOLDER_MODULES = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "GRP_LYR_FILE = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx\"\n",
    "\n",
    "# set gdal global environ\n",
    "import os\n",
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN'] = 'EMPTY_DIR'\n",
    "os.environ['CPL_VSIL_CURL_ALLOWED_EXTENSIONS '] = 'tif'\n",
    "os.environ['VSI_CACHE '] = 'TRUE'\n",
    "os.environ['GDAL_HTTP_MULTIRANGE '] = 'YES'\n",
    "os.environ['GDAL_HTTP_MERGE_CONSECUTIVE_RANGES '] = 'YES'\n",
    "\n",
    "# also set rasterio env variables\n",
    "rasterio_env = {\n",
    "    'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n",
    "    'CPL_VSIL_CURL_ALLOWED_EXTENSIONS':'tif',\n",
    "    'VSI_CACHE': True,\n",
    "    'GDAL_HTTP_MULTIRANGE': 'YES',\n",
    "    'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES'\n",
    "}\n",
    "\n",
    "# safe imports\n",
    "import sys                      # arcgis comes with these\n",
    "import shutil                   # arcgis comes with these\n",
    "import datetime                 # arcgis comes with these\n",
    "import numpy as np              # arcgis comes with these\n",
    "import pandas as pd             # arcgis comes with these\n",
    "import arcpy                    # arcgis comes with these\n",
    "import tempfile                 # arcgis comes with these\n",
    "import matplotlib.pyplot as plt\n",
    "import smtplib\n",
    "import mimetypes\n",
    "from datetime import datetime   # arcgis comes with these\n",
    "from email.message import EmailMessage\n",
    "from email.utils import make_msgid\n",
    "\n",
    "\n",
    "\n",
    "# risky imports (not native to arcgis)\n",
    "try:\n",
    "    import xarray as xr\n",
    "    import dask\n",
    "    import rasterio\n",
    "    import pystac_client\n",
    "    import osr\n",
    "    import json\n",
    "    from scipy.signal import savgol_filter\n",
    "    from odc import stac\n",
    "    from osgeo import gdal\n",
    "    from osgeo import ogr\n",
    "    from osgeo import osr\n",
    "except:\n",
    "    arcpy.AddError('Python libraries xarray, dask, rasterio, pystac, or odc not installed.')\n",
    "    raise # return\n",
    "\n",
    "# import tools\n",
    "try:\n",
    "    # shared folder\n",
    "    sys.path.append(FOLDER_SHARED)\n",
    "    import arc, satfetcher, tools\n",
    "\n",
    "    # module folder\n",
    "    sys.path.append(FOLDER_MODULES)\n",
    "    import nrt, cog_odc, cog\n",
    "except:\n",
    "    arcpy.AddError('Could not find tenement tools python scripts (modules, shared).')\n",
    "    raise\n",
    "    \n",
    "# disable future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=dask.array.core.PerformanceWarning)\n",
    "    \n",
    "# grab parameter values \n",
    "in_feat = r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\test2\\monitoring_areas.gdb\\monitoring_areas\"\n",
    "in_ongoing = False\n",
    "in_time_interval = 24\n",
    "#in_email_from = parameters[3].value                # email from \n",
    "#in_smtp_server = parameters[4].value               # email smtp server \n",
    "#in_smtp_port = parameters[5].value                 # email smtp port \n",
    "#in_smtp_username = parameters[6].value             # email smtp username \n",
    "#in_smtp_password = parameters[7].value             # email smtp password \n",
    "\n",
    "\n",
    "# # # # #\n",
    "# notify user and set up progress bar\n",
    "#arcpy.AddMessage('Beginning NRT Monitoring of areas.')\n",
    "#arcpy.SetProgressor(type='step', \n",
    "                    #message='Preparing parameters...',\n",
    "                    #min_range=0, max_range=20)\n",
    "        \n",
    "# set up initial continous monitoring var\n",
    "continue_monitoring = True\n",
    "\n",
    "# check if time interval is > 0\n",
    "#in_time_interval = in_time_interval * 60 * 60\n",
    "#if in_time_interval <= 0:\n",
    "    #arcpy.AddError('Time interval must be above 0 hours.')\n",
    "    #raise\n",
    "\n",
    "\n",
    "# # # # #\n",
    "# notify and increment progress bar\n",
    "#arcpy.SetProgressorLabel('Preparing parameters...')\n",
    "#arcpy.SetProgressorPosition(1)\n",
    "\n",
    "# get path to monitoring areas feature\n",
    "feat_desc = arcpy.Describe(in_feat)\n",
    "in_feat = os.path.join(feat_desc.path, feat_desc.name)\n",
    "\n",
    "\n",
    "# # # # #\n",
    "# notify and increment progress bar\n",
    "#arcpy.SetProgressorLabel('Validating monitoring areas...')\n",
    "#arcpy.SetProgressorPosition(2)\n",
    "\n",
    "# validate monitoring area feature class\n",
    "try:\n",
    "    nrt.validate_monitoring_areas(in_feat)\n",
    "except:\n",
    "    arcpy.AddError('Monitoring areas feature is invalid.')\n",
    "    raise # return\n",
    "\n",
    "    \n",
    "# # # # #\n",
    "# notify and increment progress bar\n",
    "#arcpy.SetProgressorLabel('Loading monitoring area json data...')\n",
    "#arcpy.SetProgressorPosition(2)\n",
    "    \n",
    "# prepare path to expected json file\n",
    "in_path = os.path.dirname(in_feat)\n",
    "in_path = os.path.splitext(in_path)[0]\n",
    "in_path = os.path.dirname(in_path)\n",
    "#in_data_path = os.path.join(in_path, 'data.json')\n",
    "    \n",
    "    \n",
    "# # # # #\n",
    "# notify and increment progress bar\n",
    "#arcpy.SetProgressorLabel('Loading monitoring area features...')\n",
    "#arcpy.SetProgressorPosition(2)\n",
    "\n",
    "# set required fields\n",
    "fields = [\n",
    "    'area_id', \n",
    "    'platform', \n",
    "    's_year', \n",
    "    'e_year', \n",
    "    'index', \n",
    "    'persistence', \n",
    "    'rule_1_min_conseqs', \n",
    "    'rule_1_inc_plateaus', \n",
    "    'rule_2_min_zone', \n",
    "    'rule_3_num_zones', \n",
    "    'ruleset', \n",
    "    'alert', \n",
    "    'method',\n",
    "    'alert_direction', \n",
    "    'email', \n",
    "    'ignore', \n",
    "    'color_border',\n",
    "    'color_fill',\n",
    "    'global_id', \n",
    "    'SHAPE@'\n",
    "]\n",
    "\n",
    "# get feature count and data\n",
    "try:\n",
    "    #feats = arcpy.da.SearchCursor(in_feat, fields)\n",
    "    feats = []\n",
    "    with arcpy.da.SearchCursor(in_feat, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            feats.append(row)\n",
    "except:\n",
    "    arcpy.AddError('Could not open monitoring areas feature.')\n",
    "    raise # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T08:28:30.350025Z",
     "start_time": "2022-05-18T08:28:30.347805Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "main thread is not in main loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[14]\u001b[0m:\nLine \u001b[0;34m2\u001b[0m:     reload(nrt)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\importlib\\__init__.py\u001b[0m, in \u001b[0;32mreload\u001b[0m:\nLine \u001b[0;34m169\u001b[0m:   _bootstrap._exec(spec, module)\n",
      "File \u001b[0;34m<frozen importlib._bootstrap>\u001b[0m, in \u001b[0;32m_exec\u001b[0m:\nLine \u001b[0;34m630\u001b[0m:   \n",
      "File \u001b[0;34m<frozen importlib._bootstrap_external>\u001b[0m, in \u001b[0;32mexec_module\u001b[0m:\nLine \u001b[0;34m728\u001b[0m:   \n",
      "File \u001b[0;34m<frozen importlib._bootstrap>\u001b[0m, in \u001b[0;32m_call_with_frames_removed\u001b[0m:\nLine \u001b[0;34m219\u001b[0m:   \n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules\\nrt.py\u001b[0m, in \u001b[0;32m<module>\u001b[0m:\nLine \u001b[0;34m11\u001b[0m:    matplotlib.use(\u001b[33m'\u001b[39;49;00m\u001b[33mAgg\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\matplotlib\\__init__.py\u001b[0m, in \u001b[0;32muse\u001b[0m:\nLine \u001b[0;34m1162\u001b[0m:  plt.switch_backend(name)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m, in \u001b[0;32mswitch_backend\u001b[0m:\nLine \u001b[0;34m232\u001b[0m:   close(\u001b[33m\"\u001b[39;49;00m\u001b[33mall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m, in \u001b[0;32mclose\u001b[0m:\nLine \u001b[0;34m801\u001b[0m:   _pylab_helpers.Gcf.destroy_all()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\matplotlib\\_pylab_helpers.py\u001b[0m, in \u001b[0;32mdestroy_all\u001b[0m:\nLine \u001b[0;34m87\u001b[0m:    manager.destroy()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\matplotlib\\backends\\_backend_tk.py\u001b[0m, in \u001b[0;32mdestroy\u001b[0m:\nLine \u001b[0;34m467\u001b[0m:   \u001b[36mself\u001b[39;49;00m.window.destroy()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\tkinter\\__init__.py\u001b[0m, in \u001b[0;32mdestroy\u001b[0m:\nLine \u001b[0;34m2061\u001b[0m:  \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m \u001b[36mlist\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.children.values()): c.destroy()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\tkinter\\__init__.py\u001b[0m, in \u001b[0;32mdestroy\u001b[0m:\nLine \u001b[0;34m2305\u001b[0m:  \u001b[36mself\u001b[39;49;00m.tk.call(\u001b[33m'\u001b[39;49;00m\u001b[33mdestroy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mself\u001b[39;49;00m._w)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: main thread is not in main loop\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(nrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T08:31:08.987680Z",
     "start_time": "2022-04-30T08:31:08.987413Z"
    }
   },
   "outputs": [],
   "source": [
    "# todo:\n",
    "# remove field rule 1 inc plateaus ... ?\n",
    "# remove field rule 2 bidirection. we do this via alert dir now - DONE\n",
    "# change rule 2 min stdv to min zone - DONE\n",
    "# consider a 'negative remover in positive areas' and vice versa. consider during alert?... add as extra alert dirs? - DONE\n",
    "# append all mon area field info to netcdf attr, check at start of run for change, delete cube if change\n",
    "# check if ruleset contains rule without a value entered during area creation (fields accepts nulls) - FORCED REQUIRED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T08:31:09.151691Z",
     "start_time": "2022-04-30T08:31:09.151436Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'inc_any':      'Incline only (any)', \n",
    "# 'dec_any':      'Decline only (any)', \n",
    "# 'inc_pos':      'Incline only (+ zones only)', \n",
    "# 'dec_neg':      'Decline only (- zones only)', \n",
    "# 'both_any':     'Incline or Decline (any)',\n",
    "# 'both_pos_neg': 'Incline or Decline (+/- zones only)',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T11:09:53.388941Z",
     "start_time": "2022-04-30T11:09:53.388586Z"
    }
   },
   "outputs": [],
   "source": [
    "# tips\n",
    "# use higher persistence for dynamic (1) and lower for static (0.5)\n",
    "# use decline in - or pos in + only for dynamic to avoid new regime shifts triggering alarm\n",
    "# turn off spikes for dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T05:59:20.601558Z",
     "start_time": "2022-05-05T05:59:20.428201Z"
    },
    "code_folding": [
     1,
     6,
     54,
     67,
     80,
     208,
     241,
     289,
     308,
     311,
     319,
     329,
     332,
     340,
     357,
     409,
     428,
     440,
     468,
     505,
     527,
     567,
     588,
     619,
     632,
     659,
     693,
     731,
     783,
     824,
     864,
     938,
     957,
     980,
     1019,
     1079,
     1132,
     1185,
     1200,
     1265,
     1314,
     1340,
     1380,
     1464,
     1516,
     1586,
     1618,
     1652,
     1675,
     1678,
     1689,
     1696,
     1699,
     1706,
     1715,
     1723,
     1732,
     1740,
     1743,
     1751,
     1754,
     1762,
     1765,
     1773,
     1776,
     1784,
     1787,
     1795,
     1798,
     1806,
     1809,
     1817,
     1820,
     1830,
     1838,
     1841,
     1863,
     1874,
     1885,
     1898,
     1909,
     1920,
     1931,
     1944,
     1959,
     1970
    ]
   },
   "outputs": [],
   "source": [
    "# TESTING REMOVE THIS WHEN DONE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "class MonitoringArea:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # TESTING_END_DT REMOVE THIS WHEN DONE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    def __init__(self, feat, path):\n",
    "        \n",
    "        # feature fields\n",
    "        self.area_id = feat[0]\n",
    "        self.platform = feat[1]\n",
    "        self.s_year = feat[2]\n",
    "        self.e_year = feat[3]\n",
    "        self.index = feat[4]\n",
    "        self.persistence = feat[5]\n",
    "        self.rule_1_min_conseqs = feat[6]\n",
    "        self.rule_1_inc_plateaus = feat[7]\n",
    "        self.rule_2_min_zone = feat[8]\n",
    "        self.rule_3_num_zones = feat[9]\n",
    "        self.ruleset = feat[10]\n",
    "        self.alert = feat[11]\n",
    "        self.method = feat[12]\n",
    "        self.alert_direction = feat[13]\n",
    "        self.email = feat[14]\n",
    "        self.ignore = feat[15]\n",
    "        self.color = feat[16]\n",
    "        self.global_id = feat[17]\n",
    "        \n",
    "        # feature geometry\n",
    "        self.raw_geom = feat[18]\n",
    "        self.prj_geom = None\n",
    "        \n",
    "        # path to project folder\n",
    "        self.path = path\n",
    "        \n",
    "        # xr datasets\n",
    "        self.ds_old = None\n",
    "        self.ds_new = None\n",
    "        self.ds_cmb = None\n",
    "        self.ds_anl = None\n",
    "        \n",
    "        # current alert info\n",
    "        self.alert_date = None\n",
    "        self.alert_zone = None\n",
    "        self.alert_flag = None\n",
    "        \n",
    "        # html and graph info\n",
    "        self.alert_html = None\n",
    "        self.alert_graph = None\n",
    "        \n",
    "        # TESTING REMOVE THIS WHEN DONE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        self.TESTING_END_DT = None\n",
    "        \n",
    "\n",
    "    def show_area_info(self):\n",
    "        \"\"\"\n",
    "        Simple function to print field information to \n",
    "        screen.\n",
    "        \"\"\"\n",
    "        \n",
    "        # print field attributes\n",
    "        for field in list(vars(self))[:16]:\n",
    "            print('{}: {}'.format(field, vars(self).get(field)))\n",
    "            \n",
    "        return\n",
    "\n",
    "    \n",
    "    def show_alert_info(self):\n",
    "        \"\"\"\n",
    "        Simple function to print alert information to \n",
    "        screen.\n",
    "        \"\"\"\n",
    "        \n",
    "        # print field attributes\n",
    "        for field in list(vars(self))[25:31]:\n",
    "            print('{}: {}'.format(field, vars(self).get(field)))\n",
    "            \n",
    "        return    \n",
    "    \n",
    "    \n",
    "    def validate_area(self):\n",
    "        \"\"\"\n",
    "        Checks all required monitoring area parameters are \n",
    "        valid. Raises an error if invalid.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check area id\n",
    "        if self.area_id is None:\n",
    "            raise ValueError('No area id exists.')\n",
    "\n",
    "        # check platform\n",
    "        if self.platform not in ['Landsat', 'Sentinel']:\n",
    "            raise ValueError('Platform not Landsat or Sentinel.')\n",
    "\n",
    "        # check start, end years\n",
    "        if not isinstance(self.s_year, int):\n",
    "            raise ValueError('Start year not an integer.')\n",
    "        elif not isinstance(self.e_year, int):\n",
    "            raise ValueError('End year not an integer.')\n",
    "        elif self.s_year < 1980 or self.s_year > 2050:\n",
    "            raise ValueError('Start year not between 1980-2050.')        \n",
    "        elif self.e_year < 1980 or self.e_year > 2050:\n",
    "            raise ValueError('End year not between 1980-2050.')          \n",
    "        elif self.e_year <= self.s_year:\n",
    "            raise ValueError('End year is <= start year.')           \n",
    "        elif abs(self.e_year - self.s_year) < 2:\n",
    "            raise ValueError('Training period < 2 years in length.')  \n",
    "        elif self.platform == 'Sentinel' and self.s_year < 2016:\n",
    "            raise ValueError('Start year must be >= 2016 for Sentinel data.')  \n",
    "\n",
    "        # check index\n",
    "        if self.index not in ['NDVI', 'MAVI', 'kNDVI']:\n",
    "            raise ValueError('Index must be NDVI, MAVI or kNDVI.')\n",
    "\n",
    "        # check persistence\n",
    "        if self.persistence is None:\n",
    "            raise ValueError('No persistence exists.')\n",
    "        elif self.persistence < 0.001 or self.persistence > 9.999:\n",
    "            raise ValueError('Persistence not between 0.0001 and 9.999.')\n",
    "\n",
    "        # check rule 1 min consequtives\n",
    "        if self.rule_1_min_conseqs is None:\n",
    "            raise ValueError('No rule 1 min conseqs exists.')\n",
    "        elif self.rule_1_min_conseqs < 0 or self.rule_1_min_conseqs > 999:\n",
    "            raise ValueError('Rule 1 min conseqs not between 0 and 999.')\n",
    "\n",
    "        # check rule 1 inc plateaus\n",
    "        if self.rule_1_inc_plateaus is None:\n",
    "            raise ValueError('No rule 1 inc plateaus exists.')\n",
    "        elif self.rule_1_inc_plateaus not in ['Yes', 'No']:\n",
    "            raise ValueError('Rule 1 inc plateaus must be Yes or No.')\n",
    "\n",
    "        # check rule 2 min zone\n",
    "        if self.rule_2_min_zone is None:\n",
    "            raise ValueError('No rule 2 min zone exists.')\n",
    "        elif self.rule_2_min_zone < 1 or self.rule_2_min_zone > 11:\n",
    "            raise ValueError('Rule 2 min zone not between 1 and 11.') \n",
    "            \n",
    "        # check rule 3 num zones\n",
    "        if self.rule_3_num_zones is None:\n",
    "            raise ValueError('No rule 3 num zones exists.')\n",
    "        elif self.rule_3_num_zones < 1 or self.rule_3_num_zones > 11:\n",
    "            raise ValueError('rule 3 num zones not between 1 and 11.')             \n",
    "\n",
    "        # set up allowed rulesets\n",
    "        rulesets = [\n",
    "            '1 only',\n",
    "            '2 only',\n",
    "            '3 only',\n",
    "            '1 and 2',\n",
    "            '1 and 3',\n",
    "            '2 and 3',\n",
    "            '1 or 2',\n",
    "            '1 or 3',\n",
    "            '2 or 3',\n",
    "            '1 and 2 and 3',\n",
    "            '1 or 2 and 3',\n",
    "            '1 and 2 or 3',\n",
    "            '1 or 2 or 3'\n",
    "        ]\n",
    "        \n",
    "        # check ruleset   \n",
    "        if self.ruleset not in rulesets:\n",
    "            raise ValueError('Rulset not supported.')\n",
    "\n",
    "        # check alert\n",
    "        if self.alert not in ['Yes', 'No']:\n",
    "            raise ValueError('Alert must be Yes or No.')\n",
    "\n",
    "        # check method\n",
    "        if self.method not in ['Static', 'Dynamic']:\n",
    "            raise ValueError('Method must be Static or Dynamic')\n",
    "\n",
    "        # set up alert directions \n",
    "        alert_directions = [\n",
    "            'Incline only (any)', \n",
    "            'Decline only (any)', \n",
    "            'Incline only (+ zones only)', \n",
    "            'Decline only (- zones only)', \n",
    "            'Incline or Decline (any)',\n",
    "            'Incline or Decline (+/- zones only)'\n",
    "        ]\n",
    "\n",
    "        # check alert direction\n",
    "        if self.alert_direction not in alert_directions:\n",
    "            raise ValueError('Alert direction is not supported.')\n",
    "\n",
    "        # check email address\n",
    "        if self.alert == 'Yes' and self.email is None:\n",
    "            raise ValueError('No email provided.')\n",
    "        elif self.email is not None and '@' not in self.email:\n",
    "            raise ValueError('Email address invalid.')\n",
    "\n",
    "        # check ignore\n",
    "        if self.ignore not in ['Yes', 'No']:\n",
    "            raise ValueError('Ignore must be Yes or No.')\n",
    "            \n",
    "        # check global id\n",
    "        if self.global_id is None:\n",
    "            raise ValueError('No global id exists.')\n",
    "            \n",
    "        # check path provided\n",
    "        if self.path is None:\n",
    "            raise ValueError('No project path exists.')\n",
    "\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def set_old_xr(self):\n",
    "        \"\"\"\n",
    "        If a path exists for old xr, load and set it. \n",
    "        If old xr does not exist (i.e., first time area\n",
    "        has been monitored, set None. If error during load, \n",
    "        set old xr to None.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            # build expected netcdf filepath\n",
    "            nc_path = os.path.join(self.path, self.global_id + '.nc')\n",
    "        \n",
    "            # check input path and store if so, else none\n",
    "            if os.path.exists(nc_path):\n",
    "                with xr.open_dataset(nc_path) as ds:\n",
    "                    ds.load()\n",
    "                \n",
    "                # set old ds\n",
    "                self.ds_old = ds\n",
    "                return\n",
    "            \n",
    "            else:\n",
    "                # set to none\n",
    "                self.ds_old = None\n",
    "                return\n",
    "        \n",
    "        except:\n",
    "            self.ds_old = None\n",
    "            return\n",
    "        \n",
    "        return\n",
    "            \n",
    "    \n",
    "    def validate_old_xr(self):\n",
    "        \"\"\"\n",
    "        If old xr is loaded and set, validates it to ensure \n",
    "        it has attributes that match current area feature. \n",
    "        Done to ensure user has not changed area field values\n",
    "        since last run. If old xr attributes and current area \n",
    "        do not match, set old xr dataset to None (i.e., reset\n",
    "        it).\n",
    "        \"\"\"\n",
    "        \n",
    "        # if old xr doesnt exist, leave\n",
    "        if self.ds_old is None:\n",
    "            return\n",
    "            \n",
    "        # check xr is valid\n",
    "        if not isinstance(self.ds_old, xr.Dataset):\n",
    "            self.ds_old = None\n",
    "            return\n",
    "        elif not hasattr(self.ds_old, 'attrs'):\n",
    "            self.ds_old = None\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # check key attrs in dataset\n",
    "            attrs = list(vars(self))[:16]\n",
    "            for attr in attrs:\n",
    "                if not hasattr(self.ds_old, attr):\n",
    "                    self.ds_old = None\n",
    "                    return\n",
    "\n",
    "            # check all vals match match (remove tail, add method back on)\n",
    "            attrs = attrs[:11] + ['method']\n",
    "            for attr in attrs:\n",
    "                new = str(vars(self).get(attr))\n",
    "                old = str(self.ds_old.attrs.get(attr))\n",
    "\n",
    "                if new != old:\n",
    "                    self.ds_old = None\n",
    "                    return\n",
    "                    \n",
    "        except:\n",
    "            self.ds_old = None\n",
    "            return\n",
    "        \n",
    "        return\n",
    "            \n",
    "    \n",
    "    # TODO SET END DATE TO 2050 WHEN DONE\n",
    "    def set_new_xr(self):\n",
    "        \"\"\"\n",
    "        Fetches all available digital earth australia (dea) \n",
    "        landsat/sentinel data for area bounding box. The \n",
    "        resulting data is set to the new xr. If old xr \n",
    "        exists (is not None), new xr is then subset down to \n",
    "        only the dates that dont exist in old xr. \n",
    "        \n",
    "        If an error occurs, an error is raised. \n",
    "        \"\"\"\n",
    "        \n",
    "        # set endpoint\n",
    "        STAC_ENDPOINT = 'https://explorer.sandbox.dea.ga.gov.au/stac'\n",
    "        \n",
    "        # check platform is valid\n",
    "        if self.platform not in ['Landsat', 'Sentinel']:\n",
    "            raise ValueError('Platform not supported.')\n",
    "\n",
    "        # prepare dea stac search parameters\n",
    "        if self.platform == 'Landsat':\n",
    "            \n",
    "            # set dea collection names\n",
    "            collections = [\n",
    "                'ga_ls5t_ard_3',\n",
    "                'ga_ls7e_ard_3',\n",
    "                'ga_ls8c_ard_3',\n",
    "                'ga_ls8c_ard_provisional_3'\n",
    "            ]\n",
    "            \n",
    "            # set bands\n",
    "            bands = [\n",
    "                'nbart_red', \n",
    "                'nbart_green', \n",
    "                'nbart_blue', \n",
    "                'nbart_nir', \n",
    "                'nbart_swir_1', \n",
    "                'nbart_swir_2', \n",
    "                'oa_fmask'\n",
    "            ]\n",
    "            \n",
    "        elif self.platform == 'Sentinel':\n",
    "            \n",
    "            # set dea collection names\n",
    "            collections = [\n",
    "                's2a_ard_granule',  # todo: use ver 3 when avail\n",
    "                's2b_ard_granule',  # todo: use ver 3 when avail\n",
    "                'ga_s2am_ard_provisional_3',\n",
    "                'ga_s2bm_ard_provisional_3'\n",
    "            ]\n",
    "            \n",
    "            # set bands\n",
    "            bands = [\n",
    "                'nbart_red', \n",
    "                'nbart_green', \n",
    "                'nbart_blue', \n",
    "                'nbart_nir_1', \n",
    "                'nbart_swir_2', \n",
    "                'nbart_swir_3', \n",
    "                'fmask'\n",
    "            ]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # ensure raw geom is in wgs84 (set prj_geom)\n",
    "            srs = arcpy.SpatialReference(4326)\n",
    "            self.prj_geom = self.raw_geom.projectAs(srs)\n",
    "            \n",
    "            # convert to bounding box in wgs84\n",
    "            prj_bbox = [\n",
    "                self.prj_geom.extent.XMin,\n",
    "                self.prj_geom.extent.YMin,\n",
    "                self.prj_geom.extent.XMax,\n",
    "                self.prj_geom.extent.YMax\n",
    "            ]\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            # get all avail dea satellite data without compute\n",
    "            self.ds_new = nrt.fetch_cube_data(collections=collections, \n",
    "                                              bands=bands, \n",
    "                                              start_dt='1980-01-01', \n",
    "                                              end_dt=self.TESTING_END_DT,     #'2050-12-31', \n",
    "                                              bbox=prj_bbox, \n",
    "                                              resolution=10, \n",
    "                                              ds_existing=None)\n",
    "        \n",
    "            # group duplicate times if exist\n",
    "            self.ds_new = satfetcher.group_by_solar_day(self.ds_new)\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            # subset new xr to new dates (if old exists)\n",
    "            if self.ds_old is not None:\n",
    "                \n",
    "                # get last datetime in old dataset\n",
    "                last_dt = self.ds_old['time'].isel(time=-1)\n",
    "                \n",
    "                # get all datetimes in new dataset\n",
    "                new_dts = self.ds_new['time']\n",
    "                new_dts = new_dts.where(new_dts['time'] > last_dt, drop=True)\n",
    "                \n",
    "                # select only new\n",
    "                self.ds_new = self.ds_new.sel(time=new_dts)       \n",
    "                \n",
    "            # enforce none type if no new dates\n",
    "            if len(self.ds_new['time']) == 0:\n",
    "                self.ds_new = None\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def new_xr_dates_found(self):\n",
    "        \"\"\"\n",
    "        Does quick check to see if any new xr dates currently \n",
    "        exist. Returns true if times exist, false if not.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if dates exist\n",
    "        if self.ds_new is None:\n",
    "            return False\n",
    "        elif 'time' not in self.ds_new:\n",
    "            return False\n",
    "        elif len(self.ds_new['time']) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def count_new_xr_dates(self):\n",
    "        \"\"\"\n",
    "        Get number of dates in new xr.\n",
    "        \"\"\"\n",
    "        \n",
    "        # count based on time dim\n",
    "        if self.ds_new is not None:\n",
    "            return len(self.ds_new['time'])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def apply_new_xr_fmask(self):\n",
    "        \"\"\"\n",
    "        Takes the new xr and applies the dea fmask band to \n",
    "        remove invalid pixels and dates. If an error occurs,\n",
    "        error is raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')\n",
    "        \n",
    "        try:\n",
    "            # get mask band name (either be oa_fmask or fmask)\n",
    "            mask = [v for v in self.ds_new if 'mask' in v][0]\n",
    "            \n",
    "            # mask invalid pixels i.e., not valid, water, snow\n",
    "            self.ds_new = cog.remove_fmask_dates(ds=self.ds_new, \n",
    "                                                 valid_class=[1, 4, 5],\n",
    "                                                 max_invalid=0,\n",
    "                                                 mask_band=mask, \n",
    "                                                 nodata_value=np.nan,\n",
    "                                                 drop_fmask=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def apply_new_xr_index(self):\n",
    "        \"\"\"\n",
    "        Takes the new xr and applies user chosen vegetation\n",
    "        index. If an error occurs, error is raised. \n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')\n",
    "        \n",
    "        # check if platform set\n",
    "        if self.platform not in ['Landsat', 'Sentinel']:\n",
    "            raise ValueError('Platform not supported.')\n",
    "            \n",
    "        # check if index set\n",
    "        if self.index not in ['NDVI', 'MAVI', 'kNDVI']:\n",
    "            raise ValueError('Index not supported.')\n",
    "        \n",
    "        try:\n",
    "            # conform dea band names and calc vegetation index\n",
    "            platform = self.platform.lower()\n",
    "            self.ds_new = satfetcher.conform_dea_ard_band_names(ds=self.ds_new, \n",
    "                                                                platform=platform) \n",
    "            \n",
    "            # calculate vegetation index\n",
    "            index = self.index.lower()\n",
    "            self.ds_new = tools.calculate_indices(ds=self.ds_new, \n",
    "                                                  index=index, \n",
    "                                                  custom_name='veg_idx', \n",
    "                                                  rescale=False, \n",
    "                                                  drop=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "            \n",
    "            \n",
    "    def load_new_xr(self):\n",
    "        \"\"\"\n",
    "        Loads new xr values into memory using the xarray \n",
    "        load function. This will result in downloading from \n",
    "        dea and can take awhile.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')\n",
    "        \n",
    "        try:\n",
    "            # load new xr and close connection \n",
    "            self.ds_new.load()\n",
    "            self.ds_new.close()\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def remove_new_xr_edges(self):\n",
    "        \"\"\"\n",
    "        Sets any pixels in the new xr to nodata (nan) if they occur \n",
    "        within the original bounding box but outside of the vector\n",
    "        boundary of the monitoring area. This is achieved by creating \n",
    "        an in-memory raster of 1s and 0s (in boundary, out boundary) \n",
    "        and applies it to the new dataset. If an error occurs,\n",
    "        no mask is applied.\n",
    "        \"\"\" \n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')\n",
    "            \n",
    "        # check if raw geometry exists\n",
    "        if self.raw_geom is None:\n",
    "            raise ValueError('No raw area geometry provided.')       \n",
    "        \n",
    "        try:\n",
    "            # take a copy in case of error\n",
    "            tmp = self.ds_new.copy(deep=True)\n",
    "            \n",
    "            # rasterize area polygon, set outside pixels to nan\n",
    "            mask = nrt.rasterize_polygon(ds=self.ds_new, \n",
    "                                         geom=self.raw_geom)\n",
    "            \n",
    "            # mask edge pixels to nan\n",
    "            self.ds_new = self.ds_new.where(mask)\n",
    "            \n",
    "            # check if not all nan\n",
    "            if self.ds_new.to_array().isnull().all():\n",
    "                raise ValueError('Mask set all pixels to nan, rolling back.')  \n",
    "\n",
    "        except Exception as e:\n",
    "            self.ds_new = tmp\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "            \n",
    "\n",
    "    def reduce_new_xr(self):\n",
    "        \"\"\"\n",
    "        Reduces new xr dataset into temporal medians. That is, one \n",
    "        median vegetation index value for the entire monitoring area \n",
    "        per date. If an error occurs, error is raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')        \n",
    "        \n",
    "        try:\n",
    "            # get temporal medians\n",
    "            self.ds_new = self.ds_new.median(['x', 'y'])\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def interp_new_xr_nans(self):\n",
    "        \"\"\"\n",
    "        Interpolates any existing nan values in new xr linearly.\n",
    "        If nan values still exist after interpolation (often on\n",
    "        edge dates due to lack of extrapolation), these will be\n",
    "        dropped. If error occurs or all values are nan, error is\n",
    "        raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')          \n",
    "\n",
    "        try:\n",
    "            # interpolate na linearly\n",
    "            self.ds_new = self.ds_new.interpolate_na('time')\n",
    "            \n",
    "            # check if any nan\n",
    "            if self.ds_new.to_array().isnull().any():\n",
    "                self.ds_new = self.ds_new.where(~self.ds_new.isnull(), \n",
    "                                                drop=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check we have data remaining\n",
    "        if len(self.ds_new['time']) == 0:\n",
    "            raise ValueError('No data remaining after nodata dropped.')\n",
    "            \n",
    "        return\n",
    "\n",
    "\n",
    "    def append_new_xr_vars(self):\n",
    "        \"\"\"\n",
    "        Appends required xr variables to new xr if do not exist.\n",
    "        These variables are required for storing outputs from \n",
    "        change detection results, cleaned vegetation, etc. If\n",
    "        error, error is raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')  \n",
    "        \n",
    "        # set required variable names\n",
    "        new_vars = [\n",
    "            'veg_clean', \n",
    "            'static_raw', \n",
    "            'static_clean',\n",
    "            'static_rule_one',\n",
    "            'static_rule_two',\n",
    "            'static_rule_three',\n",
    "            'static_zones',\n",
    "            'static_alerts',\n",
    "            'dynamic_raw', \n",
    "            'dynamic_clean',\n",
    "            'dynamic_rule_one',\n",
    "            'dynamic_rule_two',\n",
    "            'dynamic_rule_three',\n",
    "            'dynamic_zones',\n",
    "            'dynamic_alerts'\n",
    "        ]        \n",
    "        \n",
    "        # iter var names and append to xr\n",
    "        for var in new_vars:\n",
    "            if var not in self.ds_new:\n",
    "                da = xr.full_like(self.ds_new['veg_idx'], np.nan)\n",
    "                self.ds_new[var] = da\n",
    "        \n",
    "        return\n",
    "        \n",
    "            \n",
    "    def set_cmb_xr(self):\n",
    "        \"\"\"\n",
    "        Takes old xr (if exists) and concatenates the new \n",
    "        xr dates and values onto the end of the old xr (if\n",
    "        exists). A single cmb (combined) xr is created as\n",
    "        a result. This is done to ensure old xr change and\n",
    "        vegetation values persist from one monitoring\n",
    "        cycle to another. If no old xr exists, new xr is\n",
    "        set to as cmb xr. If error, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new xr exists\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')\n",
    "            \n",
    "        # set new xr to cmb xr if no old xr\n",
    "        if self.ds_old is None:\n",
    "            self.ds_cmb = self.ds_new.copy(deep=True)\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # add new times onto end of old times\n",
    "            xrs = [self.ds_old, self.ds_new]\n",
    "            self.ds_cmb = xr.concat(xrs, dim='time')\n",
    "            \n",
    "            # sort by time\n",
    "            self.ds_cmb = self.ds_cmb.sortby('time')\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "\n",
    "    \n",
    "    def fix_cmb_xr_spikes(self):\n",
    "        \"\"\"\n",
    "        Detects severe vegetation index outliers using the TIMESAT \n",
    "        3.3 median spike detection method. Sets spike values to \n",
    "        nan and then interpolates them, if they exist. If error, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if cmb xr exists\n",
    "        if self.ds_cmb is None:\n",
    "            raise ValueError('No cmb xr provided.')\n",
    "        \n",
    "        try:\n",
    "            # remove outliers via median spike method\n",
    "            da = nrt.remove_spikes(da=self.ds_cmb['veg_idx'], \n",
    "                                   factor=1, \n",
    "                                   win_size=3)\n",
    "            \n",
    "            # interpolate nans linearly\n",
    "            da = da.interpolate_na('time')\n",
    "            \n",
    "            # set result to clean var\n",
    "            self.ds_cmb['veg_clean'] = da            \n",
    "            \n",
    "            # if nans still exists, drop them in cmb xr\n",
    "            if da.isnull().any():\n",
    "                self.ds_cmb = self.ds_cmb.where(~da.isnull(), drop=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check we still have data remaining\n",
    "        if len(self.ds_cmb['time']) == 0:\n",
    "            raise ValueError('No data remaining after no data dropped.')\n",
    "            \n",
    "        return\n",
    "\n",
    "    \n",
    "    # check mean approach\n",
    "    def smooth_cmb_xr_index(self):\n",
    "        \"\"\"\n",
    "        Mildly smoothes the cmb xr clean vegetation index values \n",
    "        using the savitsky golay filter. If error, error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if cmb xr exists\n",
    "        if self.ds_cmb is None:\n",
    "            raise ValueError('No cmb xr provided.')\n",
    "        \n",
    "        # reduce code with a array\n",
    "        da = self.ds_cmb['veg_clean']\n",
    "        \n",
    "        # mask if needed\n",
    "        mask = None\n",
    "        if da.isnull().any():\n",
    "            mask = da.isnull()\n",
    "            da = da.where(~mask, da.mean())\n",
    "        \n",
    "        try:\n",
    "            # get time dimension axis\n",
    "            dims = list(da.dims)\n",
    "            for idx, dim in enumerate(dims):\n",
    "                if dim == 'time':\n",
    "                    axis = idx\n",
    "\n",
    "            # set up kwargs\n",
    "            kwargs={\n",
    "                'window_length': 3, \n",
    "                'polyorder': 1,\n",
    "                'axis': axis\n",
    "            }\n",
    "\n",
    "            # apply savitsky filter to outlier-free index\n",
    "            da = xr.apply_ufunc(savgol_filter, \n",
    "                                da,\n",
    "                                dask='allowed',\n",
    "                                kwargs=kwargs)\n",
    "                \n",
    "            # reset nan values if found\n",
    "            if mask is not None:\n",
    "                da = da.where(~mask, np.nan)\n",
    "            \n",
    "            # update existing values in cmb xr\n",
    "            self.ds_cmb['veg_clean'] = da\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "    \n",
    "\n",
    "    def set_anl_xr(self):\n",
    "        \"\"\"\n",
    "        Takes cmb xr (if exists) and copys it in memory. The\n",
    "        copied xr dataset is then subset to the training start \n",
    "        year (all years before are removed). The result is the anl \n",
    "        (analysis) xr, which is exists to be used temporarily to \n",
    "        generate new change models. If error, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if start year is valid\n",
    "        if self.s_year is None:\n",
    "            raise ValueError('Not training start year provided.')\n",
    "\n",
    "        # check if cmb xr exists\n",
    "        if self.ds_cmb is None:\n",
    "            raise ValueError('No cmb xr provided.')\n",
    "            \n",
    "        try:\n",
    "            # copy cmb xr to anl xr\n",
    "            self.ds_anl = self.ds_cmb.copy(deep=True)\n",
    "            \n",
    "            # remove all dates before start year\n",
    "            dts = self.ds_anl['time.year'] >= self.s_year\n",
    "            self.ds_anl = self.ds_anl.where(dts, drop=True)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check if dates valid\n",
    "        if len(self.ds_anl) == 0:\n",
    "            raise ValueError('No dates remaning in dataset.')\n",
    "        elif len(self.ds_cmb.groupby('time.year')) < 3:\n",
    "            raise ValueError('Not enough years remaining in dataset.')\n",
    "        \n",
    "        return\n",
    "        \n",
    "\n",
    "    # TODO play with smoothing, persistence - \n",
    "    # ALSO TRY MIN TRAINING LENGTH COULD WORK!!! set to 1 year worth of dates, 2 years worth of dates, etc\n",
    "    # ALSO check if dims in correct order for static and dynamic raw outputs\n",
    "    # area_summary.ds['static_raw'] = area_summary.ds['static_raw'].transpose('time', 'y', 'x')\n",
    "    def detect_change_anl_xr(self):\n",
    "        \"\"\"\n",
    "        Performs ewmacd change detection (static and dynamic \n",
    "        types) on anl xr. Uses the raw vegetation index time\n",
    "        series to detect the change. If error or all nan, error \n",
    "        raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "            \n",
    "        # check start and end years valid\n",
    "        if self.s_year is None or self.e_year is None:\n",
    "            raise ValueError('No start and/or end year provided.')        \n",
    "            \n",
    "        # check if persistence is valid\n",
    "        if self.persistence is None:\n",
    "            raise ValueError('No persistence provided.')\n",
    "            \n",
    "        try:\n",
    "            # perform ewmacd change detection\n",
    "            self.ds_anl = nrt.detect_change(ds=self.ds_anl,\n",
    "                                            method='both',\n",
    "                                            var='veg_idx',\n",
    "                                            train_start=self.s_year,\n",
    "                                            train_end=self.e_year,\n",
    "                                            persistence=self.persistence)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check if we have data\n",
    "        for var in ['static_raw', 'dynamic_raw']:\n",
    "            if self.ds_anl[var].isnull().all():\n",
    "                raise ValueError('Change result is empty.')            \n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    # check mean approach\n",
    "    def smooth_anl_xr_change(self):\n",
    "        \"\"\"\n",
    "        Mildly smoothes the anl xr static and dynamic change \n",
    "        signal values using the savitsky golay filter. If error, \n",
    "        error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "            \n",
    "        # set up static and dynamic arrays\n",
    "        da_static = self.ds_anl['static_raw']\n",
    "        da_dynamic = self.ds_anl['dynamic_raw']\n",
    "\n",
    "        # create static mask if needed\n",
    "        mask_static = None\n",
    "        if da_static.isnull().any():\n",
    "            mask_static = da_static.isnull()\n",
    "            da_static = da_static.where(~mask_static, \n",
    "                                        float(da_static.mean()))\n",
    "        \n",
    "        # now create dynamic mask if needed\n",
    "        mask_dynamic = None\n",
    "        if da_dynamic.isnull().any():\n",
    "            mask_dynamic = da_dynamic.isnull()\n",
    "            da_dynamic = da_dynamic.where(~mask_dynamic, \n",
    "                                          float(da_dynamic.mean()))\n",
    "\n",
    "        try:\n",
    "            # get time dimension axis\n",
    "            dims = list(self.ds_anl.dims)\n",
    "            for idx, dim in enumerate(dims):\n",
    "                if dim == 'time':\n",
    "                    axis = idx\n",
    "\n",
    "            # set up kwargs\n",
    "            kwargs={\n",
    "                'window_length': 3, \n",
    "                'polyorder': 1,\n",
    "                'axis': axis\n",
    "            }\n",
    "\n",
    "            # apply savitsky filter to static change values\n",
    "            da_static = xr.apply_ufunc(savgol_filter, \n",
    "                                       da_static,\n",
    "                                       dask='allowed',\n",
    "                                       kwargs=kwargs)\n",
    "\n",
    "            # apply savitsky filter to dynamic change values\n",
    "            da_dynamic = xr.apply_ufunc(savgol_filter, \n",
    "                                        da_dynamic,\n",
    "                                        dask='allowed',\n",
    "                                        kwargs=kwargs)\n",
    "                \n",
    "                        \n",
    "            # reset static nan values if found\n",
    "            if mask_static is not None:\n",
    "                da_static = da_static.where(~mask_static, np.nan)\n",
    "                \n",
    "            # now reset dynamic nan values if found\n",
    "            if mask_dynamic is not None:\n",
    "                da_dynamic = da_dynamic.where(~mask_dynamic, np.nan)\n",
    "            \n",
    "            # update static, dynamic clean values in anl xr\n",
    "            self.ds_anl['static_clean'] = da_static\n",
    "            self.ds_anl['dynamic_clean'] = da_dynamic\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return      \n",
    "\n",
    "    \n",
    "    def transfer_old_to_anl_xr(self):\n",
    "        \"\"\"\n",
    "        Takes old xr and transfers all historical values\n",
    "        (i.e., everything except new values) to the anl xr\n",
    "        (which contains everything from training period \n",
    "        onwards.) This is done to ensure fluctuations in \n",
    "        prior change values persists up until the newest \n",
    "        values. If an error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # if no old xr, skip transfer\n",
    "        if self.ds_old is None:\n",
    "            return\n",
    "        \n",
    "        # check if old and anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "            \n",
    "        # set up relevant vars\n",
    "        data_vars = [\n",
    "            'static_raw', \n",
    "            'static_clean', \n",
    "            'dynamic_raw', \n",
    "            'dynamic_clean'\n",
    "        ]\n",
    "        \n",
    "        # ensure vars exist in both xrs\n",
    "        for var in data_vars:\n",
    "            if var not in self.ds_old or var not in self.ds_anl:\n",
    "                raise ValueError('Missing variables in old and/or new xrs.')\n",
    "        \n",
    "        try:         \n",
    "            # transfer vals from old to anl xr at matching dates\n",
    "            self.ds_anl = nrt.transfer_xr_values(ds_to=self.ds_anl,\n",
    "                                                 ds_from=self.ds_old,\n",
    "                                                 data_vars=data_vars)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "\n",
    "            \n",
    "    def build_zones(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and classifies them into 1 of 11 zones based\n",
    "        on where the change value falls. Honours direction \n",
    "        of change by returning zone value with sign (+/-).\n",
    "        If error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if old and anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "        \n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "                    \n",
    "        try:\n",
    "            # build zone values using smoothed static signal\n",
    "            da = self.ds_anl['static_clean']\n",
    "            self.ds_anl['static_zones'] = xr.apply_ufunc(nrt.build_zones, da)\n",
    "\n",
    "            # build zone values using smoothed dynamic signal\n",
    "            da = self.ds_anl['dynamic_clean']\n",
    "            self.ds_anl['dynamic_zones'] = xr.apply_ufunc(nrt.build_zones, da)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check if we have any data\n",
    "        for var in ['static_zones', 'dynamic_zones']:\n",
    "            if self.ds_anl[var].isnull().all():\n",
    "                raise ValueError('Zone result is empty.')\n",
    "            \n",
    "        return\n",
    "            \n",
    "    \n",
    "    def build_rule_one(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and applies rule one rules to them. Rule one\n",
    "        calculates consequtive runs of values across time.\n",
    "        Honours direction of change by returning value \n",
    "        with sign (+/-). If error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if old and anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "        \n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "        \n",
    "        # check if rule one parameters valid\n",
    "        if self.rule_1_min_conseqs is None:\n",
    "            raise ValueError('No minimum consequtives provided.')\n",
    "        elif self.rule_1_inc_plateaus is None:\n",
    "            raise ValueError('No include plateaus provided.')   \n",
    "            \n",
    "        # prepare plateaus\n",
    "        if self.rule_1_inc_plateaus == 'Yes':\n",
    "            plateaus = True\n",
    "        else:\n",
    "            plateaus = False\n",
    "            \n",
    "        # set kwarg options\n",
    "        kwargs = {\n",
    "            'min_conseqs': self.rule_1_min_conseqs,\n",
    "            'inc_plateaus': plateaus\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # generate all rule 1 runs (+/-) for static change\n",
    "            da = self.ds_anl['static_clean']\n",
    "            self.ds_anl['static_rule_one'] = xr.apply_ufunc(nrt.build_rule_one_runs,\n",
    "                                                            da,\n",
    "                                                            kwargs=kwargs)\n",
    "\n",
    "            # generate all rule 1 runs (+/-) for dynamic change\n",
    "            da = self.ds_anl['dynamic_clean']\n",
    "            self.ds_anl['dynamic_rule_one'] = xr.apply_ufunc(nrt.build_rule_one_runs,\n",
    "                                                             da,\n",
    "                                                             kwargs=kwargs)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if we have any data\n",
    "        for var in ['static_rule_one', 'dynamic_rule_one']:\n",
    "            if self.ds_anl[var].isnull().all():\n",
    "                raise ValueError('Rule one result empty.')\n",
    "            \n",
    "        return\n",
    "            \n",
    "            \n",
    "    def build_rule_two(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and applies rule two rules to them. Rule two\n",
    "        masks out stdv values that fall within a specified\n",
    "        minimum zone threshold. Honours direction of change \n",
    "        by returning value with sign (+/-). If error occurs, \n",
    "        error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if old and anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "        \n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "        \n",
    "        # check if rule two parameters valid\n",
    "        if self.rule_2_min_zone is None:\n",
    "            raise ValueError('No minimum zone provided.')\n",
    "            \n",
    "        # convert zone to std\n",
    "        stdvs = nrt.zone_to_std(self.rule_2_min_zone)[0]\n",
    "         \n",
    "        # set kwarg options\n",
    "        kwargs = {'min_stdv': stdvs}\n",
    "\n",
    "        try:\n",
    "            # generate all rule 2 mask (+/-) for static change\n",
    "            da = self.ds_anl['static_clean']\n",
    "            self.ds_anl['static_rule_two'] = xr.apply_ufunc(nrt.build_rule_two_mask,\n",
    "                                                            da,\n",
    "                                                            kwargs=kwargs)\n",
    "\n",
    "            # generate all rule 2 mask (+/-) for dynamic change\n",
    "            da = self.ds_anl['dynamic_clean']\n",
    "            self.ds_anl['dynamic_rule_two'] = xr.apply_ufunc(nrt.build_rule_two_mask,\n",
    "                                                             da,\n",
    "                                                             kwargs=kwargs)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check if we have any data\n",
    "        for var in ['static_rule_two', 'dynamic_rule_two']:\n",
    "            if self.ds_anl[var].isnull().all():\n",
    "                raise ValueError('Rule two result empty.')\n",
    "            \n",
    "        return\n",
    "            \n",
    "            \n",
    "    def build_rule_three(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and applies rule three rules to them. Rule three\n",
    "        detects sharp zone value spikes that occurr between \n",
    "        dates. Honours direction of change by returning value \n",
    "        with sign (+/-). If error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if old and anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "        \n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds_anl:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "        \n",
    "        # check if rule three parameters valid\n",
    "        if self.rule_3_num_zones is None:\n",
    "            raise ValueError('No number of zones provided.')\n",
    "            \n",
    "        # convert zone to std and multiple by 2 (2 std per zone)\n",
    "        stdvs = nrt.zone_to_std(self.rule_3_num_zones)[0] \n",
    "        stdvs = stdvs * 2\n",
    "        \n",
    "        # set kwarg options\n",
    "        kwargs = {'min_stdv': stdvs}\n",
    "\n",
    "        try:\n",
    "            # generate all rule 3 spikes (+/-) for static change\n",
    "            da = self.ds_anl['static_clean']\n",
    "            self.ds_anl['static_rule_three'] = xr.apply_ufunc(nrt.build_rule_three_spikes,\n",
    "                                                              da,\n",
    "                                                              kwargs=kwargs)\n",
    "\n",
    "            # generate all rule 3 spikes (+/-) for dynamic change\n",
    "            da = self.ds_anl['dynamic_clean']\n",
    "            self.ds_anl['dynamic_rule_three'] = xr.apply_ufunc(nrt.build_rule_three_spikes,\n",
    "                                                               da,\n",
    "                                                               kwargs=kwargs)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)    \n",
    "            \n",
    "        # check if we have any data\n",
    "        for var in ['static_rule_three', 'dynamic_rule_three']:\n",
    "            if self.ds_anl[var].isnull().all():\n",
    "                raise ValueError('Rule two result empty.')\n",
    "                \n",
    "        return\n",
    "\n",
    "                \n",
    "    def build_alerts(self):\n",
    "        \"\"\"\n",
    "        Takes the previously derived rule one, two, three values\n",
    "        and combines them into an alert mask (1, 0) variable for \n",
    "        static and dynamic methods. This method considers \n",
    "        both the user's requested ruleset and the particular\n",
    "        direction of change (incline or decline) required for\n",
    "        alert to be set as true (1). If error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if old and anl xr exists\n",
    "        if self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "        \n",
    "        # set up valid rulesets\n",
    "        valid_rules = [\n",
    "            '1 only', \n",
    "            '2 only', \n",
    "            '3 only', \n",
    "            '1 and 2', \n",
    "            '1 and 3', \n",
    "            '2 and 3', \n",
    "            '1 or 2', \n",
    "            '1 or 3', \n",
    "            '2 or 3', \n",
    "            '1 and 2 and 3', \n",
    "            '1 or 2 and 3',\n",
    "            '1 and 2 or 3', \n",
    "            '1 or 2 or 3'\n",
    "        ]\n",
    "        \n",
    "        # check if ruleset valid\n",
    "        if self.ruleset not in valid_rules:\n",
    "            raise ValueError('Ruleset not supported.')\n",
    "        \n",
    "        # set up valid directions \n",
    "        valid_directions = [\n",
    "            'Incline only (any)',\n",
    "            'Decline only (any)',\n",
    "            'Incline only (+ zones only)',\n",
    "            'Decline only (- zones only)',\n",
    "            'Incline or Decline (any)',\n",
    "            'Incline or Decline (+/- zones only)'\n",
    "        ]\n",
    "        \n",
    "        # check if direction valid\n",
    "        if self.ruleset not in valid_rules:\n",
    "            raise ValueError('Direction not supported.')\n",
    "        \n",
    "        # set kwarg options\n",
    "        kwargs = {\n",
    "            'ruleset': self.ruleset,\n",
    "            'direction': self.alert_direction\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # generate and combines rules into alert for static change \n",
    "            self.ds_anl['static_alerts'] = xr.apply_ufunc(nrt.build_alerts,\n",
    "                                                          self.ds_anl['static_rule_one'],\n",
    "                                                          self.ds_anl['static_rule_two'],\n",
    "                                                          self.ds_anl['static_rule_three'],\n",
    "                                                          kwargs=kwargs)\n",
    "\n",
    "            # generate and combines rules into alert for dynamic change \n",
    "            self.ds_anl['dynamic_alerts'] = xr.apply_ufunc(nrt.build_alerts,\n",
    "                                                           self.ds_anl['dynamic_rule_one'],\n",
    "                                                           self.ds_anl['dynamic_rule_two'],\n",
    "                                                           self.ds_anl['dynamic_rule_three'],\n",
    "                                                           kwargs=kwargs)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check if we have any data\n",
    "        for var in ['static_alerts', 'dynamic_alerts']:\n",
    "            if self.ds_anl[var].isnull().all():\n",
    "                raise ValueError('Alert result empty.')\n",
    "                \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def transfer_anl_to_cmb_xr(self):\n",
    "        \"\"\"\n",
    "        Takes the anl xr values and transfers to new xr dates\n",
    "        to ensure we only have the latest analysis results. \n",
    "        The new results are then added to the cmb xr to ensure\n",
    "        the historical values are not touched yet still \n",
    "        associated with the newest dates and values. If an error \n",
    "        occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if new, anl, cmb xrs valid\n",
    "        if self.ds_new is None:\n",
    "            raise ValueError('No new xr provided.')\n",
    "        elif self.ds_cmb is None:\n",
    "            raise ValueError('No cmb xr provided.')   \n",
    "        elif self.ds_anl is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "\n",
    "        # get relevant change var names in anl xr\n",
    "        data_vars = []\n",
    "        for var in self.ds_anl:\n",
    "            if 'static' in var or 'dynamic' in var:\n",
    "                data_vars.append(var)\n",
    "\n",
    "        # check if vars exist\n",
    "        if len(data_vars) == 0:\n",
    "            raise ValueError('No required variables exist.')\n",
    "            \n",
    "        # check if vars in other xrs\n",
    "        for var in data_vars:\n",
    "            if var not in self.ds_new or var not in self.ds_cmb:\n",
    "                raise ValueError('Required vars not in new or cmb xrs.')\n",
    "                \n",
    "        try:\n",
    "            # transfer vals from anl to new xr at matching dates\n",
    "            self.ds_new = nrt.transfer_xr_values(ds_to=self.ds_new,\n",
    "                                                 ds_from=self.ds_anl,\n",
    "                                                 data_vars=data_vars)\n",
    "            \n",
    "            # transfer vals from new to cmb xr at matching dates\n",
    "            self.ds_cmb = nrt.transfer_xr_values(ds_to=self.ds_cmb,\n",
    "                                                 ds_from=self.ds_new,\n",
    "                                                 data_vars=data_vars)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    def append_cmb_xr_attrs(self):\n",
    "        \"\"\"\n",
    "        Takes the current monitoring area feature's field\n",
    "        values (i.e., attributes) and updates the cmb xr's\n",
    "        internal attributes to match. This is done as the\n",
    "        process strips attributes off the xr due to various\n",
    "        numpy operations. If error, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if cmb xr exists\n",
    "        if self.ds_cmb is None:\n",
    "            raise ValueError('No cmb xr provided.')\n",
    "\n",
    "        try:\n",
    "            # iter required attributes and update\n",
    "            for attr in list(vars(self))[:16]:\n",
    "                attr = {attr: str(vars(self).get(attr))}\n",
    "                self.ds_cmb.attrs.update(attr)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "        \n",
    "        \n",
    "    # need to check zone sign for ANY DIRECTION option\n",
    "    def set_alert_data(self):\n",
    "        \"\"\"\n",
    "        Takes cmb and anl xrs and sets up alert information,\n",
    "        html element (for email) and a png graph (for email).\n",
    "        If error occurs, error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if cmb xr exists\n",
    "        if self.ds_anl is None or self.ds_cmb is None:\n",
    "            raise ValueError('No anl and/or cmb xrs provided.')\n",
    "\n",
    "        # check if method type is valid    \n",
    "        if self.method not in ['Static', 'Dynamic']:\n",
    "            raise ValueError('Alert method not supported.')\n",
    "            \n",
    "        # set up lowercase method name\n",
    "        method = self.method.lower()\n",
    "\n",
    "        try:\n",
    "            # get the second latest date as new object\n",
    "            pix = self.ds_cmb.isel(time=-2).copy(deep=True)\n",
    "            \n",
    "            # set current alert date\n",
    "            dt = pix['time'].dt.strftime('%Y-%m-%d')\n",
    "            alert_date = str(dt.values)\n",
    "            \n",
    "            # set current alert zone and type\n",
    "            self.alert_zone = float(pix[method + '_zones'].values)\n",
    "            alert_type = 'Incline' if self.alert_zone > 0 else 'Decline'\n",
    "            \n",
    "            # set current alert flag\n",
    "            self.alert_flag = False\n",
    "            if float(pix[method + '_alerts'].values) == 1.0:\n",
    "                self.alert_flag = True\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "                \n",
    "        try:\n",
    "            # setup html template for email\n",
    "            html = (\n",
    "                \"\"\"\n",
    "                <div style=\"background-color: #dbf1e5;\">\n",
    "                    <p style=\"color: white; font-family:arial; font-size: 28px; background-color: #3cb371; margin: 20px 0px 0px 0px;\">\n",
    "                        Area: {AREA_ID}\n",
    "                    </p>\n",
    "                    <p style=\"color: black; font-family:arial; font-size:16px; margin: 5px 0px 0px 0px;\"><b>Triggered: </b>{DATE}.</p>\n",
    "                    <p style=\"color: black; font-family:arial; font-size:16px; margin: 5px 0px 0px 0px;\"><b>Change type: </b>{TYPE}.</p>\n",
    "                    <p style=\"color: black; font-family:arial; font-size:16px; margin: 5px 0px 0px 0px;\"><b>Current zone: </b>{ZONE}.</p>\n",
    "                    <p style=\"color: black; font-family:arial; font-size:16px; margin: 5px 0px 0px 0px;\"><b>User Method: </b>{METHOD}.</p>\n",
    "                    <p style=\"color: black; font-family:arial; font-size:16px; margin: 5px 0px 0px 0px;\"><b>User Persistence: </b>{PERSISTENCE}.</p>\n",
    "                    <p style=\"color: black; font-family:arial; font-size:16px; margin: 5px 0px 0px 0px;\"><b>User Ruleset: </b>{RULESET}.</p>\n",
    "                    <p style=\"color: black; font-family:arial; font-size:16px; margin: 5px 0px 0px 0px;\"><b>User Direction: </b>{DIRECTION}.</p>\n",
    "                    <img src=\"cid:{IMAGE_CID}\">\n",
    "                    <!--<p>&nbsp;</p>-->\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            )           \n",
    "            \n",
    "            # insert into html\n",
    "            html = html.replace('{AREA_ID}',     str(self.area_id))\n",
    "            html = html.replace('{DATE}',        str(alert_date))\n",
    "            html = html.replace('{TYPE}',        str(alert_type))\n",
    "            html = html.replace('{DIRECTION}',   str(self.alert_direction))\n",
    "            html = html.replace('{ZONE}',        str(self.alert_zone))\n",
    "            html = html.replace('{METHOD}',      str(self.method))\n",
    "            html = html.replace('{PERSISTENCE}', str(self.persistence))\n",
    "            html = html.replace('{RULESET}',     str(self.ruleset))\n",
    "            html = html.replace('{IMAGE_CID}',   'CID' + '_' + str(self.area_id))\n",
    "\n",
    "            # set html\n",
    "            self.alert_html = html\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        try:\n",
    "            # remove last date (-1 for slice)\n",
    "            da = self.ds_anl.isel(time=slice(0, -1))\n",
    "            \n",
    "            # get array of date time strings\n",
    "            dts = da['time'].dt.strftime('%Y-%m-%d')\n",
    "            dts = [str(dt) for dt in dts.values]\n",
    "\n",
    "            # get veg raw and clean, change, alarm\n",
    "            veg_raw = np.array(da['veg_idx'].values, dtype='float32')\n",
    "            veg_cln = np.array(da['veg_clean'].values, dtype='float32')\n",
    "            chg_cln = np.array(da['{}_clean'.format(method)].values, dtype='float32')\n",
    "\n",
    "            # prepare alerts\n",
    "            alerts = np.array(da['{}_alerts'.format(method)].values, dtype='float32')\n",
    "            alerts = np.where(alerts == 1.0, chg_cln, np.nan)\n",
    "\n",
    "            # set up fig and axes\n",
    "            fig, axs = plt.subplots(nrows=1, \n",
    "                                    ncols=2, \n",
    "                                    figsize=(15, 4), \n",
    "                                    constrained_layout=True)\n",
    "\n",
    "            # set white around graphs transparent\n",
    "            fig.patch.set_facecolor('none')\n",
    "\n",
    "            # set x axis spacing, correct if \n",
    "            x_axis_spacing = int(len(dts) / 30)  # play with this\n",
    "\n",
    "            # set up left graph for veg data\n",
    "            axs[0].plot(dts, veg_raw, color='black', alpha=0.25)\n",
    "            axs[0].plot(dts, veg_cln, color='green')\n",
    "            axs[0].set_title('Vegetation History')\n",
    "            axs[0].set_xlabel('Date')\n",
    "            axs[0].tick_params('x', labelrotation=90)\n",
    "            axs[0].set_ylabel('Vegetation')\n",
    "            axs[0].set_xticks(np.where(dts)[0][0::x_axis_spacing])\n",
    "\n",
    "            # set up right graph for change data\n",
    "            axs[1].plot(dts, chg_cln, color='red')\n",
    "            axs[1].plot(dts, alerts, color='maroon', linestyle='none', marker='o', markersize=3, label='Alert')\n",
    "            axs[1].set_title('Change History')\n",
    "            axs[1].set_xlabel('Date')\n",
    "            axs[1].tick_params('x', labelrotation=90)\n",
    "            axs[1].set_ylabel('Change Deviation')\n",
    "            axs[1].set_xticks(np.where(dts)[0][0::x_axis_spacing])\n",
    "\n",
    "            # set zone color ranges\n",
    "            zone_colors = [\n",
    "                [19, 999,   '#FF7F7F'],\n",
    "                [17,  19,   '#FFA77F'],\n",
    "                [15,  17,   '#FFD37F'],\n",
    "                [13,  15,   '#FFFF73'], \n",
    "                [11,  13,   '#D1FF73'],\n",
    "                [9,   11,   '#A3FF73'],\n",
    "                [7,    9,   '#73FFDF'],\n",
    "                [5,    7,   '#73DFFF'],\n",
    "                [3,    5,   '#73B2FF'], \n",
    "                [1,    3,   '#DF73FF'],\n",
    "                [0,    1,   '#FF73DF'],\n",
    "                [-0,  -1,   '#FF73DF'],\n",
    "                [-1,  -3,   '#DF73FF'],\n",
    "                [-3,  -5,   '#73B2FF'],\n",
    "                [-5,  -7,   '#73DFFF'],\n",
    "                [-7,  -9,   '#73FFDF'],\n",
    "                [-9,  -11,  '#A3FF73'],\n",
    "                [-11, -13,  '#D1FF73'],\n",
    "                [-13, -15,  '#FFFF73'],\n",
    "                [-15, -17,  '#FFD37F'],\n",
    "                [-17, -19,  '#FFA77F'],\n",
    "                [-19, -999, '#FF7F7F'] \n",
    "            ]\n",
    "\n",
    "            # generate zone colors\n",
    "            for c in zone_colors:\n",
    "                axs[1].axhspan(c[0], c[1], color=c[2], alpha=0.20)\n",
    "\n",
    "            # add vertical line for latest date\n",
    "            axs[1].axvline(dts[-1], linestyle='dashed', alpha=0.5, color='black', label=dts[-1])\n",
    "            axs[1].legend()\n",
    "\n",
    "            # finally, set the yaxis limits\n",
    "            y_min = np.nanmin(chg_cln) - 1\n",
    "            y_max = np.nanmax(chg_cln) + 1\n",
    "            axs[1].set_ylim([y_min, y_max])\n",
    "            \n",
    "            # create temp file path and save graph png to it\n",
    "            with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "                fn = tmp.name + '.png'\n",
    "                plt.savefig(fn, facecolor=fig.get_facecolor())\n",
    "            \n",
    "            # set graph path\n",
    "            self.alert_graph = fn\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)            \n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "    def refresh_area_symbology(self):\n",
    "        \"\"\"\n",
    "        Refreshes the alert symbology on the ArcGIS Pro \n",
    "        active map monitoring area(s) layer (if exist). If \n",
    "        an alert zone changes, the feature color code (just \n",
    "        zone value) is updated via arcpy and the feature \n",
    "        symbology is refreshed. If error occurs, an error \n",
    "        is raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if \n",
    "        if self.area_id is None:\n",
    "            raise ValueError('Area identifier not provided.')\n",
    "        elif self.alert_flag is None:\n",
    "            raise ValueError('No current zone provided.')\n",
    "        elif np.isnan(self.alert_flag):\n",
    "            raise ValueError('No current zone provided.')\n",
    "\n",
    "        # check project folder path\n",
    "        if self.path is None:\n",
    "            raise ValueError('No monitoring area project folder provided.')\n",
    "\n",
    "        # build expected geodatabase path and check exists\n",
    "        gdb_path = os.path.join(self.path, 'monitoring_areas.gdb')\n",
    "        if not os.path.exists(gdb_path):\n",
    "            raise ValueError('No monitoring area geodatabase exists.')\n",
    "\n",
    "        # build expected feat class and fields\n",
    "        fc_path = os.path.join(gdb_path, 'monitoring_areas')\n",
    "        fields = ['area_id', 'color']\n",
    "\n",
    "        try:\n",
    "            with arcpy.da.UpdateCursor(fc_path, fields) as cursor:\n",
    "                for row in cursor:\n",
    "                    if row[0] == self.area_id:\n",
    "                        row[1] = self.alert_zone\n",
    "                        cursor.updateRow(row)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        try:           \n",
    "            # for current project, open current map\n",
    "            aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "            m = aprx.activeMap\n",
    "\n",
    "            # remove all layers associated with monitoring areas\n",
    "            for layer in m.listLayers():\n",
    "                if layer.name == 'monitoring_areas':\n",
    "                    m.removeLayer(layer)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        try:           \n",
    "            # re-open current map, re-add area feature\n",
    "            aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "            m = aprx.activeMap\n",
    "            m.addDataFromPath(fc_path)\n",
    "\n",
    "            # update all monitoring area features symbology\n",
    "            for layer in m.listLayers('monitoring_areas'):\n",
    "                arc.apply_monitoring_area_symbology(layer)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def export_cmb_xr(self):\n",
    "        \"\"\"\n",
    "        Exports current cmb xr (which contains everything) \n",
    "        at this point) to netcdf named with global id. An\n",
    "        error will raise an error.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if cmb xr valid\n",
    "        if self.ds_cmb is None:\n",
    "            raise ValueError('No cmb xr provided.')\n",
    "        elif not isinstance(self.ds_cmb, xr.Dataset):\n",
    "            raise TypeError('The cmb xr is not an xr dataset type.')\n",
    "            \n",
    "        # check if path and global id exist\n",
    "        if self.path is None:\n",
    "            raise ValueError('No path provided.')\n",
    "        elif self.global_id is None:\n",
    "            raise ValueError('No global id provided.')\n",
    "        \n",
    "        try:\n",
    "            # build expected netcdf filepath\n",
    "            nc_path = os.path.join(self.path, self.global_id + '.nc')\n",
    "            \n",
    "            # export nc\n",
    "            self.ds_cmb.to_netcdf(nc_path)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "        \n",
    "        return\n",
    "          \n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets all generated area parameters and xr \n",
    "        datasets. \n",
    "        \"\"\"\n",
    "\n",
    "        # set proj geom to none\n",
    "        self.prj_geom = None\n",
    "\n",
    "        # set alert info to none\n",
    "        self.alert_zone =  None\n",
    "        self.alert_flag =  None\n",
    "        self.alert_html =  None\n",
    "        self.alert_graph = None\n",
    "\n",
    "        # iter xrs and close \n",
    "        xrs = [self.ds_old, self.ds_new, self.ds_cmb, self.ds_anl]\n",
    "        for x in xrs:\n",
    "            try:\n",
    "                if x is not None:\n",
    "                    x.close()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # set xrs to none\n",
    "        self.ds_old = None\n",
    "        self.ds_new = None\n",
    "        self.ds_cmb = None\n",
    "        self.ds_anl = None\n",
    "\n",
    "        return  \n",
    "        \n",
    "    \n",
    "    # todo\n",
    "    def run_all(self, TEST_DT):\n",
    "        \"\"\"\n",
    "        Put all processes in here when happy.\n",
    "        \"\"\"\n",
    "                \n",
    "        # ensure area is monitor-allowed\n",
    "        if self.ignore == 'Yes':\n",
    "            return\n",
    "        \n",
    "        # notify\n",
    "        #self.show_area_info()\n",
    "        \n",
    "        # TESTING DATE TIMES\n",
    "        self.TESTING_END_DT = TEST_DT\n",
    "        print('\\n\\nENDING DATETIME: {}'.format(self.TESTING_END_DT))\n",
    "        \n",
    "        \n",
    "        # # # # #   \n",
    "        #arcpy.AddMessage('Starting process for area {}.'.format(area.area_id))\n",
    "        #\n",
    "            \n",
    "            \n",
    "        # # # # # validate area. invalid value triggers error, skip on error\n",
    "        try:\n",
    "            # validate area. invalid value triggers error, skip on error\n",
    "            self.validate_area()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Area {} is invalid, see messages.'.format(area.area_id))\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "            \n",
    "        # # # # # get old xr. if no old or error, sets old to none. pass if none or error\n",
    "        try:\n",
    "            # get old xr. if no old or error, sets old to none. pass if none or error\n",
    "            self.set_old_xr()\n",
    "        except:\n",
    "            arcpy.AddWarning('No existing xr for area, getting new xr.')\n",
    "            print('No existing xr for area, getting new xr.')\n",
    "            pass\n",
    "\n",
    "\n",
    "        # # # # # validate old xr. skips old xr if none. changed attrs sets old xr to none\n",
    "        try:\n",
    "            # validate old xr. skips old xr if none. changed attrs sets old xr to none\n",
    "            self.validate_old_xr()\n",
    "        except:\n",
    "            arcpy.AddWarning('Attributes of existing xr have changed, resetting.')\n",
    "            print('Attributes of existing xr have changed, resetting.')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # # # # # get all sat data. subset new xr to new dates if old xr exists. on error, set new to none, skip\n",
    "        try:\n",
    "            # get all sat data. subset new xr to new dates if old xr exists. on error, set new to none, skip\n",
    "            self.set_new_xr()  \n",
    "\n",
    "            # skip if no new dates, else notify\n",
    "            if self.new_xr_dates_found() is False:\n",
    "                arcpy.AddMessage('No new satellite dates found, skipping.')\n",
    "                print('No new satellite dates found, skipping.')\n",
    "                return #continue \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not obtain satellite data, see messages.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue        \n",
    "        \n",
    "        \n",
    "        # # # # # apply fmask on new xr. if error or no dates, skip\n",
    "        try:\n",
    "            # apply fmask on new xr. if error or no dates, skip\n",
    "            self.apply_new_xr_fmask()\n",
    "\n",
    "            # skip if no new dates, else notify\n",
    "            if self.new_xr_dates_found() is False:\n",
    "                arcpy.AddMessage('No cloud free data exists, skipping.')\n",
    "                print('No cloud free data exists, skipping.')\n",
    "                return #continue    \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not apply fmask, see messages.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue       \n",
    "        \n",
    "        \n",
    "        # # # # # apply veg index on new xr. if error or no dates, skip\n",
    "        try:\n",
    "            # apply veg index on new xr. if error or no dates, skip\n",
    "            self.apply_new_xr_index() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not apply vegetation index, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # load new xr. if error, skip\n",
    "        try:\n",
    "            # load new xr. if error, skip\n",
    "            self.load_new_xr() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not load satellite data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            raise # continue  \n",
    "        \n",
    "        raise\n",
    "    \n",
    "        # # # # # remove edge pixels. if error or empty, return orig new xr\n",
    "        try:\n",
    "            # remove edge pixels. if error or empty, return orig new xr\n",
    "            self.remove_new_xr_edges() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not mask edge pixels, proceeding with them.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "\n",
    "        # # # # # reduce new xr to median value per date. if error, skip\n",
    "        try:\n",
    "            # reduce new xr to median value per date. if error, skip\n",
    "            self.reduce_new_xr() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not reduce data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # interp nans. if any remain, drop. if empty, error and skip\n",
    "        try:\n",
    "            # interp nans. if any remain, drop. if empty, error and skip\n",
    "            self.interp_new_xr_nans() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not interpolate data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # append required vars to new xr. if error, skip\n",
    "        try:\n",
    "            # append required vars to new xr. if error, skip\n",
    "            self.append_new_xr_vars() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not add vars to data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # combine old and new xrs. if no old xr, new xr used. if error, skip\n",
    "        try:\n",
    "            # combine old and new xrs. if no old xr, new xr used. if error, skip\n",
    "            self.set_cmb_xr() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not combine old and new data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # replaces spikes with interp in cmb xr. set result to veg_clean var. if error or no data, skip\n",
    "        try:\n",
    "            # replaces spikes with interp in cmb xr. set result to veg_clean var. if error or no data, skip\n",
    "            self.fix_cmb_xr_spikes() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not remove spike outliers, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # smooth clean veg index with savitsky filter in cmb xr. if error, skip\n",
    "        try:\n",
    "            # smooth clean veg index with savitsky filter in cmb xr. if error, skip\n",
    "            self.smooth_cmb_xr_index() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not smooth index, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # create analysis (anl) xr, remove pre-training years. if error, skip\n",
    "        try:\n",
    "            # create analysis (anl) xr, remove pre-training years. if error, skip\n",
    "            self.set_anl_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not create analysis data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # detect raw static, dynamic change via anl xr, if error, skip\n",
    "        try:\n",
    "            # detect raw static, dynamic change via anl xr, if error, skip\n",
    "            self.detect_change_anl_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not perform change detection, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "            \n",
    "            \n",
    "        # # # # # smooth static, dynamic change via anl xr, if error, skip\n",
    "        try:\n",
    "            # smooth static, dynamic change via anl xr, if error, skip\n",
    "            self.smooth_anl_xr_change()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not smooth change data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # transfer old xr change values to anl xr to persist history. if error, skip\n",
    "        try:\n",
    "            # transfer old xr change values to anl xr to persist history. if error, skip\n",
    "            self.transfer_old_to_anl_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not transfer old data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # build zones. if error, skip\n",
    "        try:\n",
    "            # build zones. if error, skip\n",
    "            self.build_zones()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not generate zones, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # build rule one, two, three. if error, skip\n",
    "        try:\n",
    "            # build rule one, two, three. if error, skip\n",
    "            self.build_rule_one()\n",
    "            self.build_rule_two()\n",
    "            self.build_rule_three()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not generate rules, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # build alerts. if error, skip   \n",
    "        try:\n",
    "            # build alerts. if error, skip\n",
    "            self.build_alerts()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not generate alerts, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # transfer anl xr to cmb xr to persist history. if error, skip\n",
    "        try:\n",
    "            # transfer anl xr to cmb xr to persist history. if error, skip\n",
    "            self.transfer_anl_to_cmb_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not transfer analysis data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # append area field attrs back on to cmb xr. if error, skip\n",
    "        try:\n",
    "            # append area field attrs back on to cmb xr. if error, skip\n",
    "            self.append_cmb_xr_attrs()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not append attributes, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue    \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        # # # # # set alert info, html, graph data. if error, skip\n",
    "        try:\n",
    "            # set alert info, html, graph data. if error, skip\n",
    "            self.set_alert_data()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not extract alert information, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue    \n",
    "\n",
    "            \n",
    "        # show information about current alert\n",
    "        #area.show_alert_info()\n",
    "\n",
    "        \n",
    "        # # # # # refresh monitoring area symbology. if error, skip\n",
    "        try:\n",
    "            # refresh monitoring area symbology. if error, skip\n",
    "            self.refresh_area_symbology()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not refresh symbology, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue    \n",
    "        \n",
    "\n",
    "        # # # # # export cmb xr. if error, skip\n",
    "        try:\n",
    "            # export cmb xr. if error, skip\n",
    "            self.export_cmb_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not export latest netcdf, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue  \n",
    "    \n",
    "    \n",
    "        # on to next area\n",
    "        # ...\n",
    "    \n",
    "        return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing date times for cog\n",
    "TEST_DTS = pd.date_range(start='2015-01-01', end='2022-12-31', freq='2W')\n",
    "TEST_DTS = [dt.strftime('%Y-%m-%d') for dt in TEST_DTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_email = 'mrlewie@outlook.com'\n",
    "host_server = 'smtp.office365.com'\n",
    "host_port = 587\n",
    "host_user = 'mrlewie@outlook.com'\n",
    "host_pass = 'halfLife1985micr'\n",
    "#area.email = 'mrlewie@outlook.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T06:08:00.586243Z",
     "start_time": "2022-05-05T06:08:00.583202Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# meta\n",
    "def create_zone_graph():\n",
    "    \"\"\"\n",
    "    Creares a static zone legend graph for\n",
    "    the footer area of the sent alert email.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # generate dummy graph data\n",
    "        xs = np.arange(0, 31)\n",
    "        ys = np.arange(-11, 12)\n",
    "\n",
    "        # set up fig\n",
    "        fig, ax = plt.subplots(figsize=[15, 8])\n",
    "        ax.set_title('Zone Legend')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_ylabel('Zone')   \n",
    "        fig.patch.set_facecolor('none')\n",
    "\n",
    "        # set zone color ranges\n",
    "        zone_colors = [\n",
    "            [-11, '#FF7F7F'],\n",
    "            [-10, '#FFA77F'],\n",
    "            [-9,  '#FFD37F'],\n",
    "            [-8,  '#FFFF73'], \n",
    "            [-7,  '#D1FF73'],\n",
    "            [-6,  '#A3FF73'],\n",
    "            [-5,  '#73FFDF'],\n",
    "            [-4,  '#73DFFF'],\n",
    "            [-3,  '#73B2FF'], \n",
    "            [-2,  '#DF73FF'],\n",
    "            [-1,  '#FF73DF'],\n",
    "            [ 1,  '#FF73DF'],\n",
    "            [ 2,  '#DF73FF'],\n",
    "            [ 3,  '#73B2FF'],\n",
    "            [ 4,  '#73DFFF'],\n",
    "            [ 5,  '#73FFDF'],\n",
    "            [ 6,  '#A3FF73'],\n",
    "            [ 7,  '#D1FF73'],\n",
    "            [ 8,  '#FFFF73'],\n",
    "            [ 9,  '#FFD37F'],\n",
    "            [ 10, '#FFA77F'],\n",
    "            [ 11, '#FF7F7F'] \n",
    "        ]\n",
    "\n",
    "        # generate hidden lines for labels\n",
    "        for c in zone_colors:\n",
    "            plt.axhline(c[0], color=c[1], alpha=0.75, linewidth=19, label='Zone: {}'.format(c[0]))\n",
    "\n",
    "        # clean up y axis zone ticks\n",
    "        ax.set_yticks(np.arange(-11, 12, step=1))\n",
    "\n",
    "        # place a zero line \n",
    "        plt.axhline(0, linestyle='dashed', alpha=1.0, color='black')\n",
    "\n",
    "        # limit axis to zone extents\n",
    "        plt.ylim([-11.5, 11.5])\n",
    "\n",
    "        # create temp file path and save graph png to it\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "            zone_fn = tmp.name + '.png'\n",
    "            plt.savefig(zone_fn, facecolor=fig.get_facecolor())\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise ValueError(e)\n",
    "        \n",
    "    return zone_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T06:12:55.327569Z",
     "start_time": "2022-05-05T06:12:55.322473Z"
    },
    "code_folding": [
     1,
     62
    ]
   },
   "outputs": [],
   "source": [
    "# not quite done yet, replace testing stuff, do meta\n",
    "def email_alerts(areas, host_email, host_server, host_port, host_user, host_pass):\n",
    "    \"\"\"\n",
    "    Sends an email with all the latest alert\n",
    "    triggers, area info and vegetation and \n",
    "    change graphs for every area that was triggered.\n",
    "    \"\"\"\n",
    "\n",
    "    # check if host email is valid\n",
    "    if host_email is None:\n",
    "        raise ValueError('No host email provided.')\n",
    "    elif '@' not in host_email or '.' not in host_email:\n",
    "        raise ValueError('Host email is invalid.')\n",
    "\n",
    "    # check host server is valid\n",
    "    if host_server is None:\n",
    "        raise ValueError('No host server provided.')\n",
    "\n",
    "    # check if host port valid\n",
    "    if host_port is None:\n",
    "        raise ValueError('No host port provided.')\n",
    "    elif not isinstance(host_port, int):\n",
    "        raise TypeError('Host port must be integer.')\n",
    "\n",
    "    # check if host username and password is valid\n",
    "    if host_user is None:\n",
    "        raise ValueError('No host username provided.')\n",
    "    elif host_pass is None:\n",
    "        raise ValueError('No host password provided.')\n",
    "\n",
    "    # check areas is valid\n",
    "    if not isinstance(areas, list):\n",
    "        raise TypeError('Areas must be a list of area objects.')        \n",
    "\n",
    "    # get a list of any areas with alert data\n",
    "    area_list = []\n",
    "    for area in areas:\n",
    "        \n",
    "        # TESTING TOP TWO !!!\n",
    "        alertable = 'Yes' #area.alert       #TESTING\n",
    "        flagged = True    #area.alert_flag  #TESTING\n",
    "        \n",
    "        has_email = area.email\n",
    "        has_html = area.alert_html\n",
    "        has_graph = area.alert_graph\n",
    "        \n",
    "        # if alertable and currently flagged...\n",
    "        if alertable == 'Yes' and flagged is True:\n",
    "            if has_email and has_html and has_graph:\n",
    "                area_list.append(area)\n",
    "    \n",
    "    # check if anything available, else leave\n",
    "    if len(area_list) == 0:\n",
    "        return\n",
    "        \n",
    "    # iter valid areas and build email content\n",
    "    html_body = ''\n",
    "    for area in area_list:\n",
    "        html_body += area.alert_html\n",
    "        \n",
    "\n",
    "    # build template email html \n",
    "    html = (\n",
    "        \"\"\"\n",
    "        <html>\n",
    "        <body>\n",
    "        <div style=\"background-color: #dbf1e5;\">\n",
    "        <p style=\"color: white; font-family: arial; font-size: 34px; background-color: #3cb371; margin: 0px 0px 10px 0px;\">\n",
    "        Monitoring Area Alert Report\n",
    "        </p>\n",
    "        <p style=\"color: black; font-family:arial; font-size:16px; margin: 0px 0px 0px 0px;\">\n",
    "        This report lists currently active monitoring areas triggered during the monitoring cycle performed\n",
    "        on {RUN_DATE}. Monitoring area that were not triggered are not shown.\n",
    "        </p>\n",
    "        </div>\n",
    "        {BODY_DATA}\n",
    "        <div style=\"background-color: #dbf1e5;\">\n",
    "        <p style=\"color: white; font-family:arial; font-size: 28px; background-color: #3cb371; margin: 20px 0px 0px 0px;\">\n",
    "        Legend\n",
    "        </p>\n",
    "        <img src=\"cid:CID_ZONE_IMAGE\">\n",
    "        </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # if soemthing was triggered...\n",
    "    if html_body != '':\n",
    "\n",
    "        # set current run date\n",
    "        run_date = datetime.now().strftime('%Y-%m-%d %H:%M%S')\n",
    "        \n",
    "        # add details to html body\n",
    "        html = html.replace('{RUN_DATE}', run_date)\n",
    "        html = html.replace('{BODY_DATA}', html_body)\n",
    "\n",
    "        try:\n",
    "            # prepare general email details\n",
    "            msg = EmailMessage()\n",
    "            msg['Subject'] = 'NRT Alerts ({})'.format(run_date)\n",
    "            msg['From'] = host_email\n",
    "            msg['To'] = area.email\n",
    "\n",
    "            # set text content...?\n",
    "            msg.set_content('Text Body')\n",
    "\n",
    "            # set html content\n",
    "            msg.add_alternative(html, subtype='html')\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)        \n",
    "        \n",
    "        # open cids and graphs and add as attachment\n",
    "        for area in area_list:\n",
    "            try:\n",
    "                with open(area.alert_graph, 'rb') as img:\n",
    "\n",
    "                    # set image cid, mime type, attach to email\n",
    "                    img_cid = 'CID' + '_' + str(area.area_id)\n",
    "                    mimetype = mimetypes.guess_type(img.name)[0]\n",
    "                    maintype, subtype = mimetype.split('/')\n",
    "                    msg.get_payload()[1].add_related(img.read(), \n",
    "                                                     maintype=maintype, \n",
    "                                                     subtype=subtype, \n",
    "                                                     cid=img_cid)\n",
    "            except Exception as e:\n",
    "                raise ValueError(e)\n",
    "                \n",
    "        try:\n",
    "            # create stock zone graph filename\n",
    "            zone_fn = create_zone_graph()\n",
    "            \n",
    "            with open(zone_fn, 'rb') as img:\n",
    "                \n",
    "                # set zone graph image cid, mime type, attach to email\n",
    "                img_cid = 'CID_ZONE_IMAGE'\n",
    "                mimetype = mimetypes.guess_type(img.name)[0]\n",
    "                maintype, subtype = mimetype.split('/')\n",
    "                msg.get_payload()[1].add_related(img.read(), \n",
    "                                                 maintype=maintype, \n",
    "                                                 subtype=subtype, \n",
    "                                                 cid=img_cid)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # send email via smtp server\n",
    "            with smtplib.SMTP(host_server, host_port) as server:\n",
    "\n",
    "                # begin ttls, login and send\n",
    "                server.starttls()\n",
    "                server.login(host_user, host_pass)\n",
    "                server.sendmail(host_email, area.email, msg.as_string())\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# build a list of monitoring area objects via feats\n",
    "areas = []\n",
    "for feat in feats:\n",
    "    try:\n",
    "        # create instance of area and add to list\n",
    "        area = MonitoringArea(feat, path=in_path)\n",
    "        areas.append(area)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ENDING DATETIME: 2022-12-25\n",
      "Obtaining all satellite data for monitoring area.\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "In  \u001b[0;34m[34]\u001b[0m:\nLine \u001b[0;34m12\u001b[0m:    area.run_all(TEST_DT=TEST_DTS[-\u001b[34m1\u001b[39;49;00m])\n",
      "In  \u001b[0;34m[32]\u001b[0m:\nLine \u001b[0;34m1709\u001b[0m:  \u001b[36mself\u001b[39;49;00m.set_new_xr()  \n",
      "In  \u001b[0;34m[32]\u001b[0m:\nLine \u001b[0;34m377\u001b[0m:   ds_existing=\u001b[34mNone\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules\\nrt.py\u001b[0m, in \u001b[0;32mfetch_cube_data\u001b[0m:\nLine \u001b[0;34m3450\u001b[0m:  limit=\u001b[34m250\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules\\cog_odc.py\u001b[0m, in \u001b[0;32mfetch_stac_items_odc\u001b[0m:\nLine \u001b[0;34m135\u001b[0m:   items = items + query.get_all_items()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\pystac_client\\item_search.py\u001b[0m, in \u001b[0;32mget_all_items\u001b[0m:\nLine \u001b[0;34m464\u001b[0m:   feature_collection = \u001b[36mself\u001b[39;49;00m.get_all_items_as_dict()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\pystac_client\\item_search.py\u001b[0m, in \u001b[0;32mget_all_items_as_dict\u001b[0m:\nLine \u001b[0;34m451\u001b[0m:   \u001b[34mfor\u001b[39;49;00m page \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._stac_io.get_pages(\u001b[36mself\u001b[39;49;00m.url, \u001b[36mself\u001b[39;49;00m.method, \u001b[36mself\u001b[39;49;00m.get_parameters()):\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\pystac_client\\stac_api_io.py\u001b[0m, in \u001b[0;32mget_pages\u001b[0m:\nLine \u001b[0;34m200\u001b[0m:   page = \u001b[36mself\u001b[39;49;00m.read_json(url, method=method, parameters=parameters)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\pystac\\stac_io.py\u001b[0m, in \u001b[0;32mread_json\u001b[0m:\nLine \u001b[0;34m197\u001b[0m:   txt = \u001b[36mself\u001b[39;49;00m.read_text(source, *args, **kwargs)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\pystac_client\\stac_api_io.py\u001b[0m, in \u001b[0;32mread_text\u001b[0m:\nLine \u001b[0;34m68\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.request(href, *args, parameters=parameters, **kwargs)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\pystac_client\\stac_api_io.py\u001b[0m, in \u001b[0;32mrequest\u001b[0m:\nLine \u001b[0;34m125\u001b[0m:   resp = \u001b[36mself\u001b[39;49;00m.session.send(prepped)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\requests\\sessions.py\u001b[0m, in \u001b[0;32msend\u001b[0m:\nLine \u001b[0;34m655\u001b[0m:   r = adapter.send(request, **kwargs)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\requests\\adapters.py\u001b[0m, in \u001b[0;32msend\u001b[0m:\nLine \u001b[0;34m449\u001b[0m:   timeout=timeout\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m, in \u001b[0;32murlopen\u001b[0m:\nLine \u001b[0;34m706\u001b[0m:   chunked=chunked,\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m, in \u001b[0;32m_make_request\u001b[0m:\nLine \u001b[0;34m445\u001b[0m:   six.raise_from(e, \u001b[34mNone\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m, in \u001b[0;32m_make_request\u001b[0m:\nLine \u001b[0;34m440\u001b[0m:   httplib_response = conn.getresponse()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\http\\client.py\u001b[0m, in \u001b[0;32mgetresponse\u001b[0m:\nLine \u001b[0;34m1369\u001b[0m:  response.begin()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\http\\client.py\u001b[0m, in \u001b[0;32mbegin\u001b[0m:\nLine \u001b[0;34m310\u001b[0m:   version, status, reason = \u001b[36mself\u001b[39;49;00m._read_status()\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\http\\client.py\u001b[0m, in \u001b[0;32m_read_status\u001b[0m:\nLine \u001b[0;34m271\u001b[0m:   line = \u001b[36mstr\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.fp.readline(_MAXLINE + \u001b[34m1\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33miso-8859-1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\socket.py\u001b[0m, in \u001b[0;32mreadinto\u001b[0m:\nLine \u001b[0;34m589\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._sock.recv_into(b)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\ssl.py\u001b[0m, in \u001b[0;32mrecv_into\u001b[0m:\nLine \u001b[0;34m1071\u001b[0m:  \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.read(nbytes, buffer)\n",
      "File \u001b[0;34mC:\\Users\\Lewis\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-dev-odc\\Lib\\ssl.py\u001b[0m, in \u001b[0;32mread\u001b[0m:\nLine \u001b[0;34m929\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._sslobj.read(\u001b[36mlen\u001b[39;49;00m, buffer)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: \n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "i = 0 # TESTING\n",
    "continue_monitoring = True\n",
    "\n",
    "# if len(areas) > 0:\n",
    "# begin monitoring process iteration\n",
    "while continue_monitoring:\n",
    "\n",
    "    # iterate area objects\n",
    "    for area in areas:\n",
    "                \n",
    "        # test running\n",
    "        area.run_all(TEST_DT=TEST_DTS[-1])\n",
    "        \n",
    "    # send emails\n",
    "    try:\n",
    "        email_alerts(areas, host_email, host_server, host_port, host_user, host_pass)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise\n",
    "        \n",
    "    # reset areas\n",
    "    for area in areas:\n",
    "        area.reset()\n",
    "        \n",
    "    # wait for a minute\n",
    "    print('Sleeping for 1 minute.')\n",
    "    for t in range(60):\n",
    "        time.sleep(1)\n",
    "        \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T08:14:44.443815Z",
     "start_time": "2022-05-01T08:14:28.859356Z"
    },
    "code_folding": [
     26,
     37,
     47,
     63,
     80,
     91,
     112,
     123,
     134,
     145,
     156,
     167,
     177,
     188,
     199,
     210,
     221,
     232,
     245,
     256,
     267,
     278,
     289,
     303,
     313
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ENDING DATETIME: 2015-01-04\n",
      "Obtaining all satellite data for monitoring area.\n",
      "Beginning STAC search for items. This can take awhile.\n",
      "Searching collection: ga_ls5t_ard_3\n",
      "Searching collection: ga_ls7e_ard_3\n",
      "Excluding SLC-off times.\n",
      "Searching collection: ga_ls8c_ard_3\n",
      "Searching collection: ga_ls8c_ard_provisional_3\n",
      "A total of 927 scenes were found.\n",
      "Replacing url prefix: s3://dea-public-data with https://data.dea.ga.gov.au\n",
      "Converting raw STAC data into xarray dataset via odc-stac.\n",
      "Created xarray dataset via odc-stac successfully.\n",
      "Removing dates where too many invalid pixels.\n",
      "Mask band is currently dask. Computing, please wait.\n",
      "Filling invalid pixels with requested nodata value.\n",
      "Dropping mask band.\n",
      "Removed invalid images successfully.\n",
      "Conforming DEA ARD satellite band names.\n",
      "Satellite band names conformed successfully.\n",
      "Calculating indices: mavi.\n",
      "Calculating index: mavi\n",
      "Renamed default indices.\n",
      "Calculated indices successfully.\n",
      "Removing spike outliers.\n",
      "Spike removal completed successfully.\n",
      "Beginning change detection.\n",
      "Sleeping for 1 minute.\n"
     ]
    }
   ],
   "source": [
    "i = 0 # TESTING\n",
    "while continue_monitoring:\n",
    "\n",
    "    # iterate area objects\n",
    "    for area in areas:\n",
    "        \n",
    "        #if area.ignore is 'Yes':\n",
    "        # continue\n",
    "        if area.area_id != 'A2':\n",
    "            continue\n",
    "        \n",
    "        # TESTING DATE TIMES\n",
    "        area.TESTING_END_DT = TEST_DTS[i]\n",
    "        print('\\n\\nENDING DATETIME: {}'.format(area.TESTING_END_DT))\n",
    "\n",
    "        # # # # #   \n",
    "        arcpy.AddMessage('Starting process for area {}.'.format(area.area_id))\n",
    "\n",
    "        # show information about area\n",
    "        #area.show_area_info()\n",
    "\n",
    "\n",
    "        # # # # # validate area. invalid value triggers error, skip on error    \n",
    "        try:\n",
    "            # validate area. invalid value triggers error, skip on error\n",
    "            area.validate_area()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Area {} is invalid, see messages.'.format(area.area_id))\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # get old xr. if no old or error, sets old to none. pass if none or error\n",
    "        try:\n",
    "            # get old xr. if no old or error, sets old to none. pass if none or error\n",
    "            area.set_old_xr()\n",
    "        except:\n",
    "            print('No existing xr for area, getting new xr.')\n",
    "            arcpy.AddWarning('No existing xr for area, getting new xr.')\n",
    "            pass\n",
    "\n",
    "\n",
    "        # # # # # validate old xr. skips old xr if none. changed attrs sets old xr to none\n",
    "        try:\n",
    "            # validate old xr. skips old xr if none. changed attrs sets old xr to none\n",
    "            area.validate_old_xr()\n",
    "        except:\n",
    "            print('Attributes of existing xr have changed, resetting.') # TESTING\n",
    "            arcpy.AddWarning('Attributes of existing xr have changed, resetting.')\n",
    "            pass    \n",
    "\n",
    "\n",
    "        # # # # # get all sat data. subset new xr to new dates if old xr exists. on error, set new to none, skip\n",
    "        try:\n",
    "            # get all sat data. subset new xr to new dates if old xr exists. on error, set new to none, skip\n",
    "            area.set_new_xr()  \n",
    "\n",
    "            # skip if no new dates, else notify\n",
    "            if area.new_xr_dates_found() is False:\n",
    "                print('No new satellite dates found, skipping.')\n",
    "                arcpy.AddMessage('No new satellite dates found, skipping.')\n",
    "                continue \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not obtain satellite data, see messages.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # apply fmask on new xr. if error or no dates, skip\n",
    "        try:\n",
    "            # apply fmask on new xr. if error or no dates, skip\n",
    "            area.apply_new_xr_fmask()\n",
    "\n",
    "            # skip if no new dates, else notify\n",
    "            if area.new_xr_dates_found() is False:\n",
    "                print('No cloud free data exists, skipping.')\n",
    "                arcpy.AddMessage('No cloud free data exists, skipping.')\n",
    "                continue   \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not apply fmask, see messages.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # apply veg index on new xr. if error or no dates, skip\n",
    "        try:\n",
    "            # apply veg index on new xr. if error or no dates, skip\n",
    "            area.apply_new_xr_index() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not apply vegetation index, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # load new xr. if error, skip\n",
    "        try:\n",
    "            # load new xr. if error, skip\n",
    "            area.load_new_xr() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not load satellite data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # remove edge pixels. if error or empty, return orig new xr\n",
    "        try:\n",
    "            # remove edge pixels. if error or empty, return orig new xr\n",
    "            area.remove_new_xr_edges() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not mask edge pixels, proceeding with them.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "\n",
    "        # # # # # reduce new xr to median value per date. if error, skip\n",
    "        try:\n",
    "            # reduce new xr to median value per date. if error, skip\n",
    "            area.reduce_new_xr() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not reduce data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # interp nans. if any remain, drop. if empty, error and skip\n",
    "        try:\n",
    "            # interp nans. if any remain, drop. if empty, error and skip\n",
    "            area.interp_new_xr_nans() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not interpolate data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # append required vars to new xr. if error, skip\n",
    "        try:\n",
    "            # append required vars to new xr. if error, skip\n",
    "            area.append_new_xr_vars() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not add vars to data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # combine old and new xrs. if no old xr, new xr used. if error, skip\n",
    "        try:\n",
    "            # combine old and new xrs. if no old xr, new xr used. if error, skip\n",
    "            area.set_cmb_xr() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not combine old and new data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # replaces spikes with interp in cmb xr. set result to veg_clean var. if error or no data, skip\n",
    "        try:\n",
    "            # replaces spikes with interp in cmb xr. set result to veg_clean var. if error or no data, skip\n",
    "            area.fix_cmb_xr_spikes() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not remove spike outliers, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # smooth clean veg index with savitsky filter in cmb xr. if error, skip\n",
    "        try:\n",
    "            # smooth clean veg index with savitsky filter in cmb xr. if error, skip\n",
    "            area.smooth_cmb_xr_index() \n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not smooth index, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # create analysis (anl) xr, remove pre-training years. if error, skip\n",
    "        try:\n",
    "            # create analysis (anl) xr, remove pre-training years. if error, skip\n",
    "            area.set_anl_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not create analysis data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # detect raw static, dynamic change via anl xr, if error, skip\n",
    "        try:\n",
    "            # detect raw static, dynamic change via anl xr, if error, skip\n",
    "            area.detect_change_anl_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not perform change detection, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # smooth static, dynamic change via anl xr, if error, skip\n",
    "        try:\n",
    "            # smooth static, dynamic change via anl xr, if error, skip\n",
    "            area.smooth_anl_xr_change()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not smooth change data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # transfer old xr change values to anl xr to persist history. if error, skip\n",
    "        try:\n",
    "            # transfer old xr change values to anl xr to persist history. if error, skip\n",
    "            area.transfer_old_to_anl_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not transfer old data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # build zones. if error, skip\n",
    "        try:\n",
    "            # build zones. if error, skip\n",
    "            area.build_zones()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not generate zones, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # build rule one, two, three. if error, skip\n",
    "        try:\n",
    "            # build rule one, two, three. if error, skip\n",
    "            area.build_rule_one()\n",
    "            area.build_rule_two()\n",
    "            area.build_rule_three()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not generate rules, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # build alerts. if error, skip   \n",
    "        try:\n",
    "            # build alerts. if error, skip\n",
    "            area.build_alerts()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not generate alerts, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # transfer anl xr to cmb xr to persist history. if error, skip\n",
    "        try:\n",
    "            # transfer anl xr to cmb xr to persist history. if error, skip\n",
    "            area.transfer_anl_to_cmb_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not transfer analysis data, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue\n",
    "\n",
    "\n",
    "        # # # # # append area field attrs back on to cmb xr. if error, skip\n",
    "        try:\n",
    "            # append area field attrs back on to cmb xr. if error, skip\n",
    "            area.append_cmb_xr_attrs()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not append attributes, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue    \n",
    "\n",
    "\n",
    "        # # # # # set alert info, html, graph data. if error, skip\n",
    "        try:\n",
    "            # set alert info, html, graph data. if error, skip\n",
    "            area.set_alert_data()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not extract alert information, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue    \n",
    "\n",
    "        # show information about current alert\n",
    "        #area.show_alert_info()\n",
    "\n",
    "\n",
    "        # # # # # refresh monitoring area symbology. if error, skip\n",
    "        try:\n",
    "            # refresh monitoring area symbology. if error, skip\n",
    "            area.refresh_area_symbology()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not refresh symbology, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue    \n",
    "        \n",
    "\n",
    "        # export cmb\n",
    "        try:\n",
    "            area.export_cmb_xr()\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not export latest netcdf, see messages. Skipping.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            print(e)\n",
    "            raise # continue  \n",
    "    \n",
    "        # on to next area\n",
    "        # ...\n",
    "    \n",
    "        \n",
    "   # raise\n",
    "    \n",
    "    # send emails\n",
    "    #try:\n",
    "        #email_alerts(areas, host_email, host_server, host_port, host_user, host_pass)\n",
    "    #except Exception as e:\n",
    "        #raise\n",
    "    \n",
    "    \n",
    "    \n",
    "    # reset areas\n",
    "    #for area in areas:\n",
    "        #area.reset()\n",
    "        \n",
    "    # wait for a minute\n",
    "    print('Sleeping for 1 minute.')\n",
    "    for t in range(60):\n",
    "        time.sleep(1)\n",
    "        \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if True:\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['veg_idx'].plot()\n",
    "    ds_tmp['veg_clean'].plot()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['static_raw'].plot()\n",
    "    ds_tmp['static_clean'].plot()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['dynamic_raw'].plot()\n",
    "    ds_tmp['dynamic_clean'].plot()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['static_zones'].plot()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['dynamic_zones'].plot()\n",
    "    plt.show()    \n",
    "    \n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['static_clean'].plot(color='black')\n",
    "    ds_tmp['static_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['static_clean'].where(ds_tmp['static_rule_one'] > 0).plot(marker='s', color='blue')\n",
    "    ds_tmp['static_clean'].where(ds_tmp['static_rule_one'] < 0).plot(marker='s', color='red')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['dynamic_clean'].plot(color='black')\n",
    "    ds_tmp['dynamic_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['dynamic_clean'].where(ds_tmp['dynamic_rule_one'] > 0).plot(marker='s', color='blue')\n",
    "    ds_tmp['dynamic_clean'].where(ds_tmp['dynamic_rule_one'] < 0).plot(marker='s', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['static_clean'].plot(color='black')\n",
    "    ds_tmp['static_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['static_clean'].where(ds_tmp['static_rule_two'] > 0).plot(marker='s', color='blue')\n",
    "    ds_tmp['static_clean'].where(ds_tmp['static_rule_two'] < 0).plot(marker='s', color='red')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['dynamic_clean'].plot(color='black')\n",
    "    ds_tmp['dynamic_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['dynamic_clean'].where(ds_tmp['dynamic_rule_two'] > 0).plot(marker='s', color='blue')\n",
    "    ds_tmp['dynamic_clean'].where(ds_tmp['dynamic_rule_two'] < 0).plot(marker='s', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['static_clean'].plot(color='black')\n",
    "    ds_tmp['static_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['static_clean'].where(ds_tmp['static_rule_three'] > 0).plot(marker='s', color='blue')\n",
    "    ds_tmp['static_clean'].where(ds_tmp['static_rule_three'] < 0).plot(marker='s', color='red')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['dynamic_clean'].plot(color='black')\n",
    "    ds_tmp['dynamic_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['dynamic_clean'].where(ds_tmp['dynamic_rule_three'] > 0).plot(marker='s', color='blue')\n",
    "    ds_tmp['dynamic_clean'].where(ds_tmp['dynamic_rule_three'] < 0).plot(marker='s', color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['static_clean'].plot(color='black')\n",
    "    ds_tmp['static_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['static_clean'].where(ds_tmp['static_alerts'] > 0).plot(marker='s', color='orange')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=[15, 3])\n",
    "    ds_tmp['dynamic_clean'].plot(color='black')\n",
    "    ds_tmp['dynamic_clean'].plot(linestyle='None', markersize=4, marker='o', color='black', alpha=0.5)\n",
    "    ds_tmp['dynamic_clean'].where(ds_tmp['dynamic_alerts'] > 0).plot(marker='s', color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_nc = r'C:\\Users\\Lewis\\Desktop\\test\\test.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     43,
     56,
     185,
     294,
     322,
     359,
     381,
     411,
     440,
     480,
     517,
     566,
     610,
     674,
     730,
     804,
     871,
     938,
     1018,
     1052,
     1161,
     1178,
     1205
    ]
   },
   "outputs": [],
   "source": [
    "class MonitoringAreaStatistics:\n",
    "\n",
    "    # TESTING_END_DT REMOVE THIS WHEN DONE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    def __init__(self, feat, path, out_nc):\n",
    "        \n",
    "        # feature fields\n",
    "        self.area_id = feat[0]\n",
    "        self.platform = feat[1]\n",
    "        self.s_year = feat[2]\n",
    "        self.e_year = feat[3]\n",
    "        self.index = feat[4]\n",
    "        self.persistence = feat[5]\n",
    "        self.rule_1_min_conseqs = feat[6]\n",
    "        self.rule_1_inc_plateaus = feat[7]\n",
    "        self.rule_2_min_zone = feat[8]\n",
    "        self.rule_3_num_zones = feat[9]\n",
    "        self.ruleset = feat[10]\n",
    "        self.alert = feat[11]\n",
    "        self.method = feat[12]\n",
    "        self.alert_direction = feat[13]\n",
    "        self.email = feat[14]\n",
    "        self.ignore = feat[15]\n",
    "        self.color = feat[16]\n",
    "        self.global_id = feat[17]\n",
    "        \n",
    "        # feature geometry\n",
    "        self.raw_geom = feat[18]\n",
    "        self.prj_geom = None\n",
    "        \n",
    "        # path to project folder, output file\n",
    "        self.path = path\n",
    "        self.out_nc = out_nc\n",
    "        \n",
    "        # xr datasets\n",
    "        self.ds = None\n",
    "        \n",
    "        # xr edge mask\n",
    "        self.mask = None\n",
    "        \n",
    "        # TESTING REMOVE THIS WHEN DONE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        self.TESTING_END_DT = None\n",
    "        \n",
    "        \n",
    "    def show_area_info(self):\n",
    "        \"\"\"\n",
    "        Simple function to print field information to \n",
    "        screen.\n",
    "        \"\"\"\n",
    "        \n",
    "        # print field attributes\n",
    "        for field in list(vars(self))[:16]:\n",
    "            print('{}: {}'.format(field, vars(self).get(field)))\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def validate_area(self):\n",
    "        \"\"\"\n",
    "        Checks all required monitoring area parameters are \n",
    "        valid. Raises an error if invalid.\n",
    "        \"\"\"\n",
    "\n",
    "        # check area id\n",
    "        if self.area_id is None:\n",
    "            raise ValueError('No area id exists.')\n",
    "\n",
    "        # check platform\n",
    "        if self.platform not in ['Landsat', 'Sentinel']:\n",
    "            raise ValueError('Platform not Landsat or Sentinel.')\n",
    "\n",
    "        # check start, end years\n",
    "        if not isinstance(self.s_year, int):\n",
    "            raise ValueError('Start year not an integer.')\n",
    "        elif not isinstance(self.e_year, int):\n",
    "            raise ValueError('End year not an integer.')\n",
    "        elif self.s_year < 1980 or self.s_year > 2050:\n",
    "            raise ValueError('Start year not between 1980-2050.')        \n",
    "        elif self.e_year < 1980 or self.e_year > 2050:\n",
    "            raise ValueError('End year not between 1980-2050.')          \n",
    "        elif self.e_year <= self.s_year:\n",
    "            raise ValueError('End year is <= start year.')           \n",
    "        elif abs(self.e_year - self.s_year) < 2:\n",
    "            raise ValueError('Training period < 2 years in length.')  \n",
    "        elif self.platform == 'Sentinel' and self.s_year < 2016:\n",
    "            raise ValueError('Start year must be >= 2016 for Sentinel data.')  \n",
    "\n",
    "        # check index\n",
    "        if self.index not in ['NDVI', 'MAVI', 'kNDVI']:\n",
    "            raise ValueError('Index must be NDVI, MAVI or kNDVI.')\n",
    "\n",
    "        # check persistence\n",
    "        if self.persistence is None:\n",
    "            raise ValueError('No persistence exists.')\n",
    "        elif self.persistence < 0.001 or self.persistence > 9.999:\n",
    "            raise ValueError('Persistence not between 0.0001 and 9.999.')\n",
    "\n",
    "        # check rule 1 min consequtives\n",
    "        if self.rule_1_min_conseqs is None:\n",
    "            raise ValueError('No rule 1 min conseqs exists.')\n",
    "        elif self.rule_1_min_conseqs < 0 or self.rule_1_min_conseqs > 999:\n",
    "            raise ValueError('Rule 1 min conseqs not between 0 and 999.')\n",
    "\n",
    "        # check rule 1 inc plateaus\n",
    "        if self.rule_1_inc_plateaus is None:\n",
    "            raise ValueError('No rule 1 inc plateaus exists.')\n",
    "        elif self.rule_1_inc_plateaus not in ['Yes', 'No']:\n",
    "            raise ValueError('Rule 1 inc plateaus must be Yes or No.')\n",
    "\n",
    "        # check rule 2 min zone\n",
    "        if self.rule_2_min_zone is None:\n",
    "            raise ValueError('No rule 2 min zone exists.')\n",
    "        elif self.rule_2_min_zone < 1 or self.rule_2_min_zone > 11:\n",
    "            raise ValueError('Rule 2 min zone not between 1 and 11.') \n",
    "\n",
    "        # check rule 3 num zones\n",
    "        if self.rule_3_num_zones is None:\n",
    "            raise ValueError('No rule 3 num zones exists.')\n",
    "        elif self.rule_3_num_zones < 1 or self.rule_3_num_zones > 11:\n",
    "            raise ValueError('rule 3 num zones not between 1 and 11.')             \n",
    "\n",
    "        # set up allowed rulesets\n",
    "        rulesets = [\n",
    "            '1 only',\n",
    "            '2 only',\n",
    "            '3 only',\n",
    "            '1 and 2',\n",
    "            '1 and 3',\n",
    "            '2 and 3',\n",
    "            '1 or 2',\n",
    "            '1 or 3',\n",
    "            '2 or 3',\n",
    "            '1 and 2 and 3',\n",
    "            '1 or 2 and 3',\n",
    "            '1 and 2 or 3',\n",
    "            '1 or 2 or 3'\n",
    "        ]\n",
    "\n",
    "        # check ruleset   \n",
    "        if self.ruleset not in rulesets:\n",
    "            raise ValueError('Rulset not supported.')\n",
    "\n",
    "        # check alert\n",
    "        if self.alert not in ['Yes', 'No']:\n",
    "            raise ValueError('Alert must be Yes or No.')\n",
    "\n",
    "        # check method\n",
    "        if self.method not in ['Static', 'Dynamic']:\n",
    "            raise ValueError('Method must be Static or Dynamic')\n",
    "\n",
    "        # set up alert directions \n",
    "        alert_directions = [\n",
    "            'Incline only (any)', \n",
    "            'Decline only (any)', \n",
    "            'Incline only (+ zones only)', \n",
    "            'Decline only (- zones only)', \n",
    "            'Incline or Decline (any)',\n",
    "            'Incline or Decline (+/- zones only)'\n",
    "        ]\n",
    "\n",
    "        # check alert direction\n",
    "        if self.alert_direction not in alert_directions:\n",
    "            raise ValueError('Alert direction is not supported.')\n",
    "\n",
    "        # check email address\n",
    "        if self.alert == 'Yes' and self.email is None:\n",
    "            raise ValueError('No email provided.')\n",
    "        elif self.email is not None and '@' not in self.email:\n",
    "            raise ValueError('Email address invalid.')\n",
    "\n",
    "        # check ignore\n",
    "        if self.ignore not in ['Yes', 'No']:\n",
    "            raise ValueError('Ignore must be Yes or No.')\n",
    "\n",
    "        # check global id\n",
    "        if self.global_id is None:\n",
    "            raise ValueError('No global id exists.')\n",
    "\n",
    "        # check path provided\n",
    "        if self.path is None:\n",
    "            raise ValueError('No project path exists.')\n",
    "\n",
    "        return\n",
    "        \n",
    "        \n",
    "    # TODO SET END DATE TO 2050 WHEN DONE\n",
    "    def set_xr(self):\n",
    "        \"\"\"\n",
    "        Fetches all available digital earth australia (dea) \n",
    "        landsat/sentinel data for area bounding box. Start date\n",
    "        is based on provided start year. The resulting data is \n",
    "        set to the xr. If an error occurs, an error is raised. \n",
    "        \"\"\"\n",
    "        \n",
    "        # set endpoint\n",
    "        STAC_ENDPOINT = 'https://explorer.sandbox.dea.ga.gov.au/stac'\n",
    "        \n",
    "        # check platform is valid\n",
    "        if self.platform not in ['Landsat', 'Sentinel']:\n",
    "            raise ValueError('Platform not supported.')\n",
    "\n",
    "        # prepare dea stac search parameters\n",
    "        if self.platform == 'Landsat':\n",
    "            \n",
    "            # set dea collection names\n",
    "            collections = [\n",
    "                'ga_ls5t_ard_3',\n",
    "                'ga_ls7e_ard_3',\n",
    "                'ga_ls8c_ard_3',\n",
    "                'ga_ls8c_ard_provisional_3'\n",
    "            ]\n",
    "            \n",
    "            # set bands\n",
    "            bands = [\n",
    "                'nbart_red', \n",
    "                'nbart_green', \n",
    "                'nbart_blue', \n",
    "                'nbart_nir', \n",
    "                'nbart_swir_1', \n",
    "                'nbart_swir_2', \n",
    "                'oa_fmask'\n",
    "            ]\n",
    "            \n",
    "        elif self.platform == 'Sentinel':\n",
    "            \n",
    "            # set dea collection names\n",
    "            collections = [\n",
    "                's2a_ard_granule',  # todo: use ver 3 when avail\n",
    "                's2b_ard_granule',  # todo: use ver 3 when avail\n",
    "                'ga_s2am_ard_provisional_3',\n",
    "                'ga_s2bm_ard_provisional_3'\n",
    "            ]\n",
    "            \n",
    "            # set bands\n",
    "            bands = [\n",
    "                'nbart_red', \n",
    "                'nbart_green', \n",
    "                'nbart_blue', \n",
    "                'nbart_nir_1', \n",
    "                'nbart_swir_2', \n",
    "                'nbart_swir_3', \n",
    "                'fmask'\n",
    "            ]\n",
    "        \n",
    "        try:\n",
    "            # ensure raw geom is in wgs84 (set prj_geom)\n",
    "            srs = arcpy.SpatialReference(4326)\n",
    "            self.prj_geom = self.raw_geom.projectAs(srs)\n",
    "            \n",
    "            # convert to bounding box in wgs84\n",
    "            prj_bbox = [\n",
    "                self.prj_geom.extent.XMin,\n",
    "                self.prj_geom.extent.YMin,\n",
    "                self.prj_geom.extent.XMax,\n",
    "                self.prj_geom.extent.YMax\n",
    "            ]\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "            \n",
    "        # check if start date provided \n",
    "        if self.s_year is None:\n",
    "            raise ValueError('No start year provided.')\n",
    "            \n",
    "        try:\n",
    "            # prepare start date \n",
    "            start_dt = '{}-01-01'.format(self.s_year)\n",
    "            \n",
    "            # get all avail dea satellite data without compute\n",
    "            self.ds = nrt.fetch_cube_data(collections=collections, \n",
    "                                          bands=bands, \n",
    "                                          start_dt=start_dt, \n",
    "                                          end_dt=self.TESTING_END_DT,     #'2050-12-31', \n",
    "                                          bbox=prj_bbox, \n",
    "                                          resolution=10, \n",
    "                                          ds_existing=None)\n",
    "        \n",
    "            # group duplicate times if exist\n",
    "            self.ds = satfetcher.group_by_solar_day(self.ds)\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        try:\n",
    "            # enforce none type if no dates\n",
    "            if len(self.ds['time']) == 0:\n",
    "                self.ds = None\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def apply_xr_fmask(self):\n",
    "        \"\"\"\n",
    "        Takes the xr and applies the dea fmask band to remove \n",
    "        invalid pixels and dates. If an error occurs, error is \n",
    "        raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "\n",
    "        try:\n",
    "            # get mask band name (either be oa_fmask or fmask)\n",
    "            mask = [v for v in self.ds if 'mask' in v][0]\n",
    "\n",
    "            # mask invalid pixels i.e., not valid, water, snow\n",
    "            self.ds = cog.remove_fmask_dates(ds=self.ds, \n",
    "                                             valid_class=[1, 4, 5],\n",
    "                                             max_invalid=0,\n",
    "                                             mask_band=mask, \n",
    "                                             nodata_value=np.nan,\n",
    "                                             drop_fmask=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def apply_xr_index(self):\n",
    "        \"\"\"\n",
    "        Takes the  xr and applies user chosen vegetation\n",
    "        index. If an error occurs, error is raised. \n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "\n",
    "        # check if platform set\n",
    "        if self.platform not in ['Landsat', 'Sentinel']:\n",
    "            raise ValueError('Platform not supported.')\n",
    "\n",
    "        # check if index set\n",
    "        if self.index not in ['NDVI', 'MAVI', 'kNDVI']:\n",
    "            raise ValueError('Index not supported.')\n",
    "\n",
    "        try:\n",
    "            # conform dea band names and calc vegetation index\n",
    "            platform = self.platform.lower()\n",
    "            self.ds = satfetcher.conform_dea_ard_band_names(ds=self.ds, \n",
    "                                                            platform=platform) \n",
    "\n",
    "            # calculate vegetation index\n",
    "            index = self.index.lower()\n",
    "            self.ds = tools.calculate_indices(ds=self.ds, \n",
    "                                              index=index, \n",
    "                                              custom_name='veg_idx', \n",
    "                                              rescale=False, \n",
    "                                              drop=True)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def load_xr(self):\n",
    "        \"\"\"\n",
    "        Loads xr values into memory using the xarray \n",
    "        load function. This will result in downloading from \n",
    "        dea and can take awhile.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No new xr provided.')\n",
    "\n",
    "        try:\n",
    "            # load new xr and close connection \n",
    "            self.ds.load()\n",
    "            self.ds.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def set_xr_edge_mask(self):\n",
    "        \"\"\"\n",
    "        Sets an xr array useful for masking out edge pixels. Edge pixels \n",
    "        can occur within the original bounding box but outside of the \n",
    "        vector boundary of the monitoring area. This mask is created \n",
    "        as array of 1s and 0s (in boundary, out boundary) \n",
    "        and applies it to the xr via the apply_xr_edge_mask function. \n",
    "        If an error occurs, no mask is applied.\n",
    "        \"\"\" \n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "\n",
    "        # check if raw geometry exists\n",
    "        if self.raw_geom is None:\n",
    "            raise ValueError('No raw area geometry provided.')       \n",
    "\n",
    "        try:\n",
    "            # rasterize area polygon, set outside pixels to nan\n",
    "            self.mask = nrt.rasterize_polygon(ds=self.ds, \n",
    "                                              geom=self.raw_geom)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.mask = None\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def interp_xr_nans(self):\n",
    "        \"\"\"\n",
    "        Interpolates any existing nan values in xr, linearly.\n",
    "        If nan values still exist after interpolation (often on\n",
    "        edge dates due to lack of extrapolation), these will be\n",
    "        dropped. If error occurs, error is raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')          \n",
    "\n",
    "        try:\n",
    "            # interpolate na linearly\n",
    "            self.ds = self.ds.interpolate_na('time')\n",
    "            \n",
    "            # fill any remaining nans\n",
    "            self.ds = self.ds.fillna(0)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check we have data remaining\n",
    "        if len(self.ds['time']) == 0:\n",
    "            raise ValueError('No data remaining after nodata dropped.')\n",
    "            \n",
    "        return\n",
    "\n",
    "\n",
    "    def append_xr_vars(self):\n",
    "        \"\"\"\n",
    "        Appends required xr variables to xr if do not exist.\n",
    "        These variables are required for storing outputs from \n",
    "        change detection results, cleaned vegetation, etc. If\n",
    "        error, error is raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')  \n",
    "        \n",
    "        # set required variable names\n",
    "        new_vars = [\n",
    "            'veg_clean', \n",
    "            'static_raw', \n",
    "            'static_clean',\n",
    "            'static_rule_one',\n",
    "            'static_rule_two',\n",
    "            'static_rule_three',\n",
    "            'static_zones',\n",
    "            'static_alerts',\n",
    "            'dynamic_raw', \n",
    "            'dynamic_clean',\n",
    "            'dynamic_rule_one',\n",
    "            'dynamic_rule_two',\n",
    "            'dynamic_rule_three',\n",
    "            'dynamic_zones',\n",
    "            'dynamic_alerts'\n",
    "        ]        \n",
    "        \n",
    "        # iter var names and append to xr\n",
    "        for var in new_vars:\n",
    "            if var not in self.ds:\n",
    "                da = xr.full_like(self.ds['veg_idx'], np.nan)\n",
    "                self.ds[var] = da\n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "    def fix_xr_spikes(self):\n",
    "        \"\"\"\n",
    "        Detects severe vegetation index outliers using the TIMESAT \n",
    "        3.3 median spike detection method. Sets spike values to \n",
    "        nan and then interpolates them, if they exist. If error, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "        \n",
    "        try:\n",
    "            # remove outliers via median spike method\n",
    "            da = nrt.remove_spikes(da=self.ds['veg_idx'], \n",
    "                                   factor=1, \n",
    "                                   win_size=3)\n",
    "            \n",
    "            # interpolate nans linearly\n",
    "            da = da.interpolate_na('time')\n",
    "            \n",
    "            # fill nan values\n",
    "            da = da.fillna(0)\n",
    "            \n",
    "            # set result to clean var\n",
    "            self.ds['veg_clean'] = da   \n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check we still have data remaining\n",
    "        if len(self.ds['time']) == 0:\n",
    "            raise ValueError('No data remaining after no data dropped.')\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    # remove commented out code if happy with method\n",
    "    def smooth_xr_index(self):\n",
    "        \"\"\"\n",
    "        Mildly smoothes the xr clean vegetation index values \n",
    "        using the savitsky golay filter. If error, error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "\n",
    "        try:\n",
    "            # get time dimension axis\n",
    "            dims = list(self.ds.dims)\n",
    "            for idx, dim in enumerate(dims):\n",
    "                if dim == 'time':\n",
    "                    axis = idx\n",
    "\n",
    "            # set up kwargs\n",
    "            kwargs={\n",
    "                'window_length': 3, \n",
    "                'polyorder': 1,\n",
    "                'a': axis\n",
    "            }\n",
    "            \n",
    "            # get fill nan array\n",
    "            #da = self.ds['veg_clean'].fillna(0)\n",
    "            \n",
    "            # apply savitsky filter to outlier-free index\n",
    "            #da = xr.apply_ufunc(savgol_filter, \n",
    "                                #da,\n",
    "                                #dask='allowed',\n",
    "                                #kwargs=kwargs)\n",
    "\n",
    "            # apply savitsky filter and handle nans\n",
    "            da = xr.apply_ufunc(nrt.safe_savgol, \n",
    "                                self.ds['veg_clean'],\n",
    "                                dask='allowed',\n",
    "                                kwargs=kwargs)\n",
    "                        \n",
    "            # update existing values in xr\n",
    "            self.ds['veg_clean'] = da\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        return\n",
    "\n",
    "    # TODO play with smoothing, persistence \n",
    "    # ALSO TRY MIN TRAINING LENGTH COULD WORK!!! set to 1 year worth of dates, 2 years worth of dates, etc\n",
    "    def detect_change_xr(self):\n",
    "        \"\"\"\n",
    "        Performs ewmacd change detection (static and dynamic \n",
    "        types) on xr. Uses the raw vegetation index time series \n",
    "        to detect the change. If error or all nan, error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if anl xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "\n",
    "        # check start and end years valid\n",
    "        if self.s_year is None or self.e_year is None:\n",
    "            raise ValueError('No start and/or end year provided.')        \n",
    "\n",
    "        # check if persistence is valid\n",
    "        if self.persistence is None:\n",
    "            raise ValueError('No persistence provided.')\n",
    "            \n",
    "        try:\n",
    "            # perform ewmacd change detection\n",
    "            self.ds = nrt.detect_change(ds=self.ds,\n",
    "                                        method='both',\n",
    "                                        var='veg_idx',\n",
    "                                        train_start=self.s_year,\n",
    "                                        train_end=self.e_year,\n",
    "                                        persistence=self.persistence)\n",
    "            \n",
    "            # ensure static, dynamic dimension order correct\n",
    "            self.ds['static_raw'] = self.ds['static_raw'].transpose('time', 'y', 'x')\n",
    "            self.ds['dynamic_raw'] = self.ds['dynamic_raw'].transpose('time', 'y', 'x')\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if we have data\n",
    "        for var in ['static_raw', 'dynamic_raw']:\n",
    "            if self.ds[var].isnull().all():\n",
    "                raise ValueError('Change result is empty.')            \n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    # remove commented out code if happy with method\n",
    "    def smooth_xr_change(self):\n",
    "        \"\"\"\n",
    "        Mildly smoothes the xr static and dynamic change \n",
    "        signal values using the savitsky golay filter. If error, \n",
    "        error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "            \n",
    "        try:\n",
    "            # get time dimension axis\n",
    "            dims = list(self.ds.dims)\n",
    "            for idx, dim in enumerate(dims):\n",
    "                if dim == 'time':\n",
    "                    axis = idx\n",
    "\n",
    "            # set up kwargs\n",
    "            kwargs={\n",
    "                'window_length': 3, \n",
    "                'polyorder': 1,\n",
    "                'a': axis\n",
    "            }\n",
    "            \n",
    "            # ensure no static or dynamic nans\n",
    "            #da_static = self.ds['static_raw'].fillna(0)\n",
    "            #da_dynamic = self.ds['dynamic_raw'].fillna(0)\n",
    "                        \n",
    "            # apply savitsky filter to static change values\n",
    "            #da_static = xr.apply_ufunc(savgol_filter, \n",
    "                                       #da_static,\n",
    "                                       #dask='allowed',\n",
    "                                       #kwargs=kwargs)\n",
    "\n",
    "            # apply savitsky filter to dynamic change values\n",
    "            #da_dynamic = xr.apply_ufunc(savgol_filter, \n",
    "                                        #da_dynamic,\n",
    "                                        #dask='allowed',\n",
    "                                        #kwargs=kwargs)\n",
    "            \n",
    "            # apply static savitsky filter and handle nans\n",
    "            da_static = xr.apply_ufunc(nrt.safe_savgol, \n",
    "                                       self.ds['static_raw'],\n",
    "                                       dask='allowed',\n",
    "                                       kwargs=kwargs)\n",
    "            \n",
    "            # apply dynamic savitsky filter and handle nans\n",
    "            da_dynamic = xr.apply_ufunc(nrt.safe_savgol, \n",
    "                                        self.ds['dynamic_raw'],\n",
    "                                        dask='allowed',\n",
    "                                        kwargs=kwargs)\n",
    "            \n",
    "\n",
    "            # update static, dynamic clean values in xr\n",
    "            self.ds['static_clean'] = da_static\n",
    "            self.ds['dynamic_clean'] = da_dynamic\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        return       \n",
    "\n",
    "\n",
    "    def build_zones(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and classifies them into 1 of 11 zones based\n",
    "        on where the change value falls. Honours direction \n",
    "        of change by returning zone value with sign (+/-).\n",
    "        If error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "\n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "\n",
    "        try:\n",
    "            # seperate dims\n",
    "            t, y, x = self.ds['time'], self.ds['y'], self.ds['x']\n",
    "\n",
    "            # get rows of static values per pixel and apply func along rows\n",
    "            da = self.ds['static_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_zones, axis=0, arr=da)\n",
    "\n",
    "            # rebuild static xr array \n",
    "            da_static = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                     coords={'time': t, 'y': y, 'x': x}, \n",
    "                                     dims=['time', 'y', 'x'])\n",
    "\n",
    "            # get rows of dynamic values per pixel and apply func along rows\n",
    "            da = self.ds['dynamic_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_zones, axis=0, arr=da)\n",
    "\n",
    "            # rebuild dynamic xr array \n",
    "            da_dynamic = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                      coords={'time': t, 'y': y, 'x': x}, \n",
    "                                      dims=['time', 'y', 'x'])\n",
    "\n",
    "            # update xr dataset\n",
    "            self.ds['static_zones'] = da_static\n",
    "            self.ds['dynamic_zones'] = da_dynamic\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if we have any data\n",
    "        for var in ['static_zones', 'dynamic_zones']:\n",
    "            if self.ds[var].isnull().all():\n",
    "                raise ValueError('Zone result is empty.')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def build_rule_one(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and applies rule one rules to them. Rule one\n",
    "        calculates consequtive runs of values across time.\n",
    "        Honours direction of change by returning value \n",
    "        with sign (+/-). If error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "        \n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "        \n",
    "        # check if rule one parameters valid\n",
    "        if self.rule_1_min_conseqs is None:\n",
    "            raise ValueError('No minimum consequtives provided.')\n",
    "        elif self.rule_1_inc_plateaus is None:\n",
    "            raise ValueError('No include plateaus provided.')   \n",
    "            \n",
    "        # prepare plateaus\n",
    "        if self.rule_1_inc_plateaus == 'Yes':\n",
    "            plateaus = True\n",
    "        else:\n",
    "            plateaus = False\n",
    "            \n",
    "        # set kwarg options\n",
    "        kwargs = {\n",
    "            'min_conseqs': self.rule_1_min_conseqs,\n",
    "            'inc_plateaus': plateaus\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # seperate dims\n",
    "            t, y, x = self.ds['time'], self.ds['y'], self.ds['x']\n",
    "\n",
    "            # get rows of static values per pixel and apply rule 1 runs (+/-) along rows\n",
    "            da = self.ds['static_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_rule_one_runs, axis=0, arr=da, **kwargs)\n",
    "\n",
    "            # rebuild static xr array \n",
    "            da_static = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                     coords={'time': t, 'y': y, 'x': x}, \n",
    "                                     dims=['time', 'y', 'x'])\n",
    "\n",
    "            # get rows of dynamic values per pixel and apply rule 1 runs (+/-) along rows\n",
    "            da = self.ds['dynamic_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_rule_one_runs, axis=0, arr=da, **kwargs)\n",
    "\n",
    "            # rebuild dynamic xr array \n",
    "            da_dynamic = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                      coords={'time': t, 'y': y, 'x': x}, \n",
    "                                      dims=['time', 'y', 'x'])\n",
    "\n",
    "            # update xr dataset\n",
    "            self.ds['static_rule_one'] = da_static\n",
    "            self.ds['dynamic_rule_one'] = da_dynamic\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if we have any data\n",
    "        for var in ['static_rule_one', 'dynamic_rule_one']:\n",
    "            if self.ds[var].isnull().all():\n",
    "                raise ValueError('Rule one result empty.')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def build_rule_two(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and applies rule two rules to them. Rule two\n",
    "        masks out stdv values that fall within a specified\n",
    "        minimum zone threshold. Honours direction of change \n",
    "        by returning value with sign (+/-). If error occurs, \n",
    "        error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "\n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "\n",
    "        # check if rule two parameters valid\n",
    "        if self.rule_2_min_zone is None:\n",
    "            raise ValueError('No minimum zone provided.') \n",
    "\n",
    "        # convert zone to std\n",
    "        stdvs = nrt.zone_to_std(self.rule_2_min_zone)[0]\n",
    "\n",
    "        # set kwarg options\n",
    "        kwargs = {'min_stdv': stdvs}\n",
    "\n",
    "        try:\n",
    "            # seperate dims\n",
    "            t, y, x = self.ds['time'], self.ds['y'], self.ds['x']\n",
    "\n",
    "            # get rows of static values per pixel and apply rule 2 mask (+/-) along rows\n",
    "            da = self.ds['static_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_rule_two_mask, axis=0, arr=da, **kwargs)\n",
    "\n",
    "            # rebuild static xr array \n",
    "            da_static = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                     coords={'time': t, 'y': y, 'x': x}, \n",
    "                                     dims=['time', 'y', 'x'])\n",
    "\n",
    "            # get rows of dynamic values per pixel and apply rule 2 mask (+/-) along rows\n",
    "            da = self.ds['dynamic_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_rule_two_mask, axis=0, arr=da, **kwargs)\n",
    "\n",
    "            # rebuild dynamic xr array \n",
    "            da_dynamic = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                      coords={'time': t, 'y': y, 'x': x}, \n",
    "                                      dims=['time', 'y', 'x'])\n",
    "\n",
    "            # update xr dataset\n",
    "            self.ds['static_rule_two'] = da_static\n",
    "            self.ds['dynamic_rule_two'] = da_dynamic\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if we have any data\n",
    "        for var in ['static_rule_two', 'dynamic_rule_two']:\n",
    "            if self.ds[var].isnull().all():\n",
    "                raise ValueError('Rule two result empty.')\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def build_rule_three(self):\n",
    "        \"\"\"\n",
    "        Takes cleaned static and dynamic change deviation\n",
    "        values and applies rule three rules to them. Rule three\n",
    "        detects sharp zone value spikes that occurr between \n",
    "        dates. Honours direction of change by returning value \n",
    "        with sign (+/-). If error occurs, error raised.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "\n",
    "        # check if required vars in xr\n",
    "        if 'static_clean' not in self.ds:\n",
    "            raise ValueError('No clean static variable.')\n",
    "        elif 'dynamic_clean' not in self.ds:\n",
    "            raise ValueError('No clean dynamic variable.')\n",
    "\n",
    "        # check if rule three parameters valid\n",
    "        if self.rule_3_num_zones is None:\n",
    "            raise ValueError('No number of zones provided.') \n",
    "\n",
    "        # convert zone to std and multiple by 2 (2 std per zone)\n",
    "        stdvs = nrt.zone_to_std(self.rule_3_num_zones)[0] \n",
    "        stdvs = stdvs * 2\n",
    "\n",
    "        # set kwarg options\n",
    "        kwargs = {'min_stdv': stdvs}\n",
    "\n",
    "        try:\n",
    "            # seperate dims\n",
    "            t, y, x = self.ds['time'], self.ds['y'], self.ds['x']\n",
    "\n",
    "            # get rows of static values per pixel and apply rule 3 spikes (+/-) along rows\n",
    "            da = self.ds['static_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_rule_three_spikes, axis=0, arr=da, **kwargs)\n",
    "\n",
    "            # rebuild static xr array \n",
    "            da_static = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                     coords={'time': t, 'y': y, 'x': x}, \n",
    "                                     dims=['time', 'y', 'x'])\n",
    "\n",
    "            # get rows of dynamic values per pixel and apply rule 3 spikes (+/-) along rows\n",
    "            da = self.ds['dynamic_clean'].stack(z=['y', 'x']).values\n",
    "            da = np.apply_along_axis(nrt.build_rule_three_spikes, axis=0, arr=da, **kwargs)\n",
    "\n",
    "            # rebuild dynamic xr array \n",
    "            da_dynamic = xr.DataArray(da.reshape(len(t), len(y), len(x)), \n",
    "                                      coords={'time': t, 'y': y, 'x': x}, \n",
    "                                      dims=['time', 'y', 'x'])\n",
    "\n",
    "            # update xr dataset\n",
    "            self.ds['static_rule_three'] = da_static\n",
    "            self.ds['dynamic_rule_three'] = da_dynamic\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if we have any data\n",
    "        for var in ['static_rule_three', 'dynamic_rule_three']:\n",
    "            if self.ds[var].isnull().all():\n",
    "                raise ValueError('Rule three result empty.')\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def build_alerts(self):\n",
    "        \"\"\"\n",
    "        Takes the previously derived rule one, two, three values\n",
    "        and combines them into an alert mask (1, 0) variable for \n",
    "        static and dynamic methods. This method considers \n",
    "        both the user's requested ruleset and the particular\n",
    "        direction of change (incline or decline) required for\n",
    "        alert to be set as true (1). If error occurs, error raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No anl xr provided.')\n",
    "        \n",
    "        # set up valid rulesets\n",
    "        valid_rules = [\n",
    "            '1 only', \n",
    "            '2 only', \n",
    "            '3 only', \n",
    "            '1 and 2', \n",
    "            '1 and 3', \n",
    "            '2 and 3', \n",
    "            '1 or 2', \n",
    "            '1 or 3', \n",
    "            '2 or 3', \n",
    "            '1 and 2 and 3', \n",
    "            '1 or 2 and 3',\n",
    "            '1 and 2 or 3', \n",
    "            '1 or 2 or 3'\n",
    "        ]\n",
    "        \n",
    "        # check if ruleset valid\n",
    "        if self.ruleset not in valid_rules:\n",
    "            raise ValueError('Ruleset not supported.')\n",
    "        \n",
    "        # set up valid directions \n",
    "        valid_directions = [\n",
    "            'Incline only (any)',\n",
    "            'Decline only (any)',\n",
    "            'Incline only (+ zones only)',\n",
    "            'Decline only (- zones only)',\n",
    "            'Incline or Decline (any)',\n",
    "            'Incline or Decline (+/- zones only)'\n",
    "        ]\n",
    "        \n",
    "        # check if direction valid\n",
    "        if self.ruleset not in valid_rules:\n",
    "            raise ValueError('Direction not supported.')\n",
    "        \n",
    "        # set kwarg options\n",
    "        kwargs = {\n",
    "            'ruleset': self.ruleset,\n",
    "            'direction': self.alert_direction\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # generate and combines rules into alert for static change \n",
    "            self.ds['static_alerts'] = xr.apply_ufunc(nrt.build_alerts,\n",
    "                                                      self.ds['static_rule_one'],\n",
    "                                                      self.ds['static_rule_two'],\n",
    "                                                      self.ds['static_rule_three'],\n",
    "                                                      kwargs=kwargs)\n",
    "\n",
    "            # generate and combines rules into alert for dynamic change \n",
    "            self.ds['dynamic_alerts'] = xr.apply_ufunc(nrt.build_alerts,\n",
    "                                                       self.ds['dynamic_rule_one'],\n",
    "                                                       self.ds['dynamic_rule_two'],\n",
    "                                                       self.ds['dynamic_rule_three'],\n",
    "                                                       kwargs=kwargs)\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "            \n",
    "        # check if we have any data\n",
    "        for var in ['static_alerts', 'dynamic_alerts']:\n",
    "            if self.ds[var].isnull().all():\n",
    "                raise ValueError('Alert result empty.')\n",
    "                \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def apply_xr_edge_mask(self):\n",
    "            \"\"\"\n",
    "            Applies the xr edge mask generated earlier during the \n",
    "            set_xr_edge_mask function. Any pixels within this mask \n",
    "            will be set to nodata (nan). If an error occurs, no mask \n",
    "            is applied.\n",
    "            \"\"\" \n",
    "\n",
    "            # check if xr exists\n",
    "            if self.ds is None:\n",
    "                raise ValueError('No xr provided.')\n",
    "\n",
    "            # check if edge mask exists\n",
    "            if self.mask is None:\n",
    "                raise ValueError('No edge mask provided.')       \n",
    "\n",
    "            try:\n",
    "                # take a copy in case of error\n",
    "                tmp = self.ds.copy(deep=True)\n",
    "\n",
    "                # mask edge pixels to nan\n",
    "                self.ds = self.ds.where(self.mask)\n",
    "\n",
    "                # check if not all nan\n",
    "                if self.ds.to_array().isnull().all():\n",
    "                    raise ValueError('Mask set all pixels to nan, rolling back.')  \n",
    "\n",
    "            except Exception as e:\n",
    "                self.ds = tmp\n",
    "                raise ValueError(e)\n",
    "\n",
    "            return\n",
    "    \n",
    "    \n",
    "    def perform_kernel_density(self):\n",
    "        \"\"\"\n",
    "        Generates various summary states of vegetation\n",
    "        and change over time and displays it as\n",
    "        a kernel density raster. Error will result in\n",
    "        raised error.\n",
    "        \"\"\"\n",
    "\n",
    "        # ensure x, y and time in dataset\n",
    "        if 'x' not in self.ds or 'y' not in self.ds:\n",
    "            raise ValueError('No x, y dimensions.')\n",
    "        elif 'time' not in self.ds:\n",
    "            raise ValueError('No time dimensions.')\n",
    "\n",
    "        try:\n",
    "            # smooth dataset via mean\n",
    "            self.ds = self.ds.rolling(x=3, y=3, \n",
    "                                      center=True, \n",
    "                                      min_periods=1).mean()\n",
    "\n",
    "            # increase resolution of grid 5-fold\n",
    "            x_min, x_max = float(self.ds['x'].min()), float(self.ds['x'].max())\n",
    "            y_min, y_max = float(self.ds['y'].min()), float(self.ds['y'].max())\n",
    "\n",
    "            # generate high resolution coordinates\n",
    "            xs = np.linspace(x_min, x_max, len(self.ds['x']) * 5)\n",
    "            ys = np.linspace(y_min, y_max, len(self.ds['y']) * 5)\n",
    "\n",
    "            # interpolate values to new grid\n",
    "            self.ds = self.ds.interp(x=xs, y=ys)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if method provided \n",
    "        if self.method not in ['Static', 'Dynamic']:\n",
    "            raise ValueError('Change method not provided.')\n",
    "\n",
    "        # prepare method name\n",
    "        method = self.method.lower()\n",
    "\n",
    "        try:\n",
    "            # set up mask\n",
    "            da_mask = self.ds['veg_idx'].mean('time')\n",
    "            da_mask = xr.where(~da_mask.isnull(), True, False)\n",
    "            \n",
    "            # set up core arrays \n",
    "            da_veg = self.ds['veg_idx']\n",
    "            da_chg = self.ds['{}_clean'.format(method)]\n",
    "            da_zne = self.ds['{}_zones'.format(method)]\n",
    "            da_alt = self.ds['{}_alerts'.format(method)]\n",
    "                        \n",
    "            # get vege avg and std all-time\n",
    "            da_veg_avg = da_veg.mean('time')\n",
    "            da_veg_std = da_veg.std('time')\n",
    "            \n",
    "            # get latest vege\n",
    "            da_veg_lts = da_veg.isel(time=-2, drop=True)\n",
    "            \n",
    "            # get change max inc, dec all-time\n",
    "            da_chg_max_inc = da_chg.where(da_chg >= 0, 0).max('time')\n",
    "            da_chg_max_dec = da_chg.where(da_chg <= 0, 0).min('time')\n",
    "            \n",
    "            # get change avg inc, dec all-time\n",
    "            da_chg_avg_bth = da_chg.mean('time')\n",
    "            da_chg_avg_inc = da_chg.where(da_chg >= 0, 0).mean('time')\n",
    "            da_chg_avg_dec = da_chg.where(da_chg <= 0, 0).mean('time')            \n",
    "            \n",
    "            # get count alerts all time all dirs\n",
    "            da_alt_cnt_bth = da_alt.sum('time')\n",
    "            da_alt_cnt_inc = da_alt.where(da_chg >= 0, 0).sum('time')\n",
    "            da_alt_cnt_dec = da_alt.where(da_chg <= 0, 0).sum('time')\n",
    "            \n",
    "            # get latest change\n",
    "            da_chg_lts = da_chg.isel(time=-2, drop=True)\n",
    "            \n",
    "            # set up list of clean datasets\n",
    "            ds_list = [\n",
    "                da_veg_avg.to_dataset(name='vege_avg_all_time'),\n",
    "                da_veg_std.to_dataset(name='vege_std_all_time'),\n",
    "                da_veg_lts.to_dataset(name='vege_latest_time'),   \n",
    "                da_chg_max_inc.to_dataset(name='change_max_all_time_incline'),  \n",
    "                da_chg_max_dec.to_dataset(name='change_max_all_time_decline'),  \n",
    "                da_chg_avg_bth.to_dataset(name='change_avg_all_time_inc_dec'),  \n",
    "                da_chg_avg_inc.to_dataset(name='change_avg_all_time_incline'),  \n",
    "                da_chg_avg_dec.to_dataset(name='change_avg_all_time_decline'),                \n",
    "                da_chg_lts.to_dataset(name='change_latest_time'),   \n",
    "                da_alt_cnt_bth.to_dataset(name='alerts_cnt_all_time_inc_dec'),  \n",
    "                da_alt_cnt_inc.to_dataset(name='alerts_cnt_all_time_incline'),  \n",
    "                da_alt_cnt_dec.to_dataset(name='alerts_cnt_all_time_decline'),  \n",
    "            ]\n",
    "\n",
    "            # combine into one, apply mask\n",
    "            ds = xr.merge(ds_list)\n",
    "            ds = ds.where(da_mask)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "\n",
    "        # check if anything in dataset\n",
    "        if ds.to_array().isnull().all():\n",
    "            raise ValueError('No kernel densities could be generated.')\n",
    "\n",
    "        # set to class dataset\n",
    "        self.ds = ds.copy(deep=True)\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "    def append_attrs(self):\n",
    "        \"\"\"\n",
    "        Adds expected attributes to xr\n",
    "        dataset prior to export.\n",
    "        \"\"\"\n",
    "\n",
    "        # check if xr exists\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr dataset exists.')\n",
    "\n",
    "        # manually create attrs for dataset (geotiffs lacking) \n",
    "        self.ds = tools.manual_create_xr_attrs(self.ds)\n",
    "        self.ds.attrs.update({'nodatavals': np.nan})   \n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def export_xr(self):\n",
    "        \"\"\"\n",
    "        Exports kernel density-fied xr (which contains \n",
    "        everything)  to netcdf named with global id. An\n",
    "        error will raise an error.\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if xr valid\n",
    "        if self.ds is None:\n",
    "            raise ValueError('No xr provided.')\n",
    "        elif not isinstance(self.ds, xr.Dataset):\n",
    "            raise TypeError('The xr is not an xr dataset type.')\n",
    "            \n",
    "        # check if path and global id exist\n",
    "        if self.out_nc is None:\n",
    "            raise ValueError('No output NetCDF provided.')\n",
    "\n",
    "        try:           \n",
    "            # export nc\n",
    "            self.ds.to_netcdf(self.out_nc)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(e)\n",
    "        \n",
    "        return\n",
    "          \n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets all generated area parameters \n",
    "        and xr datasets. \n",
    "        \"\"\"\n",
    "\n",
    "        # set proj geom to none\n",
    "        self.prj_geom = None\n",
    "\n",
    "        # set alert info to none\n",
    "        self.alert_zone =  None\n",
    "        self.alert_flag =  None\n",
    "        self.alert_html =  None\n",
    "        self.alert_graph = None\n",
    "\n",
    "        # iter xrs and close \n",
    "        xrs = [self.ds, self.mask]\n",
    "        for x in xrs:\n",
    "            try:\n",
    "                if x is not None:\n",
    "                    x.close()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # set xrs to none\n",
    "        self.ds = None\n",
    "        self.ds_mask = None\n",
    "\n",
    "        return  \n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area_summary = MonitoringAreaStatistics(feat, path=in_path, out_nc=out_nc)\n",
    "area_summary.TESTING_END_DT = '2015-12-31'\n",
    "\n",
    "try:\n",
    "    # validate area\n",
    "    area_summary.validate_area()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "\n",
    "\n",
    "try:\n",
    "    # get and set all sat data from start training to now\n",
    "    area_summary.set_xr()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "\n",
    "\n",
    "try:\n",
    "    # apply fmask\n",
    "    area_summary.apply_xr_fmask()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "\n",
    "    \n",
    "try:\n",
    "    # calculate veg index\n",
    "    area_summary.apply_xr_index()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    # load (download) dataset\n",
    "    area_summary.load_xr()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)   \n",
    "    \n",
    "    \n",
    "try:\n",
    "    # set pixel edge mask here, apply later (need geobox)\n",
    "    area_summary.set_xr_edge_mask()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "\n",
    "    \n",
    "try:\n",
    "    # interpolate nans\n",
    "    area_summary.interp_xr_nans()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    # append required vars\n",
    "    area_summary.append_xr_vars()\n",
    "except Exception as e:\n",
    "    raise ValueError(e) \n",
    "    \n",
    "    \n",
    "try:\n",
    "    # fix spikes (may not want)\n",
    "    area_summary.fix_xr_spikes()\n",
    "except Exception as e:\n",
    "    raise ValueError(e) \n",
    "    \n",
    "\n",
    "try:\n",
    "    # smooth vege via savitsky golay\n",
    "    area_summary.smooth_xr_index()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)  \n",
    "\n",
    "\n",
    "try:\n",
    "    # detect change\n",
    "    area_summary.detect_change_xr()\n",
    "except Exception as e:\n",
    "    raise ValueError(e) \n",
    "\n",
    "\n",
    "try:\n",
    "    # smooth change via savitsky golay\n",
    "    area_summary.smooth_xr_change()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    # generate zones\n",
    "    area_summary.build_zones()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "\n",
    "\n",
    "try:\n",
    "    # generate rule one\n",
    "    area_summary.build_rule_one()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "\n",
    "    \n",
    "try:\n",
    "    # generate rule two\n",
    "    area_summary.build_rule_two()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)    \n",
    "    \n",
    "    \n",
    "try:\n",
    "    # generate rule three\n",
    "    area_summary.build_rule_three()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)    \n",
    "    \n",
    "\n",
    "try:\n",
    "    # generate alerts\n",
    "    area_summary.build_alerts()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)    \n",
    "\n",
    "    \n",
    "try:\n",
    "    # apply edge mask\n",
    "    area_summary.apply_xr_edge_mask()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)   \n",
    "    \n",
    "\n",
    "try:\n",
    "    # generate kernel density stats\n",
    "    area_summary.perform_kernel_density()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)    \n",
    "\n",
    "    \n",
    "try:\n",
    "    # append attributes to xr\n",
    "    area_summary.append_attrs()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)    \n",
    "\n",
    "\n",
    "try:\n",
    "    # append export netcdf\n",
    "    area_summary.export_xr()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    # close data\n",
    "    area_summary.reset()\n",
    "except Exception as e:\n",
    "    raise ValueError(e)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab parameter values \n",
    "in_exist_feat = r\"C:\\Users\\Lewis\\Desktop\\nrt_projects\\Test\\monitoring_areas.gdb\\monitoring_areas\"\n",
    "in_new_feat = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\project\\tenement-tools-project\\tenement-tools-project.gdb\\Polygons_7\"\n",
    "in_area_id = 'A1'\n",
    "in_platform = 'Landsat'\n",
    "in_s_year = 2000\n",
    "in_e_year = 2005\n",
    "in_veg_idx = 'MAVI'\n",
    "in_persistence = 0.5\n",
    "in_rule_1_min_conseqs = 3\n",
    "in_rule_1_inc_plateaus = 'No'\n",
    "in_rule_2_min_zone = 2\n",
    "in_rule_3_num_zones = 2\n",
    "in_ruleset = '1 and 2 or 3'\n",
    "in_alert_user = 'No'\n",
    "in_alert_method = 'Static'\n",
    "in_alert_direction = 'Decline only (any)'\n",
    "in_email = None\n",
    "in_ignore = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T08:03:25.325963Z",
     "start_time": "2022-05-24T08:03:25.252595Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T08:04:20.714547Z",
     "start_time": "2022-05-24T08:04:20.713274Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T08:08:03.380727Z",
     "start_time": "2022-05-24T08:08:03.379152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T07:50:27.530420Z",
     "start_time": "2022-05-24T07:50:27.528743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D object at 0x0000022AFC6CE148>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T07:57:08.501940Z",
     "start_time": "2022-05-24T07:57:08.425438Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
