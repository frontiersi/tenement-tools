{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T03:19:13.693078Z",
     "start_time": "2022-05-15T03:19:02.855655Z"
    }
   },
   "outputs": [],
   "source": [
    "# globals (dev)\n",
    "FOLDER_MODULES = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\modules'  \n",
    "FOLDER_SHARED = r'C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\shared'\n",
    "GRP_LYR_FILE = r\"C:\\Users\\Lewis\\Documents\\GitHub\\tenement-tools\\arc\\lyr\\group_template.lyrx\"\n",
    "\n",
    "# set gdal global environ\n",
    "import os\n",
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN'] = 'EMPTY_DIR'\n",
    "os.environ['CPL_VSIL_CURL_ALLOWED_EXTENSIONS '] = 'tif'\n",
    "os.environ['VSI_CACHE '] = 'TRUE'\n",
    "os.environ['GDAL_HTTP_MULTIRANGE '] = 'YES'\n",
    "os.environ['GDAL_HTTP_MERGE_CONSECUTIVE_RANGES '] = 'YES'\n",
    "\n",
    "# also set rasterio env variables\n",
    "rasterio_env = {\n",
    "    'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR',\n",
    "    'CPL_VSIL_CURL_ALLOWED_EXTENSIONS': 'tif',\n",
    "    'VSI_CACHE': True,\n",
    "    'GDAL_HTTP_MULTIRANGE': 'YES',\n",
    "    'GDAL_HTTP_MERGE_CONSECUTIVE_RANGES': 'YES'\n",
    "}\n",
    "\n",
    "# disable future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# safe imports\n",
    "import sys                  # arcgis comes with these\n",
    "import datetime                 # arcgis comes with these\n",
    "import pandas as pd\n",
    "import numpy as np              # arcgis comes with these\n",
    "import arcpy                    # arcgis comes with these\n",
    "from datetime import datetime   # arcgis comes with these\n",
    "\n",
    "# risky imports (not native to arcgis)\n",
    "try:\n",
    "    import xarray as xr\n",
    "    import dask\n",
    "    import rasterio\n",
    "    import pystac_client\n",
    "    from odc import stac\n",
    "except:\n",
    "    arcpy.AddError('Python libraries xarray, dask, rasterio, pystac, or odc not installed.')\n",
    "    raise\n",
    "\n",
    "# import tools\n",
    "try:\n",
    "    # shared folder\n",
    "    sys.path.append(FOLDER_SHARED)\n",
    "    import arc, satfetcher, tools\n",
    "\n",
    "    # module folder\n",
    "    sys.path.append(FOLDER_MODULES)\n",
    "    import cog_odc, canopy, nicher, vegfrax\n",
    "except:\n",
    "    arcpy.AddError('Could not find tenement tools python scripts (modules, shared).')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T03:19:13.697217Z",
     "start_time": "2022-05-15T03:19:13.693329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'vegfrax' from 'C:\\\\Users\\\\Lewis\\\\Documents\\\\GitHub\\\\tenement-tools\\\\modules\\\\vegfrax.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(vegfrax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T03:19:17.505246Z",
     "start_time": "2022-05-15T03:19:17.478393Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(self, parameters, messages):\n",
    "    \"\"\"\n",
    "    Executes the VegFrax Fractional Cover module.\n",
    "    \"\"\"\n",
    "\n",
    "    # safe imports\n",
    "    import os, sys                         \n",
    "    import datetime                        \n",
    "    import numpy as np                     \n",
    "    import pandas as pd                    \n",
    "    import tempfile                        \n",
    "\n",
    "    # risk imports (non-native to arcgis)\n",
    "    try:\n",
    "        import xarray as xr\n",
    "        import dask\n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Python libraries xarray and dask not installed.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # import tools\n",
    "    try:\n",
    "        # shared folder\n",
    "        sys.path.append(FOLDER_SHARED)\n",
    "        import arc, satfetcher, tools  \n",
    "\n",
    "        # module folder\n",
    "        sys.path.append(FOLDER_MODULES)\n",
    "        import vegfrax, cog  \n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not find tenement tools python scripts (modules, shared).')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # disable future warnings\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "    warnings.simplefilter(action='ignore', category=dask.array.core.PerformanceWarning)\n",
    "\n",
    "    # grab parameter values \n",
    "    in_low_nc = parameters[0].valueAsText             # raw input low res netcdf\n",
    "    in_high_tif = parameters[1].valueAsText           # raw input high res tif\n",
    "    out_nc = parameters[2].valueAsText                # output vegfrax netcdf\n",
    "    in_agg_dates = parameters[3].value                # aggregate all dates\n",
    "    in_start_date = parameters[4].value               # start date of aggregate\n",
    "    in_end_date = parameters[5].value                 # end date of aggregate\n",
    "    in_classes = parameters[6].valueAsText            # selected classes\n",
    "    in_agg_classes = parameters[7].value              # aggregate selected classes       \n",
    "    in_num_samples = parameters[8].value              # number of samples\n",
    "    in_max_nodata = parameters[9].value               # max nodata frequency\n",
    "    in_smooth = parameters[10].value                  # smooth output\n",
    "    in_num_estimator = parameters[11].value           # number of model estimators\n",
    "    in_criterion = parameters[12].value               # criterion type\n",
    "    in_max_depth = parameters[13].value               # max tree depth\n",
    "    in_max_features = parameters[14].value            # maximum features\n",
    "    in_bootstrap = parameters[15].value               # boostrap\n",
    "    in_fmask_flags = parameters[16].valueAsText       # fmask flag values\n",
    "    in_max_cloud = parameters[17].value               # max cloud percentage\n",
    "    in_add_result_to_map = parameters[18].value       # add result to map\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify user and set up progress bar\n",
    "    arcpy.AddMessage('Beginning VegFrax Fractional Cover.')\n",
    "    arcpy.SetProgressor(type='step', \n",
    "                        message='Preparing parameters...', \n",
    "                        min_range=0, max_range=19)\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Loading and checking satellite NetCDF...')\n",
    "    arcpy.SetProgressorPosition(1)\n",
    "\n",
    "    try:\n",
    "        # do quick lazy load of satellite netcdf for checking\n",
    "        ds_low = xr.open_dataset(in_low_nc)\n",
    "    except Exception as e:\n",
    "        arcpy.AddWarning('Could not quick load input satellite NetCDF data.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # check xr type, vars, coords, dims, attrs\n",
    "    if not isinstance(ds_low, xr.Dataset):\n",
    "        arcpy.AddError('Input satellite NetCDF must be a xr dataset.')\n",
    "        return\n",
    "    elif len(ds_low) == 0:\n",
    "        arcpy.AddError('Input NetCDF has no data/variables/bands.')\n",
    "        return\n",
    "    elif 'x' not in ds_low.dims or 'y' not in ds_low.dims or 'time' not in ds_low.dims:\n",
    "        arcpy.AddError('Input satellite NetCDF must have x, y and time dimensions.')\n",
    "        return\n",
    "    elif 'x' not in ds_low.coords or 'y' not in ds_low.coords or 'time' not in ds_low.coords:\n",
    "        arcpy.AddError('Input satellite NetCDF must have x, y and time coords.')\n",
    "        return\n",
    "    elif 'spatial_ref' not in ds_low.coords:\n",
    "        arcpy.AddError('Input satellite NetCDF must have a spatial_ref coord.')\n",
    "        return\n",
    "    elif len(ds_low['x']) == 0 or len(ds_low['y']) == 0 or len(ds_low['time']) == 0:\n",
    "        arcpy.AddError('Input satellite NetCDF must have all at least one x, y and time index.')\n",
    "        return\n",
    "    elif 'oa_fmask' not in ds_low and 'fmask' not in ds_low:\n",
    "        arcpy.AddError('Expected cloud mask band not found in satellite NetCDF.')\n",
    "        return\n",
    "    elif not hasattr(ds_low, 'time.year') or not hasattr(ds_low, 'time.month'):\n",
    "        arcpy.AddError('Input satellite NetCDF must have time with year and month component.')\n",
    "        return\n",
    "    elif ds_low.attrs == {}:\n",
    "        arcpy.AddError('Satellite NetCDF must have attributes.')\n",
    "        return\n",
    "    elif not hasattr(ds_low, 'crs'):\n",
    "        arcpy.AddError('Satellite NetCDF CRS attribute not found. CRS required.')\n",
    "        return\n",
    "    elif ds_low.crs != 'EPSG:3577':\n",
    "        arcpy.AddError('Satellite NetCDF CRS is not in GDA94 Albers (EPSG:3577).')            \n",
    "        return \n",
    "    elif not hasattr(ds_low, 'nodatavals'):\n",
    "        arcpy.AddError('Satellite NetCDF nodatavals attribute not found.')            \n",
    "        return \n",
    "\n",
    "    # efficient: if all nan, 0 at first var, assume rest same, so abort\n",
    "    if ds_low[list(ds_low)[0]].isnull().all() or (ds_low[list(ds_low)[0]] == 0).all():\n",
    "        arcpy.AddError('Satellite NetCDF has empty variables. Please download again.')            \n",
    "        return \n",
    "\n",
    "    try:\n",
    "        # now, do proper open of satellite netcdf properly (and set nodata to nan)\n",
    "        ds_low = satfetcher.load_local_nc(nc_path=in_low_nc, \n",
    "                                          use_dask=True, \n",
    "                                          conform_nodata_to=np.nan)\n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not properly load input satellite NetCDF data.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Getting NetCDF attributes...')\n",
    "    arcpy.SetProgressorPosition(2)\n",
    "\n",
    "    # get attributes from dataset\n",
    "    ds_attrs = ds_low.attrs\n",
    "    ds_band_attrs = ds_low[list(ds_low)[0]].attrs\n",
    "    ds_spatial_ref_attrs = ds_low['spatial_ref'].attrs\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Grouping dates, if required...')\n",
    "    arcpy.SetProgressorPosition(3)\n",
    "\n",
    "    # remove potential datetime duplicates (group by day)\n",
    "    ds_low = satfetcher.group_by_solar_day(ds_low)\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Reducing dataset dates, if requested...')\n",
    "    arcpy.SetProgressorPosition(4)\n",
    "\n",
    "    # check if dates are to be aggregated\n",
    "    if in_agg_dates is None:\n",
    "        arcpy.AddError('Must specify whether to aggregate dates or not.')\n",
    "        return\n",
    "\n",
    "    # if requested...\n",
    "    if in_agg_dates is False:\n",
    "\n",
    "        # check start and end dates \n",
    "        if in_start_date is None or in_end_date is None:\n",
    "            arcpy.AddError('Did not provide a start or end date.')\n",
    "            return\n",
    "\n",
    "        # prepare start, end dates\n",
    "        in_start_date = in_start_date.strftime('%Y-%m-%d')\n",
    "        in_end_date = in_end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        # check date range is valid\n",
    "        if in_start_date >= in_end_date:\n",
    "            arcpy.AddError('End date must be greater than start date.')\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # subset to requested date range\n",
    "            ds_low = vegfrax.subset_dates(ds=ds_low, \n",
    "                                          start_date=in_start_date,\n",
    "                                          end_date=in_end_date)\n",
    "        except Exception as e: \n",
    "            arcpy.AddError('Could not subset satellite NetCDF, see messages for details.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            return\n",
    "\n",
    "        # check if any dates exist \n",
    "        if 'time' not in ds_low or len(ds_low['time']) == 0:\n",
    "            arcpy.AddError('No dates exist in satellite NetCDF for requested date range.')\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Removing invalid pixels and empty dates...')\n",
    "    arcpy.SetProgressorPosition(5)  \n",
    "\n",
    "    # convert fmask as text to numeric code equivalents      \n",
    "    in_fmask_flags = [e for e in in_fmask_flags.split(';')]        \n",
    "    in_fmask_flags = arc.convert_fmask_codes(in_fmask_flags)\n",
    "\n",
    "    # check if flags selected, if not, select all \n",
    "    if len(in_fmask_flags) == 0:\n",
    "        arcpy.AddWarning('No flags set, selecting default')\n",
    "        in_fmask_flags = [1, 4, 5]\n",
    "\n",
    "    # check numeric flags are valid \n",
    "    for flag in in_fmask_flags:\n",
    "        if flag not in [0, 1, 2, 3, 4, 5, 6]:\n",
    "            arcpy.AddError('Pixel flag not supported.')\n",
    "            return\n",
    "\n",
    "    # check if duplicate flags \n",
    "    u, c = np.unique(in_fmask_flags, return_counts=True)\n",
    "    if len(u[c > 1]) > 0:\n",
    "        arcpy.AddError('Duplicate pixel flags detected.')\n",
    "        return\n",
    "\n",
    "    # check if mask band exists\n",
    "    mask_band = arc.get_name_of_mask_band(list(ds_low))\n",
    "\n",
    "    try:\n",
    "        # remove invalid pixels and empty scenes\n",
    "        ds_low = cog.remove_fmask_dates(ds=ds_low, \n",
    "                                        valid_class=in_fmask_flags, \n",
    "                                        max_invalid=in_max_cloud, \n",
    "                                        mask_band=mask_band, \n",
    "                                        nodata_value=np.nan, \n",
    "                                        drop_fmask=True)\n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not cloud mask pixels.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # check if any dates remain \n",
    "    if 'time' not in ds_low or len(ds_low['time']) == 0:\n",
    "        arcpy.AddError('No cloud-free data exists in satellite NetCDF for requested date range.')\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Conforming satellite band names...')\n",
    "    arcpy.SetProgressorPosition(6)        \n",
    "\n",
    "    try:\n",
    "        # get platform name from attributes, error if no attributes\n",
    "        in_platform = arc.get_platform_from_dea_attrs(ds_attrs)\n",
    "\n",
    "        # conform dea aws band names based on platform\n",
    "        ds_low = satfetcher.conform_dea_ard_band_names(ds=ds_low, \n",
    "                                                       platform=in_platform.lower())   \n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not get platform from attributes.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # check if all expected bands are in dataset \n",
    "    for band in ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']:\n",
    "        if band not in ds_low:\n",
    "            arcpy.AddError('Satellite NetCDF is missing band: {}. Need all bands.'.format(band))\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Calculating tasselled cap index...')\n",
    "    arcpy.SetProgressorPosition(7)        \n",
    "\n",
    "    try:\n",
    "        # calculate tasselled cap green, bare, water\n",
    "        ds_low = tools.calculate_indices(ds=ds_low, \n",
    "                                         index=['tcg', 'tcb', 'tcw'], \n",
    "                                         rescale=False, \n",
    "                                         drop=True)\n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not calculate tasselled cap index.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Reducing dataset into all-time median...')\n",
    "    arcpy.SetProgressorPosition(8)\n",
    "\n",
    "    try:\n",
    "        # reduce into an all-time median \n",
    "        ds_low = vegfrax.reduce_to_median(ds=ds_low)\n",
    "\n",
    "        # add band attrs back on\n",
    "        ds_low['tcg'].attrs = ds_band_attrs   \n",
    "        ds_low['tcb'].attrs = ds_band_attrs\n",
    "        ds_low['tcw'].attrs = ds_band_attrs\n",
    "\n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not reduce satellite NetCDF to all-time median.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Computing satellite NetCDF into memory, please wait...')\n",
    "    arcpy.SetProgressorPosition(9)\n",
    "\n",
    "    try:\n",
    "        # compute! \n",
    "        ds_low = ds_low.compute()\n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not compute satellite NetCDF. See messages for details.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # check if all nan again\n",
    "    if ds_low.to_array().isnull().all():\n",
    "        arcpy.AddError('Satellite NetCDF is empty. Please download again.')            \n",
    "        return    \n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Loading and checking classified GeoTiff...')\n",
    "    arcpy.SetProgressorPosition(10)\n",
    "\n",
    "    # check if type is geotiff \n",
    "    if not in_high_tif.endswith('.tif'):\n",
    "        arcpy.AddError('High-resolution input is not a GeoTiff.')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # do quick lazy load of geotiff for checking\n",
    "        ds_high = xr.open_rasterio(in_high_tif)\n",
    "        ds_high = ds_high.to_dataset(dim='band')                  \n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not quick load input classified GeoTiff.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # check xr type, vars, coords, dims, attrs\n",
    "    if not isinstance(ds_high, xr.Dataset):\n",
    "        arcpy.AddError('Input GeoTiff must be an xr dataset.')\n",
    "        return\n",
    "    elif len(ds_high) == 0:\n",
    "        arcpy.AddError('Input GeoTiff has no data/variables/bands.')\n",
    "        return\n",
    "    elif len(ds_high) != 1:\n",
    "        arcpy.AddError('Input GeoTiff has multiple bands.')\n",
    "        return\n",
    "    elif 'x' not in list(ds_high.coords) or 'y' not in list(ds_high.coords):\n",
    "        arcpy.AddError('Input GeoTiff must have x, y coords.')\n",
    "        return\n",
    "    elif 'x' not in list(ds_high.dims) or 'y' not in list(ds_high.dims):\n",
    "        arcpy.AddError('Input GeoTiff must have x, y dimensions.')\n",
    "        return\n",
    "    elif len(ds_high['x']) == 0 or len(ds_high['y']) == 0:\n",
    "        arcpy.AddError('Input GeoTiff must have at least one x, y index.')\n",
    "        return\n",
    "    elif ds_high.attrs == {}:\n",
    "        arcpy.AddError('GeoTiff attributes not found. GeoTiff must have attributes.')\n",
    "        return\n",
    "    elif not hasattr(ds_high, 'crs'):\n",
    "        arcpy.AddError('GeoTiff CRS attribute not found. CRS required.')\n",
    "        return\n",
    "    elif '3577' not in ds_high.crs:\n",
    "        arcpy.AddError('GeoTiff CRS is not EPSG:3577. EPSG:3577 required.')            \n",
    "        return\n",
    "    elif not hasattr(ds_high, 'nodatavals'):\n",
    "        arcpy.AddError('GeoTiff nodatavals attribute not found.')            \n",
    "        return\n",
    "    elif 'int' not in str(ds_high.to_array().dtype):\n",
    "        arcpy.AddError('GeoTiff is not an integer type. Please convert.')            \n",
    "        return\n",
    "    elif np.nan in ds_high.to_array():\n",
    "        arcpy.AddError('GeoTiff contains reserved value nan. Please convert.')            \n",
    "        return\n",
    "    elif -999 in ds_high.to_array():\n",
    "        arcpy.AddWarning('GeoTiff contains reserved value -999, will be considered as NoData.')            \n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # do proper load with dask, set nodata to -999\n",
    "        ds_high = satfetcher.load_local_rasters(rast_path_list=in_high_tif, \n",
    "                                                use_dask=True, \n",
    "                                                conform_nodata_to=-999)\n",
    "\n",
    "        # rename first and only band, manually build attributes\n",
    "        ds_high = ds_high.rename({list(ds_high)[0]: 'classes'})\n",
    "        ds_high = tools.manual_create_xr_attrs(ds=ds_high)\n",
    "\n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not properly load classified GeoTiff, see messages.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # check if not all nodata (-999)\n",
    "    if (ds_high.to_array() == -999).all():\n",
    "        arcpy.AddError('Input classified GeoTiff is completely empty.')            \n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Clipping classified GeoTiff to satellite NetCDF...')\n",
    "    arcpy.SetProgressorPosition(11)     \n",
    "\n",
    "    # check extents overlap\n",
    "    if not tools.all_xr_intersect([ds_low, ds_high]):\n",
    "        arcpy.AddError('Not all input layers intersect.')            \n",
    "        return \n",
    "\n",
    "    try:\n",
    "        # clip classified geotiff extent to netcdf\n",
    "        ds_high = tools.clip_xr_a_to_xr_b(ds_a=ds_high, \n",
    "                                          ds_b=ds_low)\n",
    "\n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not clip GeoTiff to NetCDF, see messages for details.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Computing GeoTiff into memory, please wait...')\n",
    "    arcpy.SetProgressorPosition(12)\n",
    "\n",
    "    try:\n",
    "        # compute geotiff! \n",
    "        ds_high = ds_high.compute()\n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not compute GeoTiff, see messages for details.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # ensure geotiff dataset still integer and not empty\n",
    "    if 'int' not in str(ds_high.to_array().dtype):\n",
    "        arcpy.AddError('GeoTiff was unable to maintain integer type.')            \n",
    "        return \n",
    "    elif (ds_high.to_array() == -999).all():\n",
    "        arcpy.AddError('GeoTiff is completely empty.')            \n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and set on-going progess bar\n",
    "    arcpy.SetProgressor('default', 'Generating stratified random samples...')\n",
    "\n",
    "    # ensure requested classes valid \n",
    "    if in_classes is None:\n",
    "        arcpy.AddError('No classes were selected.')\n",
    "        return\n",
    "\n",
    "    # prepare requested classes from ui\n",
    "    in_classes = in_classes.replace('Class: ', '').replace(\"'\", '')\n",
    "    in_classes = [int(c) for c in in_classes.split(';')]\n",
    "\n",
    "    # get all available classes in dataset\n",
    "    all_classes = list(np.unique(ds_high.to_array()))\n",
    "\n",
    "    # clean and check both class arrays\n",
    "    for arr in [in_classes, all_classes]:\n",
    "\n",
    "        # remove nodata if exists\n",
    "        if -999 in arr:\n",
    "            arr.remove(-999)\n",
    "\n",
    "        # check something remains \n",
    "        if arr is None or len(arr) == 0:\n",
    "            arcpy.AddError('No classes were obtained from selection and/or dataset.')\n",
    "            return\n",
    "\n",
    "    # check if more than one non-nodata classes in geotiff \n",
    "    if len(all_classes) < 2:\n",
    "        arcpy.AddError('More than one GeoTiff class required.')\n",
    "        return\n",
    "\n",
    "    # ensure all requested classes still available \n",
    "    for c in in_classes:\n",
    "        if c not in all_classes:\n",
    "            arcpy.AddError('Class {} not within satellite NetCDF extent.'.format(c))\n",
    "            return\n",
    "\n",
    "    # check number of samples \n",
    "    if in_num_samples < 1:\n",
    "        arcpy.AddError('Number of samples must be 1 or more.')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # generate stratified random samples (number per class)\n",
    "        df_samples = vegfrax.build_random_samples(ds_low=ds_low, \n",
    "                                                  ds_high=ds_high, \n",
    "                                                  classes=all_classes,\n",
    "                                                  num_samples=in_num_samples)\n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not build random samples, see messages for details.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # warn (but continue) if undersampled \n",
    "    if len(df_samples) < len(all_classes) * in_num_samples:\n",
    "        arcpy.AddWarning('Caution, smaller classes may be under-sampled.')\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progess bar\n",
    "    arcpy.SetProgressorLabel('Extracting tasselled cap values...')\n",
    "    arcpy.SetProgressorPosition(13)\n",
    "\n",
    "    try:\n",
    "        # extract tasselled cap band values at each random sample\n",
    "        df_samples = vegfrax.extract_xr_low_values(df=df_samples, \n",
    "                                                   ds=ds_low)\n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not extract values, see messages for details.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "    # ensure we have samples still \n",
    "    if len(df_samples) == 0:\n",
    "        arcpy.AddError('No tasselled cap values were extracted.')\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progess bar\n",
    "    arcpy.SetProgressorLabel('Building class fraction arrays...')\n",
    "    arcpy.SetProgressorPosition(14)\n",
    "\n",
    "    # ensure max nodata is valid \n",
    "    if in_max_nodata < 0 or in_max_nodata > 1:\n",
    "        arcpy.AddError('Maximum NoData value must be >= 0 and <= 1.')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # build class fraction windows and arrays\n",
    "        df_samples = vegfrax.build_class_fractions(df=df_samples, \n",
    "                                                   ds_low=ds_low, \n",
    "                                                   ds_high=ds_high, \n",
    "                                                   max_nodata=in_max_nodata)\n",
    "    except Exception as e: \n",
    "        arcpy.AddError('Could not build class fraction arrays, see messages for details.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and set on-going progess bar\n",
    "    arcpy.SetProgressor('default', 'Performing fractional cover analysis...')\n",
    "\n",
    "    # check aggregate classes valid \n",
    "    if in_agg_classes not in [True, False]:\n",
    "        arcpy.AddError('Combine classes is invalid.')\n",
    "        return\n",
    "\n",
    "    # check model parameters are valid\n",
    "    if in_num_estimator < 1:\n",
    "        arcpy.AddError('Number of model estimators not between 1 and 10000.')\n",
    "        return\n",
    "    elif in_criterion not in ['Mean Squared Error', 'Mean Absolute Error', 'Poisson']:\n",
    "        arcpy.AddError('Criterion not supported.')\n",
    "        return\n",
    "    elif in_max_depth is not None and in_max_depth < 1:\n",
    "        arcpy.AddError('Maximum depth must be empty or > 0.')\n",
    "        return\n",
    "    elif in_max_features not in ['Auto', 'Log2']:\n",
    "        arcpy.AddError('Maximum features must be Auto or Log2.')\n",
    "        return\n",
    "    elif in_bootstrap not in [True, False]:\n",
    "        arcpy.AddError('Boostrap must be either True or False.')\n",
    "        return\n",
    "\n",
    "    # prepare criterion value\n",
    "    if 'Squared' in in_criterion:\n",
    "        in_criterion = 'squared_error'\n",
    "    elif 'Absolute' in in_criterion:\n",
    "        in_criterion = 'absolute_error'\n",
    "    else:\n",
    "        in_criterion = 'poisson'\n",
    "\n",
    "    # prepare options \n",
    "    options = {\n",
    "        'n_estimators': in_num_estimator,\n",
    "        'criterion': in_criterion,\n",
    "        'max_depth': in_max_depth,\n",
    "        'max_features': in_max_features.lower(),\n",
    "        'bootstrap': in_bootstrap\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # perform fca and accuracy result message\n",
    "        ds_frax, result = vegfrax.perform_fcover_analysis(df=df_samples, \n",
    "                                                          ds=ds_low, \n",
    "                                                          classes=in_classes,\n",
    "                                                          combine=in_agg_classes, \n",
    "                                                          options=options)\n",
    "        # display accuracy results\n",
    "        arcpy.AddMessage(result)\n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not perform fractional cover analysis, see messages for details.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return \n",
    "\n",
    "    # check frax dataset if all nan\n",
    "    if ds_frax.to_array().isnull().all():\n",
    "        arcpy.AddError('Fractional cover dataset result is empty.')            \n",
    "        return \n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Smoothing dataset, if requested...')\n",
    "    arcpy.SetProgressorPosition(15) \n",
    "\n",
    "    # check if smooth is valid \n",
    "    if in_smooth not in [True, False]:\n",
    "        arcpy.AddError('Smooth output is invalid.')\n",
    "        return\n",
    "\n",
    "    # if requested...\n",
    "    if in_smooth:\n",
    "        try:\n",
    "            # smooth via median filter\n",
    "            ds_frax = vegfrax.smooth(ds_frax)\n",
    "        except Exception as e:\n",
    "            arcpy.AddError('Could not smooth dataset, see messages for details.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progess bar\n",
    "    arcpy.SetProgressorLabel('Appending attributes back on to dataset...')\n",
    "    arcpy.SetProgressorPosition(16)\n",
    "\n",
    "    # append attrbutes on to dataset and bands\n",
    "    ds_frax.attrs = ds_attrs\n",
    "    ds_frax['spatial_ref'].attrs = ds_spatial_ref_attrs\n",
    "    for var in ds_frax:\n",
    "        ds_frax[var].attrs = ds_band_attrs\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progess bar\n",
    "    arcpy.SetProgressorLabel('Exporting NetCDF file...')\n",
    "    arcpy.SetProgressorPosition(17)   \n",
    "\n",
    "    try:\n",
    "        # export netcdf file\n",
    "        tools.export_xr_as_nc(ds=ds_frax, filename=out_nc)\n",
    "    except Exception as e:\n",
    "        arcpy.AddError('Could not export dataset.')\n",
    "        arcpy.AddMessage(str(e))\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # notify and increment progress bar\n",
    "    arcpy.SetProgressorLabel('Adding output to map, if requested...')\n",
    "    arcpy.SetProgressorPosition(18)\n",
    "\n",
    "    # if requested...\n",
    "    if in_add_result_to_map:\n",
    "        try:\n",
    "            # open current map\n",
    "            aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "            m = aprx.activeMap\n",
    "\n",
    "            # remove existing fractional layers if exist\n",
    "            for layer in m.listLayers():\n",
    "                if layer.isGroupLayer and layer.name == 'fractions':\n",
    "                    m.removeLayer(layer)\n",
    "\n",
    "            # setup a group layer via template\n",
    "            grp_lyr = arcpy.mp.LayerFile(GRP_LYR_FILE)\n",
    "            grp = m.addLayer(grp_lyr)[0]\n",
    "            grp.name = 'fractions'\n",
    "\n",
    "            # create output folder using datetime as name\n",
    "            dt = datetime.datetime.now().strftime('%d%m%Y%H%M%S')\n",
    "            out_folder = os.path.join(os.path.dirname(out_nc), 'fractions' + '_' + dt)\n",
    "            os.makedirs(out_folder)\n",
    "\n",
    "            # disable visualise on map temporarily\n",
    "            arcpy.env.addOutputsToMap = False\n",
    "\n",
    "            # iter each var and export a seperate tif\n",
    "            tif_list = []\n",
    "            for var in ds_frax:\n",
    "\n",
    "                # create temp netcdf for one var (prevents 2.9 bug)\n",
    "                with tempfile.NamedTemporaryFile() as tmp:\n",
    "                    tmp_nc = '{}_{}.nc'.format(tmp.name, var)\n",
    "                    ds_frax[[var]].to_netcdf(tmp_nc)\n",
    "\n",
    "                # build in-memory crf for temp netcdf\n",
    "                crf = arcpy.md.MakeMultidimensionalRasterLayer(in_multidimensional_raster=tmp_nc, \n",
    "                                                               out_multidimensional_raster_layer=var)\n",
    "\n",
    "                # export temp tif\n",
    "                tmp_tif = os.path.join(out_folder, '{}.tif'.format(var))\n",
    "                tif = arcpy.management.CopyRaster(in_raster=crf, \n",
    "                                                  out_rasterdataset=tmp_tif)\n",
    "\n",
    "                # add temp tif to map and get as layer\n",
    "                m.addDataFromPath(tif)\n",
    "                layer = m.listLayers('{}.tif'.format(var))[0]\n",
    "\n",
    "                # hide layer once added\n",
    "                #layer.visible = False\n",
    "\n",
    "                # add layer to group and then remove outside layer\n",
    "                m.addLayerToGroup(grp, layer, 'BOTTOM')\n",
    "                m.removeLayer(layer) \n",
    "\n",
    "                # success, add store current layer for symbology below\n",
    "                tif_list.append('{}.tif'.format(var))\n",
    "\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not visualise output, aborting visualisation.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            pass\n",
    "\n",
    "        try:       \n",
    "            # iter tif layer names and update symbology\n",
    "            for tif in tif_list:\n",
    "                layer = m.listLayers(tif)[0]\n",
    "                sym = layer.symbology                    \n",
    "\n",
    "                # if layer has stretch coloriser, apply color\n",
    "                if hasattr(sym, 'colorizer'):\n",
    "                    if sym.colorizer.type == 'RasterStretchColorizer':\n",
    "\n",
    "                        # apply percent clip type and threshold \n",
    "                        sym.colorizer.stretchType = 'PercentClip'\n",
    "                        sym.colorizer.minPercent = 0.1\n",
    "                        sym.colorizer.maxPercent = 0.1\n",
    "\n",
    "                        # create color map and apply\n",
    "                        cmap = aprx.listColorRamps('Temperature')[0]                              \n",
    "                        sym.colorizer.colorRamp = cmap\n",
    "\n",
    "                        # apply other basic options\n",
    "                        sym.colorizer.invertColorRamp = False\n",
    "                        sym.colorizer.gamma = 1.0\n",
    "\n",
    "                        # update symbology\n",
    "                        layer.symbology = sym\n",
    "\n",
    "                        # show layer \n",
    "                        #layer.visible = True\n",
    "\n",
    "        except Exception as e:\n",
    "            arcpy.AddWarning('Could not colorise output, aborting colorisation.')\n",
    "            arcpy.AddMessage(str(e))\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "    # # # # #\n",
    "    # clean up variables\n",
    "    arcpy.SetProgressorLabel('Finalising process...')\n",
    "    arcpy.SetProgressorPosition(19)\n",
    "\n",
    "    # close and del dataset\n",
    "    ds_low.close()\n",
    "    ds_high.close()\n",
    "    ds_frax.close()\n",
    "    del ds_low\n",
    "    del ds_high\n",
    "    del ds_frax\n",
    "\n",
    "    # notify user\n",
    "    arcpy.AddMessage('Generated VegFrax successfully.')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check extents overlap\n",
    "if not tools.all_xr_intersect(ds_list):\n",
    "    arcpy.AddError('Not all input layers intersect.')            \n",
    "    return \n",
    "\n",
    "# check resample\n",
    "if in_resample not in ['Lowest Resolution', 'Highest Resolution']:\n",
    "    arcpy.AddError('Resample type not supported.')\n",
    "    return\n",
    "\n",
    "try:\n",
    "    # select target resolution dataset\n",
    "    ds_target = tools.get_target_res_xr(ds_list, \n",
    "                                        in_resample)\n",
    "except Exception as e:\n",
    "    arcpy.AddError('Could not get target GeoTiff resolution.')\n",
    "    arcpy.AddMessage(str(e))\n",
    "    return\n",
    "\n",
    "# check target xr captured\n",
    "if ds_target is None:\n",
    "    arcpy.AddError('Could not obtain optimal GeoTiff resolution.')            \n",
    "    return    \n",
    "\n",
    "try:\n",
    "    # resample all datasets to target dataset\n",
    "    for idx in range(len(ds_list)):\n",
    "        ds_list[idx] = tools.resample_xr(ds_from=ds_list[idx], \n",
    "                                         ds_to=ds_target,\n",
    "                                         resampling='nearest')\n",
    "\n",
    "        # squeeze to be safe!\n",
    "        ds_list[idx] = ds_list[idx].squeeze(drop=True)\n",
    "except Exception as e:\n",
    "    arcpy.AddError('Could not resample GeoTiffs.')\n",
    "    arcpy.AddMessage(str(e))\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # # #\n",
    "# notify and increment progess bar\n",
    "arcpy.SetProgressorLabel('Combining GeoTiffs together...')\n",
    "arcpy.SetProgressorPosition(4)\n",
    "\n",
    "try:\n",
    "    # merge vars into one dataset, fix attrs\n",
    "    ds = xr.merge(ds_list)\n",
    "    ds = tools.manual_create_xr_attrs(ds=ds)\n",
    "except Exception as e:\n",
    "    arcpy.AddError('Could not combine GeoTiffs.')\n",
    "    arcpy.AddMessage(str(e))\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "# # # # #\n",
    "# notify and increment progess bar\n",
    "arcpy.SetProgressorLabel('Reducing data to smallest GeoTiff extent...')\n",
    "arcpy.SetProgressorPosition(5)\n",
    "\n",
    "try:\n",
    "    # ensure bounding box is fixed to smallest mbr\n",
    "    ds = tools.remove_nan_xr_bounds(ds=ds)\n",
    "except Exception as e:\n",
    "    arcpy.AddError('Could not reduce to smallest GeoTiff extent.')\n",
    "    arcpy.AddMessage(str(e))           \n",
    "    return    \n",
    "\n",
    "# check if all nan again\n",
    "if ds.to_array().isnull().all():\n",
    "    arcpy.AddError('GeoTiff data is empty. Please check GeoTiffs.')            \n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "# # # # #\n",
    "# notify and increment progress bar\n",
    "arcpy.SetProgressorLabel('Computing GeoTiffs into memory, please wait...')\n",
    "arcpy.SetProgressorPosition(6)\n",
    "\n",
    "try:\n",
    "    # compute! \n",
    "    ds = ds.compute()\n",
    "except Exception as e: \n",
    "    arcpy.AddError('Could not compute GeoTiffs. See messages for details.')\n",
    "    arcpy.AddMessage(str(e))\n",
    "    return    \n",
    "\n",
    "# check if all nan again\n",
    "if ds.to_array().isnull().all():\n",
    "    arcpy.AddError('GeoTiff data is empty. Please check GeoTiffs.')            \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 % 2 == 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
